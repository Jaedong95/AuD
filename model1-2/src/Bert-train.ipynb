{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c9dbf2",
   "metadata": {},
   "source": [
    "### 1. Environment Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e256a",
   "metadata": {},
   "source": [
    "#### 1.1 Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "33e218b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import pymysql\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "from attrdict import AttrDict\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertConfig, BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401885e",
   "metadata": {},
   "source": [
    "#### 1.2 Setting Default Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "63749aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cori/AuD/model1-2/src\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b2275e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/cori/AuD/model1-2/data\"\n",
    "base_model_path = \"/home/cori/AuD/base-model\"\n",
    "save_model_path = \"/home/cori/AuD/model1-2/model\"\n",
    "config_path = \"/home/cori/AuD/model1-2/config\"\n",
    "log_path = \"/home/cori/AuD/model1-2/log\"\n",
    "config_file = \"bert-base.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f1b19",
   "metadata": {},
   "source": [
    "#### 1.3 Load Dataset "
   ]
  },
  {
   "cell_type": "raw",
   "id": "66209d1f",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "dsm_data = pd.read_csv(os.path.join(data_path, 'dsm_data.csv'))\n",
    "dsm_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "122fbda9",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# dsm_sample: label_10, dsm_sample2: label_9\n",
    "dsm_sample = pd.read_csv(os.path.join(data_path, 'dsm_sample2.csv'))\n",
    "dsm_sample.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ca3721f",
   "metadata": {},
   "source": [
    "dsm_data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db936bd0",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "dsm_data[dsm_data.label==8]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fe4882f",
   "metadata": {},
   "source": [
    "dsm_sample = dsm_data.copy()\n",
    "dsm = []\n",
    "\n",
    "dsm.extend(dsm_sample[dsm_sample.label==0].sample(40000).index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==1].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==2].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==3].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==4].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==5].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==6].sample(20000).index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==7].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==8].sample(20000).index.tolist())\n",
    "\n",
    "len(dsm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b14d00cc",
   "metadata": {},
   "source": [
    "dsm_sample = dsm_sample.loc[dsm]\n",
    "dsm_sample.to_csv(os.path.join(data_path, 'dsm_sample2.csv'), index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6638ff35",
   "metadata": {},
   "source": [
    "X_train, X_test = train_test_split(dsm_sample, test_size=0.2, random_state=42, stratify=dsm_sample['label'])\n",
    "X_train, X_dev = train_test_split(X_train, test_size=0.2, random_state=42, stratify=X_train['label'])\n",
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "416f16e3",
   "metadata": {},
   "source": [
    "X_train.groupby('label').count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "657bf8a7",
   "metadata": {},
   "source": [
    "X_train.to_csv(os.path.join(data_path, 'dsm_samp2_train.csv'), index=False)\n",
    "X_dev.to_csv(os.path.join(data_path, 'dsm_samp2_val.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(data_path, 'dsm_samp2_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671f6c4",
   "metadata": {},
   "source": [
    "#### 1.4 Load Pretrained model & tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "5c443246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '우울',\n",
       " 1: '무기력',\n",
       " 2: '급격한 체중(식욕)변화',\n",
       " 3: '수면장애',\n",
       " 4: '정서불안',\n",
       " 5: '피로',\n",
       " 6: '과도한 죄책감 및 무가치함',\n",
       " 7: '인지기능저하',\n",
       " 8: '자살충동'}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = dict()\n",
    "\n",
    "label[0] = '우울'\n",
    "label[1] = '무기력'\n",
    "label[2] = '급격한 체중(식욕)변화'\n",
    "label[3] = '수면장애'\n",
    "label[4] = '정서불안'\n",
    "label[5] = '피로'\n",
    "label[6] = '과도한 죄책감 및 무가치함'\n",
    "label[7] = '인지기능저하'\n",
    "label[8] = '자살충동'\n",
    "# label[9] = '일상'\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "0bbf96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.join(data_path, 'dsm_samp2_train.csv'))\n",
    "X_dev = pd.read_csv(os.path.join(data_path, 'dsm_samp2_val.csv'))\n",
    "X_test = pd.read_csv(os.path.join(data_path, 'dsm_samp2_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "61d2504b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63580, 15895, 19869)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5f93bf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 6, 8, 4, 3, 2, 5, 7, 1])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ce43a043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우울\n",
      "무기력\n",
      "급격한 체중(식욕)변화\n",
      "수면장애\n",
      "정서불안\n",
      "피로\n",
      "과도한 죄책감 및 무가치함\n",
      "인지기능저하\n",
      "자살충동\n"
     ]
    }
   ],
   "source": [
    "for i, name in label.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cec384fe",
   "metadata": {},
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=10, output_hidden_states=True)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "88a0b9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cori/AuD/base-model/bert-base'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(base_model_path, 'bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "ec85e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/cori/AuD/base-model/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/cori/AuD/base-model/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(base_model_path, 'bert-tiny'), model_max_length=128)\n",
    "config = BertConfig.from_pretrained(os.path.join(base_model_path, 'bert-tiny', 'bert_config.json'), num_labels=9)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(base_model_path, 'bert-tiny'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "562b48c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 128)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.attention_probs_dropout_prob, config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ee345",
   "metadata": {},
   "source": [
    "#### 1.5 setting training args & config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "9e440926",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, 'training_config.json')) as f:\n",
    "    training_config = AttrDict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "affe617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "5401389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'default_path': '../', 'data_path': 'data', 'log_path': 'log', 'model_path': 'model', 'config_path': 'config', 'seed': 42, 'train_batch_size': 8, 'device': device(type='cuda'), 'eval_batch_size': 8, 'num_epochs': 500, 'gradient_accumulation_steps': 1, 'warmup_proportion': 0, 'adam_epsilon': 1e-08, 'learning_rate': 5e-05, 'do_lower_case': False, 'no_cuda': False, 'max_steps': -1, 'logging_steps': 100})"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "bdf7ea26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-05"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "cf4e57f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(training_config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c79e9",
   "metadata": {},
   "source": [
    "### 2. Define Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "2e338dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.pad = 'max_length'\n",
    "training_config.num_epochs  = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "dd385338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = data_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.label)\n",
    "    \n",
    "    def reset_index(self):\n",
    "        self.data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # def clear_text(self)  => 전처리 코드를 여기에 넣을 경우 상당히 느려짐\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        return text, label\n",
    "        '''\n",
    "        self.reset_index()\n",
    "        text = self.data.text[idx]\n",
    "        label = self.data.label[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "e2c34513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertProcessor():\n",
    "    def __init__(self, config, training_config, tokenizer, truncation=True):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.max_len = config.max_position_embeddings\n",
    "        self.pad = training_config.pad\n",
    "        self.batch_size = training_config.train_batch_size\n",
    "        self.truncation = truncation\n",
    "    \n",
    "    def convert_data(self, data_file):\n",
    "        context2 = None    # single sentence classification\n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(data_file[idx][0], context2) for idx in range(len(data_file))],   # text, \n",
    "            max_length = self.max_len,\n",
    "            padding = self.pad,\n",
    "            truncation = self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        for i in range(len(data_file)):\n",
    "            inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "            try:\n",
    "                inputs['label'] = data_file[i][1] \n",
    "            except:\n",
    "                inputs['label'] = 0 \n",
    "            features.append(inputs)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "        return dataset\n",
    "    \n",
    "    def convert_sentence(self, sentence_list):   # 사용자 입력 문장 1개 -> 입력 형태 변환\n",
    "        pass\n",
    "    \n",
    "    def shuffle_data(self, dataset, data_type):\n",
    "        if data_type == 'train':\n",
    "            return RandomSampler(dataset)\n",
    "        elif data_type == 'eval' or data_type == 'test':\n",
    "            return SequentialSampler(dataset)\n",
    "        \n",
    "    def load_data(self, dataset, sampler):\n",
    "        return DataLoader(dataset, sampler=sampler, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdecbfd0",
   "metadata": {},
   "source": [
    "class ElectraRegressor(nn.Module):\n",
    "    '''\n",
    "    다중 분류 학습 시 선언하는 클래스 \n",
    "    '''\n",
    "    def __init__(self, electra, config):\n",
    "        # 부모 생성자 초기화, super().__init__(config) 시 오류 발생 \n",
    "        super(ElectraRegressor, self).__init__() \n",
    "        self.electra = electra\n",
    "        self.layer = nn.Linear(config.hidden_size, 128)\n",
    "        self.regressor = nn.Sequential(nn.Dropout(0.1), nn.Linear(128, 6))\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.electra(input_ids=input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids)\n",
    "        logits = outputs.last_hidden_state[:, 0, :]\n",
    "        output = self.layer(logits)\n",
    "        output = self.regressor(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "89a0759c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'default_path': '../', 'data_path': 'data', 'log_path': 'log', 'model_path': 'model', 'config_path': 'config', 'seed': 42, 'train_batch_size': 8, 'device': device(type='cuda'), 'eval_batch_size': 8, 'num_epochs': 500, 'gradient_accumulation_steps': 1, 'warmup_proportion': 0, 'adam_epsilon': 1e-08, 'learning_rate': 5e-05, 'do_lower_case': False, 'no_cuda': False, 'max_steps': -1, 'logging_steps': 100, 'pad': 'max_length'})"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config.num_epochs\n",
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "2e2c3620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "ba6556a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.save_model_path = \"/home/cori/AuD/model1-2/model\"\n",
    "training_config.log_path = \"/home/cori/AuD/model1-2/log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "9b93b173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cori/AuD/model1-2/model'"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "d8cb7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainer():\n",
    "    def __init__(self, config, training_config, model, train_dataloader, eval_dataloader, label_name, model_name):\n",
    "        self.config = config\n",
    "        self.training_config = training_config\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.eval_dataloader = eval_dataloader\n",
    "        self.label_name = label_name\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def set_seed(self):\n",
    "        random.seed(self.training_config.seed)\n",
    "        np.random.seed(self.training_config.seed)\n",
    "        torch.manual_seed(self.training_config.seed)\n",
    "        if not self.training_config.no_cuda and torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(self.training_config.seed)\n",
    "    \n",
    "    def train(self):\n",
    "        train_acc_list = []; eval_acc_list = [] \n",
    "        train_loss_list = []; eval_loss_list = []\n",
    "        # eval_acc_step = []; eval_loss_step = []\n",
    "        # train_acc_step = []; train_loss_step = []\n",
    "        nb_eval_steps = 0\n",
    "        best_loss = 9999; best_epoch = 0\n",
    "        t_total = len(self.train_dataloader) // self.training_config.gradient_accumulation_steps * self.training_config.num_epochs\n",
    "\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.training_config.learning_rate, eps=self.training_config.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(t_total * self.training_config.warmup_proportion), \\\n",
    "                                                    num_training_steps=t_total)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        for epoch in range(int(self.training_config.num_epochs)):\n",
    "            train_acc = 0.0; eval_acc = 0.0\n",
    "            train_loss = 0.0; eval_loss = 0.0 \n",
    "\n",
    "            for step, batch in enumerate(self.train_dataloader):\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.training_config.device) for t in batch)\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3]\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                # loss = outputs[0]\n",
    "                # y_pred = torch.max(outputs[1], 1)[1]\n",
    "                y_pred = outputs[1]\n",
    "                y_true = batch[3]\n",
    "                # y_true = torch.tensor([float(t) for t in y_true]).to(self.training_config.device)\n",
    "                loss = criterion(y_pred, y_true)\n",
    "                # print(outputs[0], outputs[1], batch[3])\n",
    "                loss.backward()\n",
    "                train_loss += loss.item()\n",
    "                train_acc += self.calc_accuracy(outputs[1], batch[3])\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                self.model.zero_grad()\n",
    "                '''\n",
    "                if step % training_config.logging_steps == 0:\n",
    "                    # print(f'step: {step}, {train_acc / (step + 1)}')\n",
    "                    # print(f'step: {step}, {train_loss / (step + 1)}')\n",
    "                    train_acc_step.append([step, train_acc / (step + 1)])\n",
    "                    train_loss_step.append([step, train_loss / (step + 1)])'''\n",
    "\n",
    "            train_acc = train_acc / (step + 1)\n",
    "            train_loss = train_loss / (step + 1)\n",
    "            print(f'epoch: {epoch}, train_loss: {train_loss}')\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_loss_list.append(train_loss)\n",
    "\n",
    "            for step2, batch2 in enumerate(self.eval_dataloader):\n",
    "                self.model.eval()\n",
    "                batch2 = tuple(t.to(self.training_config.device) for t in batch2)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    inputs = {\n",
    "                        \"input_ids\": batch2[0],\n",
    "                        \"attention_mask\": batch2[1],\n",
    "                        \"token_type_ids\": batch2[2],\n",
    "                        \"labels\": batch2[3]\n",
    "                    }\n",
    "                    outputs = self.model(**inputs)\n",
    "                    tmp_eval_loss, logits = outputs[:2]\n",
    "                    loss2 = criterion(logits, batch2[3])\n",
    "                    eval_loss += loss2.item()              \n",
    "                    # eval_loss += tmp_eval_loss.mean().item()\n",
    "                    eval_acc += self.calc_accuracy(outputs[1], batch2[3]) \n",
    "                    '''\n",
    "                    if step2 % training_config.logging_steps == 0:\n",
    "                        eval_acc_step.append([step2, eval_acc / (step + 1)])\n",
    "                        eval_loss_step.append([step2, eval_loss / (step + 1)])'''\n",
    "            '''            \n",
    "            try:\n",
    "                last_loss = eval_loss_list[-1]\n",
    "            except:\n",
    "                last_loss = 9999\n",
    "            '''\n",
    "            eval_loss = eval_loss / (step2 + 1)\n",
    "            eval_acc = eval_acc / (step2 + 1)\n",
    "            eval_acc_list.append(eval_acc)\n",
    "            eval_loss_list.append(eval_loss)\n",
    "            print(f'epoch: {epoch}, eval_loss: {eval_loss}')\n",
    "            \n",
    "            if eval_loss < best_loss:\n",
    "                best_loss = eval_loss\n",
    "                es = 0\n",
    "                print(f'save best loss state model & log(epoch {epoch + 1})')\n",
    "                self.save_model(os.path.join(self.training_config.save_model_path, self.label_name, self.model_name, f'bert_dsm_{epoch}.pt'))\n",
    "                best_epoch = epoch\n",
    "            else:\n",
    "                es += 1\n",
    "                print(\"Counter {} of 5\".format(es))\n",
    "\n",
    "            if es > 4:\n",
    "                print(\"Early stopping with best_loss: \", best_loss, \"and val_loss for this epoch: \", eval_loss, \"...\")\n",
    "                break\n",
    "                \n",
    "            '''\n",
    "            if eval_loss > last_loss:\n",
    "                trigger_times += 1\n",
    "                print('Trigger Times:', trigger_times)\n",
    "                self.save_model(os.path.join(self.training_config.default_path, self.training_config.model_path, f'bert_bws_{epoch}.pt'))\n",
    "                \n",
    "                if trigger_times > 4:\n",
    "                    print(\"Early stopping !\")\n",
    "                    self.save_model(os.path.join(self.training_config.default_path, self.training_config.model_path, f'bert_bws_best.pt'))\n",
    "                    break\n",
    "            else:\n",
    "                print('trigger times: 0')\n",
    "                trigger_times = 0'''\n",
    "            \n",
    "\n",
    "        self.save_log(train_acc_list, train_loss_list, eval_acc_list, eval_loss_list, epoch)\n",
    "        return train_acc_list, train_loss_list, eval_acc_list, eval_loss_list\n",
    "\n",
    "    def calc_accuracy(self, X,Y):\n",
    "        max_vals, max_indices = torch.max(X, 1)\n",
    "        train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "        return train_acc\n",
    "    \n",
    "    def compute_metrics(self, labels, preds):\n",
    "        assert len(preds) == len(labels)\n",
    "        acc = (labels == preds).mean()\n",
    "        return {\"acc\": acc}\n",
    "    \n",
    "    '''\n",
    "    def save_step_log(self, train_acc_step, train_loss_step, eval_acc_step, eval_loss_step, epoch):\n",
    "        with open(os.path.join(self.training_config.log_path, f'train_step_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_acc_step, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, f'train_step_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_loss_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, f'eval_step_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_acc_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, f'eval_step_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_loss_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "    '''\n",
    "    \n",
    "    def save_log(self, train_acc, train_loss, eval_acc, eval_loss, epoch):\n",
    "        with open(os.path.join(self.training_config.log_path, self.label_name, self.model_name, f'train_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_acc, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, self.label_name, self.model_name, f'train_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_loss, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, self.label_name, self.model_name, f'eval_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_acc, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, self.label_name, self.model_name, f'eval_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_loss, f, pickle.HIGHEST_PROTOCOL)  \n",
    "    \n",
    "    def save_model(self, model_name):\n",
    "        torch.save(self.model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fbc7d",
   "metadata": {},
   "source": [
    "### 3. Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "14329a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'label_9'\n",
    "model_name = 'bert-tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "7539a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "a820e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = BertDataset(X_train)\n",
    "val_file = BertDataset(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "bacfeb4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63580, 15895)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file), len(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "beaac774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.max_position_embeddings = 128\n",
    "config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "f4417358",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_processor = BertProcessor(config, training_config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "9d4276f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = bert_processor.convert_data(train_file)\n",
    "val_dataset = bert_processor.convert_data(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "986f2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = bert_processor.shuffle_data(train_dataset, 'train')\n",
    "val_sampler = bert_processor.shuffle_data(val_dataset, 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "4a1baa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = bert_processor.load_data(train_dataset, train_sampler)\n",
    "val_dataloader = bert_processor.load_data(val_dataset, val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "bad48641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7948, 1987)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "a1b972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trainer = BertTrainer(config, training_config, model, train_dataloader, val_dataloader, label_name, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "5b6e9d5f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.2103470317272914\n",
      "epoch: 0, eval_loss: 0.020554849305719786\n",
      "save best loss state model & log(epoch 1)\n",
      "epoch: 1, train_loss: 0.020009821761306588\n",
      "epoch: 1, eval_loss: 0.009047278841157365\n",
      "save best loss state model & log(epoch 2)\n",
      "epoch: 2, train_loss: 0.010425551458372845\n",
      "epoch: 2, eval_loss: 0.006383134840018745\n",
      "save best loss state model & log(epoch 3)\n",
      "epoch: 3, train_loss: 0.008023278510703792\n",
      "epoch: 3, eval_loss: 0.004239653666394255\n",
      "save best loss state model & log(epoch 4)\n",
      "epoch: 4, train_loss: 0.004515072208052986\n",
      "epoch: 4, eval_loss: 0.004948192808320499\n",
      "Counter 1 of 5\n",
      "epoch: 5, train_loss: 0.0037855200384780407\n",
      "epoch: 5, eval_loss: 0.004509812899528532\n",
      "Counter 2 of 5\n",
      "epoch: 6, train_loss: 0.00310356778864831\n",
      "epoch: 6, eval_loss: 0.003897410368682154\n",
      "save best loss state model & log(epoch 7)\n",
      "epoch: 7, train_loss: 0.0032885168064489133\n",
      "epoch: 7, eval_loss: 0.0032271775091955303\n",
      "save best loss state model & log(epoch 8)\n",
      "epoch: 8, train_loss: 0.0029714197499087565\n",
      "epoch: 8, eval_loss: 0.002282517832677172\n",
      "save best loss state model & log(epoch 9)\n",
      "epoch: 9, train_loss: 0.0021500131224630645\n",
      "epoch: 9, eval_loss: 0.00321303719827746\n",
      "Counter 1 of 5\n",
      "epoch: 10, train_loss: 0.0018904338492857521\n",
      "epoch: 10, eval_loss: 0.004460931148038844\n",
      "Counter 2 of 5\n",
      "epoch: 11, train_loss: 0.0014333471308940469\n",
      "epoch: 11, eval_loss: 0.002856531977372037\n",
      "Counter 3 of 5\n",
      "epoch: 12, train_loss: 0.0018309874032565268\n",
      "epoch: 12, eval_loss: 0.004963439015666505\n",
      "Counter 4 of 5\n",
      "epoch: 13, train_loss: 0.0017851820117473795\n",
      "epoch: 13, eval_loss: 0.005445830903142813\n",
      "Counter 5 of 5\n",
      "Early stopping with best_loss:  0.002282517832677172 and val_loss for this epoch:  0.005445830903142813 ...\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss, eval_acc, eval_loss = bert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "04497f7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = list(range(len(train_loss)))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "# plt.plot(list(range(len(train_loss))), train_loss, label='train_loss')\n",
    "plt.plot(list(range(len(train_loss))), train_loss, label='train_loss')\n",
    "plt.plot(list(range(len(train_loss))), eval_loss, label='val_loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32d280",
   "metadata": {},
   "source": [
    "### 3. Model Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "96dde817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '우울',\n",
       " 1: '무기력',\n",
       " 2: '급격한 체중(식욕)변화',\n",
       " 3: '수면장애',\n",
       " 4: '정서불안',\n",
       " 5: '피로',\n",
       " 6: '과도한 죄책감 및 무가치함',\n",
       " 7: '인지기능저하',\n",
       " 8: '자살충동',\n",
       " 9: '일상'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = dict()\n",
    "\n",
    "label[0] = '우울'\n",
    "label[1] = '무기력'\n",
    "label[2] = '급격한 체중(식욕)변화'\n",
    "label[3] = '수면장애'\n",
    "label[4] = '정서불안'\n",
    "label[5] = '피로'\n",
    "label[6] = '과도한 죄책감 및 무가치함'\n",
    "label[7] = '인지기능저하'\n",
    "label[8] = '자살충동'\n",
    "label[9] = '일상'\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7803e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10iull</td>\n",
       "      <td>i attempted suicide twice during this, and as ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47ohkk</td>\n",
       "      <td>i just have a feeling of sadness constantly in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107968</td>\n",
       "      <td>I think it'd be better to wear several thin cl...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_nq3wc</td>\n",
       "      <td>coming to terms with depressed emotions and ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_19471c</td>\n",
       "      <td>i have no idea why i am so depressed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>t3_ywqnu</td>\n",
       "      <td>guess what? he committed suicide when he was 3...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19865</th>\n",
       "      <td>t3_2hiaei</td>\n",
       "      <td>the replies in this post make me sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>134760</td>\n",
       "      <td>That's right... I don't know.\"T\"</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19867</th>\n",
       "      <td>t3_1yl462</td>\n",
       "      <td>it's hard not to be sad about it, though, when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19868</th>\n",
       "      <td>t3_4ugqwo</td>\n",
       "      <td>even depressed people would not want to wish h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19869 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text  label\n",
       "0         10iull  i attempted suicide twice during this, and as ...      8\n",
       "1         47ohkk  i just have a feeling of sadness constantly in...      0\n",
       "2         107968  I think it'd be better to wear several thin cl...      9\n",
       "3       t3_nq3wc  coming to terms with depressed emotions and ju...      0\n",
       "4      t3_19471c               i have no idea why i am so depressed      0\n",
       "...          ...                                                ...    ...\n",
       "19864   t3_ywqnu  guess what? he committed suicide when he was 3...      8\n",
       "19865  t3_2hiaei               the replies in this post make me sad      0\n",
       "19866     134760                   That's right... I don't know.\"T\"      9\n",
       "19867  t3_1yl462  it's hard not to be sad about it, though, when...      0\n",
       "19868  t3_4ugqwo  even depressed people would not want to wish h...      0\n",
       "\n",
       "[19869 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(os.path.join(data_path, 'dsm_samp_test.csv'))\n",
    "X_test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d62aa080",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=9)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce3c5973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/cori/AuD/base-model/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/cori/AuD/base-model/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(base_model_path, 'bert-base'), model_max_length=32)\n",
    "config = BertConfig.from_pretrained(os.path.join(base_model_path, 'bert-base', 'bert_config.json'), num_labels=10)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(base_model_path, 'bert-base'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7a16f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_position_embeddings = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b46c8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, 'training_config.json')) as f:\n",
    "    training_config = AttrDict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0086a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.pad = 'max_length'\n",
    "training_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "466405f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = data_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.label)\n",
    "    \n",
    "    def reset_index(self):\n",
    "        self.data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # def clear_text(self)  => 전처리 코드를 여기에 넣을 경우 상당히 느려짐\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        return text, label\n",
    "        '''\n",
    "        self.reset_index()\n",
    "        text = self.data.text[idx]\n",
    "        label = self.data.label[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f3451c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertProcessor():\n",
    "    def __init__(self, config, training_config, tokenizer, truncation=True):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.max_len = config.max_position_embeddings\n",
    "        self.pad = training_config.pad\n",
    "        self.batch_size = training_config.train_batch_size\n",
    "        self.truncation = truncation\n",
    "    \n",
    "    def convert_data(self, data_file):\n",
    "        context2 = None    # single sentence classification\n",
    "\n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(data_file[idx][0], context2) for idx in range(len(data_file))],   # text, \n",
    "            max_length = self.max_len,\n",
    "            padding = self.pad,\n",
    "            truncation = self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        for i in range(len(data_file)):\n",
    "            inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "            try:\n",
    "                inputs['label'] = data_file[i][1] \n",
    "            except:\n",
    "                inputs['label'] = 0 \n",
    "            features.append(inputs)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "        return dataset\n",
    "    \n",
    "    def convert_sentence(self, sent_list):   # 사용자 입력 문장 1개 -> 입력 형태 변환\n",
    "        context2 = None \n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(sent_list, context2)], max_length=self.max_len, padding=self.pad, truncation=self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        inputs = {k: batch_encoding[k][0] for k in batch_encoding}\n",
    "        inputs['label'] = 0 \n",
    "        features.append(inputs)\n",
    "\n",
    "        input_id = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        input_am = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        input_tts = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        input_lb = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "        dataset = TensorDataset(input_id, input_am, input_tts, input_lb)\n",
    "        return dataset\n",
    "    \n",
    "    def shuffle_data(self, dataset, data_type):\n",
    "        if data_type == 'train':\n",
    "            return RandomSampler(dataset)\n",
    "        elif data_type == 'eval' or data_type == 'test':\n",
    "            return SequentialSampler(dataset)\n",
    "        \n",
    "    def load_data(self, dataset, sampler):\n",
    "        return DataLoader(dataset, sampler=sampler, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "66386a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTester():\n",
    "    def __init__(self, training_config, model):\n",
    "        self.training_config = training_config\n",
    "        self.model = model\n",
    "\n",
    "    def get_label(self, test_dataloader, test_type):\n",
    "        '''\n",
    "        test_type: 0  -> Test dataset \n",
    "        test_type: 1  -> Test sentence\n",
    "        '''\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        for batch in test_dataloader:\n",
    "            self.model.eval()\n",
    "            batch = tuple(t.to(self.training_config.device) for t in batch)   # args.device: cuda \n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3]\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                test_loss, logits = outputs[:2] \n",
    "                pred = logits.detach().cpu().numpy()\n",
    "                if test_type == 0:\n",
    "                    preds.extend(np.argmax(pred, axis=1))\n",
    "                elif test_type == 1:\n",
    "                    preds.append(np.argmax(pred))  \n",
    "                            \n",
    "            label = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            labels.extend(label)\n",
    "  \n",
    "        return preds, labels \n",
    "    \n",
    "    def get_f1_score(self, test_dataloader):\n",
    "        y_pred, y_true = self.get_label(test_dataloader)\n",
    "        return round(f1_score(y_true, y_pred, average='micro'), 3) \n",
    "     \n",
    "    def get_cl_report(self, test_dataloader):\n",
    "        y_pred, y_true = self.get_label(test_dataloader)\n",
    "        cr = classification_report(y_true, y_pred).split('\\n')\n",
    "        clr_df = []\n",
    "\n",
    "        for idx, line in enumerate(cr):\n",
    "            clr_df.append([])\n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            word_list = line.strip().split(' ')\n",
    "\n",
    "            for word in word_list:\n",
    "                if word != '':\n",
    "                    clr_df[idx].append(word)\n",
    "\n",
    "        clr_df[-2][0] = ' '.join([clr_df[-2][0], clr_df[-2][1]])\n",
    "        clr_df[-3][0] = ' '.join([clr_df[-3][0], clr_df[-3][1]])\n",
    "        clr_df[-4].insert(1, ' ')\n",
    "        clr_df[-4].insert(2, ' ')\n",
    "        clr_df[0].insert(0, 'index')\n",
    "\n",
    "        clr_df[-2].pop(1)\n",
    "        clr_df[-3].pop(1)\n",
    "        clr_df.pop(1)\n",
    "        clr_df.pop(-1)\n",
    "        clr_df.pop(-4)\n",
    "        clr_df = pd.DataFrame(clr_df[1:], columns=clr_df[0])\n",
    "        clr_df.index = clr_df['index']\n",
    "\n",
    "        del clr_df['index']\n",
    "        return clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8dfbe5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processor = BertProcessor(config, training_config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eb41887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = BertDataset(X_test)\n",
    "test_dataset = test_processor.convert_data(test_file)\n",
    "test_sampler = test_processor.shuffle_data(test_dataset, 'test')\n",
    "test_dataloader = test_processor.load_data(test_dataset, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ad0437fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cori/AuD/model1-2/model'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2430407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = os.path.join(model_path, 'label_9', 'bert_medium', 'bert_class.pt')\n",
    "model_name = os.path.join(save_model_path, label, model_name, 'bert_dsm_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d97810a5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_name))\n",
    "model.to(training_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b9cabbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tester = BertTester(training_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "97399182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i attempted suicide twice during this, and as a really young kid i did once'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bddbae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'conv.pickle'), 'rb') as f:\n",
    "    conv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "51790cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>그러게, 그런데 나는 기분이 우울해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>번아웃이 온 거 같기도 해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text\n",
       "0          1        User                                     안녕\n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요\n",
       "2          3        User                               이름이 뭐야 ?\n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요\n",
       "4          5        User                                  아하 ㅎㅎ\n",
       "5          6     Chatbot                               좋은 아침이에요\n",
       "6          7        User                    그러게, 그런데 나는 기분이 우울해\n",
       "7          8     Chatbot                             무슨 일 있어요 ?\n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아\n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요\n",
       "10        11        User                         심리적으로도 지친 거 같아\n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?\n",
       "12        13        User                         번아웃이 온 거 같기도 해\n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요\n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지\n",
       "15        16     Chatbot                                  산책 좋죠\n",
       "16        17        User                               들어줘서 고마워\n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "30db8c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9317/3337350865.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv.text.loc[6] = '오늘 너무 우울하다'\n",
      "/tmp/ipykernel_9317/3337350865.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv.text.loc[12] = '일이 너무 많아서 잠도 너무 못 자 '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>오늘 너무 우울하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>일이 너무 많아서 잠도 너무 못 자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text\n",
       "0          1        User                                     안녕\n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요\n",
       "2          3        User                               이름이 뭐야 ?\n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요\n",
       "4          5        User                                  아하 ㅎㅎ\n",
       "5          6     Chatbot                               좋은 아침이에요\n",
       "6          7        User                             오늘 너무 우울하다\n",
       "7          8     Chatbot                             무슨 일 있어요 ?\n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아\n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요\n",
       "10        11        User                         심리적으로도 지친 거 같아\n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?\n",
       "12        13        User                   일이 너무 많아서 잠도 너무 못 자 \n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요\n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지\n",
       "15        16     Chatbot                                  산책 좋죠\n",
       "16        17        User                               들어줘서 고마워\n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.text.loc[6] = '오늘 너무 우울하다'\n",
    "conv.text.loc[12] = '일이 너무 많아서 잠도 너무 못 자 '\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "219ee4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated = [\"hey\", \"Hello, nice to meet you\", \"what is your name ?\", \"I am a psychological counseling chatbot\", \"Ah-huh\", \\\n",
    "              \"good morning\", \"I'm so depressed today\", \"What's wrong?\", \"I just feel so lethargic these days\", \\\n",
    "              \"When you're lethargic, you have to move your body\", \"I think he's psychologically exhausted\", \\\n",
    "              \"I think you're really tired Is your work very hard?\", \"I can't sleep because I have too much work to do\", \\\n",
    "              \"I think it's good to take a break for a while\", \"I should I'll go for a walk from time to time\", \\\n",
    "              \"Taking a walk is good\", \"Thanks for listening\", \"Yes! See you next time\"]\n",
    "\n",
    "len(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c5ba81a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "      <td>what is your name ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "      <td>Ah-huh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "      <td>good morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>오늘 너무 우울하다</td>\n",
       "      <td>I'm so depressed today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "      <td>What's wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "      <td>I just feel so lethargic these days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "      <td>When you're lethargic, you have to move your body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "      <td>I think he's psychologically exhausted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "      <td>I think you're really tired Is your work very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>일이 너무 많아서 잠도 너무 못 자</td>\n",
       "      <td>I can't sleep because I have too much work to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "      <td>I think it's good to take a break for a while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "      <td>I should I'll go for a walk from time to time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "      <td>Taking a walk is good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "      <td>Thanks for listening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "      <td>Yes! See you next time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text  \\\n",
       "0          1        User                                     안녕   \n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요   \n",
       "2          3        User                               이름이 뭐야 ?   \n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요   \n",
       "4          5        User                                  아하 ㅎㅎ   \n",
       "5          6     Chatbot                               좋은 아침이에요   \n",
       "6          7        User                             오늘 너무 우울하다   \n",
       "7          8     Chatbot                             무슨 일 있어요 ?   \n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아   \n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요   \n",
       "10        11        User                         심리적으로도 지친 거 같아   \n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?   \n",
       "12        13        User                   일이 너무 많아서 잠도 너무 못 자    \n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요   \n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지   \n",
       "15        16     Chatbot                                  산책 좋죠   \n",
       "16        17        User                               들어줘서 고마워   \n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요   \n",
       "\n",
       "                                           translated  \n",
       "0                                                 hey  \n",
       "1                             Hello, nice to meet you  \n",
       "2                                 what is your name ?  \n",
       "3             I am a psychological counseling chatbot  \n",
       "4                                              Ah-huh  \n",
       "5                                        good morning  \n",
       "6                              I'm so depressed today  \n",
       "7                                       What's wrong?  \n",
       "8                 I just feel so lethargic these days  \n",
       "9   When you're lethargic, you have to move your body  \n",
       "10             I think he's psychologically exhausted  \n",
       "11  I think you're really tired Is your work very ...  \n",
       "12   I can't sleep because I have too much work to do  \n",
       "13      I think it's good to take a break for a while  \n",
       "14      I should I'll go for a walk from time to time  \n",
       "15                              Taking a walk is good  \n",
       "16                               Thanks for listening  \n",
       "17                             Yes! See you next time  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['translated'] = translated\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "589b705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'conv_translated.pickle'), 'wb') as f:\n",
    "    pickle.dump(conv, f, pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3b06b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User</td>\n",
       "      <td>what is your name ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User</td>\n",
       "      <td>Ah-huh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                     text\n",
       "0     User                                      hey\n",
       "1  Chatbot                  Hello, nice to meet you\n",
       "2     User                      what is your name ?\n",
       "3  Chatbot  I am a psychological counseling chatbot\n",
       "4     User                                   Ah-huh"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['translated'] = translated\n",
    "conv = conv[['speaker_idx', 'translated']]\n",
    "conv.columns = ['speaker', 'text']\n",
    "conv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7797aa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'Hello, nice to meet you',\n",
       " 'what is your name ?',\n",
       " 'I am a psychological counseling chatbot',\n",
       " 'Ah-huh',\n",
       " 'good morning',\n",
       " \"I'm so depressed today\",\n",
       " \"What's wrong?\",\n",
       " 'I just feel so lethargic these days',\n",
       " \"When you're lethargic, you have to move your body\",\n",
       " \"I think he's psychologically exhausted\",\n",
       " \"I think you're really tired Is your work very hard?\",\n",
       " \"I can't sleep because I have too much work to do\",\n",
       " \"I think it's good to take a break for a while\",\n",
       " \"I should I'll go for a walk from time to time\",\n",
       " 'Taking a walk is good',\n",
       " 'Thanks for listening',\n",
       " 'Yes! See you next time']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_list = conv.text.values.tolist()\n",
    "conv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71939437",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_list = conv.text.values.tolist()\n",
    "\n",
    "conv_result = [] \n",
    "for text in conv_list: \n",
    "    conv_dataset = test_processor.convert_sentence(text)\n",
    "    conv_sampler = test_processor.shuffle_data(conv_dataset, 'test')\n",
    "    conv_dataloader = test_processor.load_data(conv_dataset, conv_sampler)\n",
    "    y_pred, y_true = bert_tester.get_label(conv_dataloader)\n",
    "    conv_result.append(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d10f41e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14854/1442458656.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv['predict'] = conv_result\n",
      "/tmp/ipykernel_14854/1442458656.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv['predict'] = conv.predict.apply(lambda x: label[x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User</td>\n",
       "      <td>hey</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User</td>\n",
       "      <td>what is your name ?</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User</td>\n",
       "      <td>Ah-huh</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>good morning</td>\n",
       "      <td>수면장애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>User</td>\n",
       "      <td>I'm so depressed today</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>What's wrong?</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>User</td>\n",
       "      <td>I just feel so lethargic these days</td>\n",
       "      <td>무기력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>When you're lethargic, you have to move your body</td>\n",
       "      <td>무기력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>User</td>\n",
       "      <td>I think he's psychologically exhausted</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I think you're really tired Is your work very ...</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>User</td>\n",
       "      <td>I can't sleep because I have too much work to do</td>\n",
       "      <td>수면장애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I think it's good to take a break for a while</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>User</td>\n",
       "      <td>I should I'll go for a walk from time to time</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Taking a walk is good</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>User</td>\n",
       "      <td>Thanks for listening</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Yes! See you next time</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                               text         predict\n",
       "0      User                                                hey              우울\n",
       "1   Chatbot                            Hello, nice to meet you              우울\n",
       "2      User                                what is your name ?              우울\n",
       "3   Chatbot            I am a psychological counseling chatbot  과도한 죄책감 및 무가치함\n",
       "4      User                                             Ah-huh              우울\n",
       "5   Chatbot                                       good morning            수면장애\n",
       "6      User                             I'm so depressed today              우울\n",
       "7   Chatbot                                      What's wrong?              우울\n",
       "8      User                I just feel so lethargic these days             무기력\n",
       "9   Chatbot  When you're lethargic, you have to move your body             무기력\n",
       "10     User             I think he's psychologically exhausted  과도한 죄책감 및 무가치함\n",
       "11  Chatbot  I think you're really tired Is your work very ...  과도한 죄책감 및 무가치함\n",
       "12     User   I can't sleep because I have too much work to do            수면장애\n",
       "13  Chatbot      I think it's good to take a break for a while              우울\n",
       "14     User      I should I'll go for a walk from time to time              우울\n",
       "15  Chatbot                              Taking a walk is good              우울\n",
       "16     User                               Thanks for listening              우울\n",
       "17  Chatbot                             Yes! See you next time              우울"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['predict'] = conv_result\n",
    "conv['predict'] = conv.predict.apply(lambda x: label[x])\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f7426eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sent = \"I can't sleep because I have too much work to do\" # X_test.text[0]\n",
    "test_data = test_processor.convert_sentence(test_sent)\n",
    "test_sampler = test_processor.shuffle_data(test_data, 'test')\n",
    "test_loader = test_processor.load_data(test_data, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dbb8068e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e266bb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1458</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  text\n",
       "label            \n",
       "0      4000  4000\n",
       "1       418   418\n",
       "2      1051  1051\n",
       "3      1458  1458\n",
       "4       143   143\n",
       "5       351   351\n",
       "6      2000  2000\n",
       "7       496   496\n",
       "8      2000  2000\n",
       "9      4000  4000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1acd9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = bert_tester.get_label(test_dataloader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d96195a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 0, 9]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99c1ba61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 0, 9]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67c3ee5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred, y_true \u001b[38;5;241m=\u001b[39m bert_tester\u001b[38;5;241m.\u001b[39mget_label(test_loader, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = bert_tester.get_label(test_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "076ea0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a1f4d80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 1]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "91b60322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 1]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a7db1779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2957</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2     3    4    5     6    7     8     9\n",
       "0  4945    0     0     0    0    0     0    0     1    54\n",
       "1     0  411     0     1    1    0     0    1     0     2\n",
       "2     0    0  1024     0    0    0     0    0     0     2\n",
       "3     1    0     0  1441    0    0     0    0     0     4\n",
       "4     0    0     0     7  136    0     0    0     0     0\n",
       "5     0    0     0     0    0  348     0    0     0     0\n",
       "6     0    0     0     0    0    0  2993    0     0     7\n",
       "7     0    0     0     0    0    0     0  489     0     1\n",
       "8     0    0     0     0    0    0     0    0  2957    43\n",
       "9    15    2    13     1    0    0     3    5     6  4955"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score , recall_score , confusion_matrix, f1_score, classification_report\n",
    "\n",
    "confusion_mt = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "confusion_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd513f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
