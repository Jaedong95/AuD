{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98f7b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import pymysql\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset\n",
    "from attrdict import AttrDict\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cf1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\AuD\\\\model1-2\\\\src'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced57464",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/AuD/model1-2/data\"\n",
    "base_model_path = \"D:/AuD/base-model\"\n",
    "save_model_path = \"D:/AuD/model1-2/model/\"\n",
    "config_path = \"D:/AuD/model1-2/config\"\n",
    "log_path = \"D:/AuD/model1-2/log\"\n",
    "config_file = \"bert-base.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36337517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fws4y</td>\n",
       "      <td>anyways, the doctor says be careful because yo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_23p0b1</td>\n",
       "      <td>i also have [aka *amerge*] for migraines, but ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26twx8</td>\n",
       "      <td>all in all i feel worthless pretty much the on...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  label\n",
       "0     4fws4y  anyways, the doctor says be careful because yo...      3\n",
       "1  t3_23p0b1  i also have [aka *amerge*] for migraines, but ...      3\n",
       "2     26twx8  all in all i feel worthless pretty much the on...      8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_samp = pd.read_csv(os.path.join(data_path, 'dsm_samp2_test.csv'))\n",
    "dsm_samp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851d15f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at D:/AuD/base-model\\bert-small were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at D:/AuD/base-model\\bert-small and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(base_model_path, 'bert-small'), model_max_length=32)\n",
    "config = BertConfig.from_pretrained(os.path.join(base_model_path, 'bert-small', 'bert_config.json'),\\\n",
    "                                    num_labels=10,\\\n",
    "                                    output_hidden_states=True,\\\n",
    "                                    output_attentions=True)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(base_model_path, 'bert-small'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd14247",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, 'training_config.json')) as f:\n",
    "    training_config = AttrDict(json.load(f))\n",
    "\n",
    "training_config.pad = 'max_length'\n",
    "training_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77edf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_position_embeddings = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c180a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = os.path.join(save_model_path, 'label_10', 'bert-mini', 'bert_dsm_4.pt')\n",
    "# model_name = os.path.join(save_model_path, 'label_10', 'bert-base', 'bert_dsm_1.pt')\n",
    "model_name = os.path.join(save_model_path, 'label_10', 'bert-small', 'bert_dsm_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87904be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_name, map_location=torch.device('cpu')))\n",
    "model.to(training_config.device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3be97acd",
   "metadata": {},
   "source": [
    "encoded = tokenizer.encode_plus(\n",
    "    text=dsm_samp.text[idx],  # the sentence to be encoded\n",
    "    add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "    max_length = 64,  # maximum length of a sentence\n",
    "    pad_to_max_length=True,  # Add [PAD]s\n",
    "    return_attention_mask = True,  # Generate the attention mask\n",
    "    return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5a7d5c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  1045,  2572,  2061, 14777,  1998,  2292,  8167, 12863,  2008,\n",
       "           1045,  2514,  2066,  1045,  1005,  1049,  2012,  2188,  2035,  2154,\n",
       "           1012,   102]]),\n",
       " 22)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1ad3e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "92918453",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.0085, -1.1707, -1.8969, -1.6441, -3.3119, -2.3559, -1.1055, -2.4915,\n",
       "         -1.9942,  7.9496]], grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[-0.1901, -0.2641, -0.0525,  ..., -0.9500, -0.2766, -0.1464],\n",
       "         [ 0.1015,  0.5429,  1.8625,  ...,  1.2891, -0.2637, -0.5567],\n",
       "         [ 0.1638, -0.0085, -0.4589,  ..., -0.6815, -0.2675, -0.8721],\n",
       "         ...,\n",
       "         [ 0.7381, -1.1474, -0.1650,  ...,  0.9194, -0.8965,  0.8303],\n",
       "         [-0.0850, -0.6053, -1.1474,  ...,  0.3525, -0.0391,  0.4304],\n",
       "         [ 1.5000, -0.7967,  0.8970,  ..., -0.1933, -0.7220, -0.0389]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0582,  0.0376, -0.2829,  ..., -0.6916, -0.3581,  0.1042],\n",
       "         [ 0.1362,  1.0145,  1.7849,  ...,  0.1044, -1.0677, -0.1571],\n",
       "         [-0.3139,  0.9738, -0.5034,  ..., -0.5775, -0.2390,  0.5566],\n",
       "         ...,\n",
       "         [ 0.5239, -0.0151, -1.3967,  ...,  1.5463, -1.6831,  0.1674],\n",
       "         [-0.3254, -0.2157, -2.1273,  ...,  0.4443, -0.1681,  0.5878],\n",
       "         [ 0.9605, -0.0452,  0.5684,  ..., -0.5463, -0.7512,  0.3987]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.1432,  0.2155, -0.7558,  ..., -0.1082, -0.4059, -0.1165],\n",
       "         [-0.0902,  0.3249,  0.7744,  ..., -0.2900, -0.2575, -0.4867],\n",
       "         [-0.2265,  0.1511, -0.6210,  ..., -0.5117, -0.3115,  0.1107],\n",
       "         ...,\n",
       "         [-0.2593, -0.0998, -1.4297,  ...,  0.8692, -2.2520,  0.2591],\n",
       "         [-0.2600,  0.4211, -1.8402,  ...,  1.2663,  0.0615, -0.0117],\n",
       "         [ 0.0235, -0.0623, -0.2065,  ..., -0.1814,  0.0783,  0.1695]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0576,  0.0402,  0.8584,  ...,  0.5202, -1.5303, -1.7730],\n",
       "         [ 1.1360,  1.1612,  1.3079,  ..., -0.5092, -0.6656, -1.3669],\n",
       "         [-0.9014,  0.3697,  0.2313,  ..., -0.0535, -1.6043, -0.7782],\n",
       "         ...,\n",
       "         [ 0.2024,  0.4462, -0.1125,  ...,  0.4364, -2.0160, -0.7103],\n",
       "         [ 0.8122,  0.1153,  0.5370,  ...,  1.4775, -1.3914, -1.4825],\n",
       "         [ 0.2844,  0.3654,  0.2878,  ...,  0.4839, -1.3129, -1.2329]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.3966, -0.8896,  1.2512,  ..., -0.5511, -0.1408,  0.5154],\n",
       "         [-0.6397, -0.9741,  1.2455,  ..., -0.8214, -0.1916,  0.6143],\n",
       "         [-0.4406, -0.9608,  1.1991,  ..., -0.6642, -0.1008,  0.6144],\n",
       "         ...,\n",
       "         [-0.7644, -0.9729,  1.0386,  ..., -0.7575, -0.2167,  0.8199],\n",
       "         [-0.3960, -0.8687,  1.1749,  ..., -0.4530,  0.0859,  0.6111],\n",
       "         [-0.4320, -0.9522,  1.1807,  ..., -0.5886,  0.0365,  0.6435]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)), attentions=(tensor([[[[4.5186e-02, 3.9213e-02, 1.0438e-01,  ..., 2.9718e-02,\n",
       "           9.5299e-02, 3.7721e-02],\n",
       "          [2.2554e-02, 2.2747e-03, 1.5511e-01,  ..., 6.2760e-03,\n",
       "           5.4396e-02, 1.3309e-02],\n",
       "          [7.0941e-02, 1.5587e-02, 1.3904e-02,  ..., 9.0982e-03,\n",
       "           1.2950e-01, 2.0871e-02],\n",
       "          ...,\n",
       "          [1.5500e-01, 3.5438e-02, 6.2895e-02,  ..., 3.7752e-03,\n",
       "           2.9036e-02, 7.2954e-02],\n",
       "          [1.3174e-02, 3.3768e-03, 2.9346e-02,  ..., 5.2058e-03,\n",
       "           6.9005e-01, 4.6863e-03],\n",
       "          [2.4058e-02, 1.2888e-02, 7.4302e-02,  ..., 3.5876e-02,\n",
       "           3.2654e-01, 1.7627e-02]],\n",
       "\n",
       "         [[4.4478e-02, 3.2885e-02, 3.6246e-02,  ..., 5.9780e-02,\n",
       "           3.6838e-02, 3.0853e-02],\n",
       "          [1.6004e-03, 8.9833e-02, 4.7547e-04,  ..., 1.1100e-03,\n",
       "           2.1038e-03, 3.3243e-03],\n",
       "          [1.1497e-02, 2.8474e-02, 5.1716e-01,  ..., 1.1849e-02,\n",
       "           7.9834e-03, 2.2657e-02],\n",
       "          ...,\n",
       "          [1.2186e-02, 1.5667e-02, 2.0794e-02,  ..., 6.8659e-01,\n",
       "           2.5206e-03, 5.6499e-03],\n",
       "          [1.1106e-01, 2.0700e-02, 2.3723e-02,  ..., 6.9971e-03,\n",
       "           9.1702e-03, 7.9015e-02],\n",
       "          [8.0623e-02, 2.0259e-02, 4.3296e-02,  ..., 3.4165e-03,\n",
       "           2.0196e-02, 9.6890e-02]],\n",
       "\n",
       "         [[4.1758e-02, 1.4438e-02, 4.0618e-02,  ..., 5.1867e-02,\n",
       "           5.6013e-02, 6.8574e-02],\n",
       "          [6.8742e-03, 4.3636e-04, 1.1157e-03,  ..., 2.6091e-05,\n",
       "           3.2088e-04, 9.6684e-01],\n",
       "          [5.5383e-02, 7.0487e-02, 1.4833e-01,  ..., 8.1006e-03,\n",
       "           1.4306e-02, 2.5735e-02],\n",
       "          ...,\n",
       "          [1.2332e-02, 3.7438e-03, 1.5220e-03,  ..., 1.3003e-02,\n",
       "           7.8602e-02, 1.2174e-02],\n",
       "          [2.4164e-02, 2.4009e-03, 3.2238e-03,  ..., 3.5107e-02,\n",
       "           9.7127e-02, 3.9590e-02],\n",
       "          [7.1146e-03, 1.3724e-06, 8.5967e-06,  ..., 1.1784e-03,\n",
       "           6.6151e-04, 9.8975e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.2745e-02, 3.6933e-02, 1.4251e-01,  ..., 2.8850e-02,\n",
       "           2.1465e-02, 2.4588e-02],\n",
       "          [5.6763e-02, 1.0897e-01, 4.3357e-02,  ..., 1.8951e-02,\n",
       "           2.1344e-02, 5.1596e-02],\n",
       "          [3.0934e-02, 2.1222e-02, 3.7657e-02,  ..., 4.4305e-02,\n",
       "           6.0158e-02, 3.3574e-02],\n",
       "          ...,\n",
       "          [3.6293e-02, 6.8817e-02, 9.8621e-02,  ..., 3.1846e-02,\n",
       "           6.5969e-02, 3.2111e-02],\n",
       "          [8.0565e-02, 8.1205e-02, 4.8856e-02,  ..., 1.7988e-02,\n",
       "           1.4384e-02, 5.5892e-02],\n",
       "          [1.5379e-02, 1.1957e-02, 1.0303e-01,  ..., 2.8556e-02,\n",
       "           2.6542e-02, 1.7470e-02]],\n",
       "\n",
       "         [[9.9713e-01, 2.1026e-04, 3.0552e-04,  ..., 7.8918e-05,\n",
       "           1.4060e-04, 7.4011e-04],\n",
       "          [9.9999e-01, 8.5280e-07, 7.1653e-08,  ..., 8.1226e-12,\n",
       "           4.0981e-15, 2.9477e-12],\n",
       "          [6.1779e-07, 9.9902e-01, 9.8362e-04,  ..., 5.2839e-10,\n",
       "           1.6008e-14, 1.1756e-17],\n",
       "          ...,\n",
       "          [3.0260e-13, 5.2690e-11, 2.4836e-13,  ..., 1.7316e-06,\n",
       "           1.0809e-10, 1.7332e-16],\n",
       "          [9.0936e-13, 4.9927e-13, 4.2663e-09,  ..., 9.9753e-01,\n",
       "           1.2511e-04, 3.2913e-11],\n",
       "          [8.6311e-12, 2.0958e-18, 1.0175e-13,  ..., 6.4544e-07,\n",
       "           1.0000e+00, 1.0468e-07]],\n",
       "\n",
       "         [[5.4844e-03, 5.6648e-04, 1.7582e-02,  ..., 2.2488e-04,\n",
       "           5.6480e-04, 3.7291e-03],\n",
       "          [3.4070e-03, 2.6739e-04, 1.1447e-01,  ..., 4.0839e-04,\n",
       "           3.5861e-04, 1.0535e-03],\n",
       "          [5.6113e-03, 4.9361e-04, 1.4308e-02,  ..., 4.3333e-03,\n",
       "           6.8284e-03, 1.3504e-03],\n",
       "          ...,\n",
       "          [1.4651e-02, 7.7473e-03, 1.8586e-02,  ..., 4.1932e-03,\n",
       "           1.9936e-03, 5.2426e-03],\n",
       "          [8.3616e-02, 4.6830e-03, 6.4884e-02,  ..., 1.2521e-02,\n",
       "           3.2758e-03, 1.5107e-02],\n",
       "          [4.0952e-02, 1.3271e-03, 5.2229e-02,  ..., 2.6523e-03,\n",
       "           6.7202e-03, 7.7731e-03]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[7.6754e-02, 1.4217e-03, 1.4941e-03,  ..., 5.8129e-03,\n",
       "           5.1635e-01, 1.0077e-02],\n",
       "          [3.3749e-01, 3.8730e-03, 3.9476e-03,  ..., 1.7200e-02,\n",
       "           5.4458e-02, 1.0355e-01],\n",
       "          [1.0840e-01, 2.8618e-04, 2.7574e-04,  ..., 2.2054e-03,\n",
       "           1.8691e-01, 9.8464e-03],\n",
       "          ...,\n",
       "          [2.5390e-01, 2.6868e-03, 3.5083e-03,  ..., 7.7110e-03,\n",
       "           3.9369e-01, 2.6702e-02],\n",
       "          [9.6899e-02, 2.4816e-02, 1.1411e-02,  ..., 7.2211e-03,\n",
       "           2.8567e-01, 1.5167e-01],\n",
       "          [2.6621e-01, 2.5962e-02, 1.3676e-02,  ..., 3.1325e-02,\n",
       "           2.9875e-02, 1.4338e-01]],\n",
       "\n",
       "         [[6.2860e-01, 2.8522e-03, 1.2665e-02,  ..., 2.5056e-02,\n",
       "           2.7040e-01, 8.8028e-03],\n",
       "          [2.0924e-01, 1.1436e-02, 7.1109e-01,  ..., 7.7956e-03,\n",
       "           9.5382e-03, 4.8700e-04],\n",
       "          [1.1915e-01, 7.1232e-05, 9.2056e-02,  ..., 7.5954e-06,\n",
       "           7.7106e-05, 2.6910e-07],\n",
       "          ...,\n",
       "          [1.9852e-01, 2.6659e-05, 6.3812e-06,  ..., 7.0972e-01,\n",
       "           7.0306e-02, 1.9827e-02],\n",
       "          [9.7930e-01, 3.5487e-05, 4.8758e-06,  ..., 9.4200e-04,\n",
       "           6.6714e-05, 1.8862e-02],\n",
       "          [9.7347e-01, 3.4366e-05, 7.1932e-06,  ..., 4.1210e-04,\n",
       "           1.3290e-02, 1.1172e-02]],\n",
       "\n",
       "         [[7.2436e-02, 3.0225e-03, 7.9411e-03,  ..., 1.6730e-03,\n",
       "           5.4893e-01, 1.7056e-02],\n",
       "          [4.8579e-01, 5.3804e-03, 1.5579e-01,  ..., 3.1927e-03,\n",
       "           1.1046e-01, 5.8609e-02],\n",
       "          [4.6270e-01, 5.8253e-03, 4.7220e-02,  ..., 2.2865e-04,\n",
       "           2.9349e-01, 9.7173e-03],\n",
       "          ...,\n",
       "          [3.6107e-02, 8.5229e-04, 4.3066e-04,  ..., 3.7324e-02,\n",
       "           6.0604e-01, 4.6682e-02],\n",
       "          [8.5592e-02, 2.3103e-04, 7.1280e-04,  ..., 5.5399e-03,\n",
       "           2.9492e-02, 9.4832e-02],\n",
       "          [1.1747e-01, 1.0584e-03, 4.3935e-03,  ..., 1.9878e-02,\n",
       "           5.4805e-01, 1.6456e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[8.2372e-05, 8.9129e-07, 3.6174e-04,  ..., 3.6380e-06,\n",
       "           7.5265e-03, 1.1483e-05],\n",
       "          [8.9507e-05, 1.2459e-07, 1.1963e-04,  ..., 7.4922e-06,\n",
       "           6.1754e-03, 6.0160e-06],\n",
       "          [2.9030e-04, 4.7784e-07, 6.0286e-05,  ..., 7.2459e-06,\n",
       "           2.9888e-02, 1.5363e-05],\n",
       "          ...,\n",
       "          [5.9722e-04, 1.2442e-07, 2.8855e-05,  ..., 1.3414e-06,\n",
       "           1.0626e-02, 4.4175e-05],\n",
       "          [8.7006e-03, 1.3099e-03, 2.5480e-04,  ..., 5.6023e-04,\n",
       "           4.5474e-02, 9.3244e-01],\n",
       "          [1.1531e-03, 6.4739e-08, 9.8981e-06,  ..., 1.1441e-06,\n",
       "           1.7959e-04, 1.3193e-05]],\n",
       "\n",
       "         [[1.0498e-01, 1.0235e-02, 2.1358e-02,  ..., 6.0830e-03,\n",
       "           4.6930e-01, 7.5042e-02],\n",
       "          [3.9679e-03, 1.0620e-01, 2.3806e-03,  ..., 3.3181e-04,\n",
       "           6.3525e-04, 3.5194e-03],\n",
       "          [2.7338e-01, 3.0510e-02, 1.4469e-01,  ..., 1.1511e-03,\n",
       "           1.3267e-02, 8.9412e-02],\n",
       "          ...,\n",
       "          [7.1136e-01, 2.2994e-02, 6.5854e-03,  ..., 1.1153e-02,\n",
       "           5.7810e-04, 2.8932e-02],\n",
       "          [2.6554e-01, 4.5283e-04, 1.8331e-03,  ..., 4.0905e-06,\n",
       "           7.0427e-01, 1.6419e-02],\n",
       "          [1.0025e-01, 6.5192e-02, 7.9702e-02,  ..., 2.5254e-02,\n",
       "           3.3830e-02, 4.7814e-02]],\n",
       "\n",
       "         [[4.2980e-02, 1.8962e-03, 8.9340e-03,  ..., 1.5826e-01,\n",
       "           3.5686e-01, 5.2366e-02],\n",
       "          [1.1773e-01, 1.2594e-02, 9.5909e-02,  ..., 2.0207e-02,\n",
       "           1.4717e-01, 3.5009e-02],\n",
       "          [4.2065e-01, 1.7078e-02, 1.0616e-01,  ..., 1.6684e-02,\n",
       "           1.0265e-01, 2.1390e-02],\n",
       "          ...,\n",
       "          [6.1337e-01, 1.7097e-02, 1.5940e-02,  ..., 4.3057e-02,\n",
       "           1.9773e-02, 4.1893e-02],\n",
       "          [9.9285e-02, 2.4303e-03, 8.8346e-04,  ..., 5.9355e-03,\n",
       "           2.4092e-02, 5.8607e-01],\n",
       "          [4.4551e-01, 2.2308e-02, 1.4880e-02,  ..., 7.3149e-03,\n",
       "           1.7294e-02, 1.5599e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.2863e-02, 6.4217e-05, 4.5507e-05,  ..., 1.8683e-04,\n",
       "           6.3298e-01, 1.2759e-01],\n",
       "          [2.3136e-02, 8.8644e-03, 2.5632e-04,  ..., 7.2914e-04,\n",
       "           6.0650e-02, 8.8647e-01],\n",
       "          [1.7834e-02, 1.0817e-02, 1.4449e-03,  ..., 2.1639e-04,\n",
       "           3.0644e-01, 6.4963e-01],\n",
       "          ...,\n",
       "          [1.5290e-02, 4.1846e-05, 2.3626e-06,  ..., 2.1535e-03,\n",
       "           7.0525e-02, 5.8428e-01],\n",
       "          [9.6615e-03, 2.1084e-05, 2.1507e-05,  ..., 1.6971e-03,\n",
       "           7.5326e-01, 2.4264e-02],\n",
       "          [3.5145e-02, 7.2135e-03, 3.8568e-03,  ..., 1.7376e-02,\n",
       "           2.8011e-01, 3.1820e-01]],\n",
       "\n",
       "         [[8.1822e-05, 8.5107e-10, 5.3673e-09,  ..., 3.5874e-09,\n",
       "           9.9949e-01, 5.3949e-05],\n",
       "          [1.5973e-02, 1.6840e-03, 1.1781e-04,  ..., 6.6969e-05,\n",
       "           6.5245e-01, 3.2356e-01],\n",
       "          [1.6554e-02, 6.5687e-03, 9.5225e-04,  ..., 7.5669e-05,\n",
       "           2.1707e-01, 7.5337e-01],\n",
       "          ...,\n",
       "          [9.1676e-03, 1.0796e-05, 3.7781e-06,  ..., 1.6993e-04,\n",
       "           6.0009e-01, 3.8462e-01],\n",
       "          [1.7382e-04, 1.7220e-07, 4.2817e-07,  ..., 1.1991e-05,\n",
       "           9.9848e-01, 4.5626e-04],\n",
       "          [3.6607e-03, 5.3300e-05, 4.6995e-05,  ..., 1.0043e-04,\n",
       "           9.5995e-01, 1.5510e-02]],\n",
       "\n",
       "         [[6.3754e-03, 2.1782e-04, 6.9676e-04,  ..., 8.0258e-06,\n",
       "           8.1839e-01, 1.0609e-02],\n",
       "          [5.4439e-02, 6.6361e-02, 3.2896e-04,  ..., 5.4564e-06,\n",
       "           2.8974e-02, 7.7314e-01],\n",
       "          [5.7461e-03, 6.5730e-02, 1.6923e-02,  ..., 9.1503e-06,\n",
       "           7.1893e-01, 1.8580e-01],\n",
       "          ...,\n",
       "          [4.1770e-07, 7.7157e-10, 5.0672e-12,  ..., 6.0499e-05,\n",
       "           5.0817e-04, 9.0369e-07],\n",
       "          [2.3039e-04, 5.3308e-08, 5.6908e-08,  ..., 1.0543e-04,\n",
       "           9.3790e-01, 1.2911e-05],\n",
       "          [6.5531e-03, 1.7044e-03, 2.2429e-02,  ..., 2.4108e-02,\n",
       "           8.3498e-01, 4.6594e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.4869e-04, 2.4595e-07, 2.0038e-08,  ..., 2.0300e-07,\n",
       "           8.3767e-01, 4.4898e-05],\n",
       "          [1.0122e-01, 2.3094e-02, 4.4665e-04,  ..., 6.7337e-05,\n",
       "           5.6094e-02, 1.1227e-01],\n",
       "          [1.0234e-01, 3.3134e-02, 1.3625e-02,  ..., 2.3071e-04,\n",
       "           4.3069e-01, 1.4656e-01],\n",
       "          ...,\n",
       "          [2.1043e-03, 2.5345e-06, 3.0016e-08,  ..., 1.6063e-04,\n",
       "           3.3927e-02, 4.7133e-04],\n",
       "          [1.7839e-05, 1.2890e-06, 2.3028e-07,  ..., 2.4427e-05,\n",
       "           3.4051e-02, 6.8373e-05],\n",
       "          [7.6518e-03, 6.2825e-04, 7.6286e-04,  ..., 2.4172e-03,\n",
       "           3.8772e-01, 3.4522e-02]],\n",
       "\n",
       "         [[1.2339e-03, 1.8898e-04, 8.2466e-05,  ..., 3.8022e-04,\n",
       "           3.5060e-01, 1.0436e-02],\n",
       "          [8.0887e-03, 5.1839e-02, 8.4938e-02,  ..., 2.6665e-03,\n",
       "           2.7837e-01, 5.5292e-01],\n",
       "          [3.3467e-03, 2.0341e-03, 5.0800e-02,  ..., 2.4831e-04,\n",
       "           1.9260e-02, 8.5810e-01],\n",
       "          ...,\n",
       "          [4.7567e-04, 9.8849e-05, 4.0948e-05,  ..., 1.8111e-01,\n",
       "           6.4628e-01, 1.4566e-01],\n",
       "          [1.2617e-02, 2.8203e-03, 8.2283e-03,  ..., 1.6849e-01,\n",
       "           2.2133e-01, 3.9817e-01],\n",
       "          [4.9537e-02, 1.3014e-02, 1.1907e-02,  ..., 7.3457e-03,\n",
       "           2.2492e-01, 2.5202e-01]],\n",
       "\n",
       "         [[5.2148e-05, 3.8528e-09, 8.4469e-09,  ..., 4.2165e-07,\n",
       "           9.9087e-01, 2.2708e-05],\n",
       "          [6.8829e-05, 1.8265e-05, 1.1231e-04,  ..., 3.8850e-06,\n",
       "           9.9301e-01, 6.5561e-03],\n",
       "          [9.9724e-06, 5.0879e-07, 1.8905e-03,  ..., 7.9299e-09,\n",
       "           1.4314e-01, 7.7065e-01],\n",
       "          ...,\n",
       "          [5.1484e-09, 4.1997e-11, 5.9081e-11,  ..., 8.2932e-04,\n",
       "           9.8949e-01, 8.9579e-03],\n",
       "          [2.8823e-07, 2.9684e-11, 1.0667e-10,  ..., 2.3851e-08,\n",
       "           1.1862e-01, 8.8136e-01],\n",
       "          [7.8838e-02, 3.8704e-04, 2.1461e-04,  ..., 1.7156e-04,\n",
       "           2.4432e-01, 4.3747e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[3.3376e-02, 1.2997e-05, 2.0217e-03,  ..., 1.0276e-04,\n",
       "           9.5132e-01, 8.7554e-03],\n",
       "          [6.9912e-02, 3.1086e-05, 1.6757e-02,  ..., 1.1323e-04,\n",
       "           8.7177e-01, 3.6929e-02],\n",
       "          [5.2893e-02, 2.4645e-05, 1.3960e-02,  ..., 3.4696e-04,\n",
       "           8.9831e-01, 1.9358e-02],\n",
       "          ...,\n",
       "          [5.0593e-02, 7.8591e-06, 4.3586e-03,  ..., 4.4215e-04,\n",
       "           9.1461e-01, 2.6288e-02],\n",
       "          [5.3999e-02, 3.5210e-04, 8.3446e-03,  ..., 9.0901e-04,\n",
       "           8.9215e-01, 1.7195e-02],\n",
       "          [4.8373e-02, 5.3651e-05, 5.6925e-03,  ..., 3.3125e-04,\n",
       "           9.1608e-01, 1.7486e-02]],\n",
       "\n",
       "         [[1.9474e-01, 3.6305e-05, 5.2411e-03,  ..., 6.0044e-05,\n",
       "           7.6440e-01, 2.5268e-02],\n",
       "          [3.7254e-02, 3.8121e-05, 3.9001e-04,  ..., 2.2266e-04,\n",
       "           9.4746e-01, 1.0236e-02],\n",
       "          [1.4702e-01, 7.1843e-05, 4.5785e-02,  ..., 2.0839e-04,\n",
       "           7.0856e-01, 5.1018e-02],\n",
       "          ...,\n",
       "          [7.5420e-02, 4.1289e-04, 3.9180e-03,  ..., 4.5965e-02,\n",
       "           8.0609e-01, 3.7598e-02],\n",
       "          [1.4696e-01, 4.8979e-04, 1.4065e-02,  ..., 3.8252e-04,\n",
       "           7.6317e-01, 5.0900e-02],\n",
       "          [8.6090e-02, 6.1645e-05, 7.0606e-03,  ..., 1.0775e-04,\n",
       "           8.4523e-01, 4.6911e-02]],\n",
       "\n",
       "         [[1.3078e-01, 5.5019e-04, 2.6213e-03,  ..., 1.5912e-03,\n",
       "           7.1313e-01, 1.2131e-01],\n",
       "          [8.7138e-02, 2.1711e-04, 2.9813e-03,  ..., 9.1122e-04,\n",
       "           8.3126e-01, 6.7453e-02],\n",
       "          [1.2702e-01, 9.2604e-04, 8.6325e-03,  ..., 5.2788e-03,\n",
       "           6.2676e-01, 1.7081e-01],\n",
       "          ...,\n",
       "          [5.7951e-02, 1.8451e-04, 1.4192e-03,  ..., 2.9669e-03,\n",
       "           8.7912e-01, 4.9202e-02],\n",
       "          [1.2453e-01, 3.1800e-03, 7.5898e-03,  ..., 3.6005e-03,\n",
       "           6.1619e-01, 1.8918e-01],\n",
       "          [1.3307e-01, 1.9598e-03, 7.3549e-03,  ..., 3.3894e-03,\n",
       "           6.1665e-01, 1.7555e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3.0748e-02, 3.5477e-07, 8.4843e-05,  ..., 3.7481e-06,\n",
       "           9.6682e-01, 2.0405e-03],\n",
       "          [6.8901e-02, 2.1078e-05, 3.0160e-04,  ..., 4.9988e-04,\n",
       "           9.1219e-01, 7.5782e-03],\n",
       "          [9.9433e-02, 7.7722e-06, 2.1515e-03,  ..., 1.9678e-04,\n",
       "           8.7345e-01, 1.7185e-02],\n",
       "          ...,\n",
       "          [8.7828e-02, 1.2361e-05, 3.5630e-04,  ..., 1.3353e-03,\n",
       "           8.9356e-01, 1.0834e-02],\n",
       "          [4.9007e-02, 4.5044e-06, 4.3426e-04,  ..., 3.3731e-05,\n",
       "           9.4338e-01, 5.8470e-03],\n",
       "          [5.4941e-02, 3.3066e-06, 4.8205e-04,  ..., 5.0866e-05,\n",
       "           9.3229e-01, 9.9083e-03]],\n",
       "\n",
       "         [[2.0965e-02, 2.8212e-05, 5.9912e-04,  ..., 9.2821e-04,\n",
       "           1.5160e-01, 4.2453e-03],\n",
       "          [8.7337e-03, 1.3175e-06, 3.5860e-05,  ..., 3.4059e-04,\n",
       "           2.3044e-01, 1.0479e-03],\n",
       "          [3.8164e-02, 2.4054e-05, 1.0091e-03,  ..., 2.3017e-03,\n",
       "           3.1530e-01, 1.1526e-02],\n",
       "          ...,\n",
       "          [3.0845e-02, 2.4512e-05, 6.0621e-04,  ..., 5.0858e-03,\n",
       "           2.3414e-01, 5.9986e-03],\n",
       "          [5.6022e-02, 1.9221e-03, 4.3016e-03,  ..., 1.2763e-02,\n",
       "           2.1727e-01, 2.1088e-02],\n",
       "          [5.1396e-02, 1.5708e-04, 2.2593e-03,  ..., 3.4339e-03,\n",
       "           3.9055e-01, 1.6201e-02]],\n",
       "\n",
       "         [[5.1177e-02, 3.1880e-04, 1.9514e-03,  ..., 6.6268e-04,\n",
       "           6.7788e-01, 3.4501e-02],\n",
       "          [4.4674e-03, 1.5229e-04, 9.7047e-05,  ..., 2.3864e-04,\n",
       "           3.0969e-02, 2.0798e-03],\n",
       "          [7.8329e-02, 1.1210e-02, 2.5090e-02,  ..., 8.1026e-03,\n",
       "           3.9648e-01, 5.7364e-02],\n",
       "          ...,\n",
       "          [2.3221e-03, 5.7585e-05, 6.0563e-05,  ..., 9.0936e-04,\n",
       "           1.2383e-02, 7.3038e-04],\n",
       "          [7.2520e-02, 1.2036e-02, 1.0298e-02,  ..., 1.0684e-02,\n",
       "           2.7570e-01, 6.2241e-02],\n",
       "          [6.2298e-02, 1.3284e-03, 4.2407e-03,  ..., 3.3498e-03,\n",
       "           3.0764e-01, 4.2640e-02]]]], grad_fn=<SoftmaxBackward0>)))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "41b16cda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([1, 8, 22, 22]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.attentions), outputs.attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "20dc229f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 22, 512)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.hidden_states), len(outputs.hidden_states[0]), len(outputs.hidden_states[0][0]), len(outputs.hidden_states[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "81e11ff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 8, 22, 22)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.attentions), len(outputs.attentions[-1]), len(outputs.attentions[-1][0]), len(outputs.attentions[-1][0][0]), len(outputs.attentions[-1][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e8832579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 22, 22])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(outputs.attentions[-1], dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1f0963c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'hidden_states', 'attentions'])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "49e46cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.3226e-01, 1.7927e-03, 2.3589e-02, 1.0825e-02, 5.1292e-03, 7.8609e-03,\n",
       "         1.9151e-04, 2.4061e-03, 1.6319e-01, 3.0710e-02, 5.1223e-03, 1.5187e-02,\n",
       "         4.1093e-03, 2.5076e-04, 2.5608e-03, 3.8680e-04, 5.2220e-05, 7.2891e-04,\n",
       "         6.6621e-04, 1.4668e-02, 4.6547e-01, 1.1284e-01],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor(1.0000, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[-1][0][0][7], sum(outputs.attentions[-1][0][0][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f2e34083",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.3376e-02, 1.2997e-05, 2.0217e-03,  ..., 1.0276e-04,\n",
       "          9.5132e-01, 8.7554e-03],\n",
       "         [6.9912e-02, 3.1086e-05, 1.6757e-02,  ..., 1.1323e-04,\n",
       "          8.7177e-01, 3.6929e-02],\n",
       "         [5.2893e-02, 2.4645e-05, 1.3960e-02,  ..., 3.4696e-04,\n",
       "          8.9831e-01, 1.9358e-02],\n",
       "         ...,\n",
       "         [5.0593e-02, 7.8591e-06, 4.3586e-03,  ..., 4.4215e-04,\n",
       "          9.1461e-01, 2.6288e-02],\n",
       "         [5.3999e-02, 3.5210e-04, 8.3446e-03,  ..., 9.0901e-04,\n",
       "          8.9215e-01, 1.7195e-02],\n",
       "         [4.8373e-02, 5.3651e-05, 5.6925e-03,  ..., 3.3125e-04,\n",
       "          9.1608e-01, 1.7486e-02]],\n",
       "\n",
       "        [[1.9474e-01, 3.6305e-05, 5.2411e-03,  ..., 6.0044e-05,\n",
       "          7.6440e-01, 2.5268e-02],\n",
       "         [3.7254e-02, 3.8121e-05, 3.9001e-04,  ..., 2.2266e-04,\n",
       "          9.4746e-01, 1.0236e-02],\n",
       "         [1.4702e-01, 7.1843e-05, 4.5785e-02,  ..., 2.0839e-04,\n",
       "          7.0856e-01, 5.1018e-02],\n",
       "         ...,\n",
       "         [7.5420e-02, 4.1289e-04, 3.9180e-03,  ..., 4.5965e-02,\n",
       "          8.0609e-01, 3.7598e-02],\n",
       "         [1.4696e-01, 4.8979e-04, 1.4065e-02,  ..., 3.8252e-04,\n",
       "          7.6317e-01, 5.0900e-02],\n",
       "         [8.6090e-02, 6.1645e-05, 7.0606e-03,  ..., 1.0775e-04,\n",
       "          8.4523e-01, 4.6911e-02]],\n",
       "\n",
       "        [[1.3078e-01, 5.5019e-04, 2.6213e-03,  ..., 1.5912e-03,\n",
       "          7.1313e-01, 1.2131e-01],\n",
       "         [8.7138e-02, 2.1711e-04, 2.9813e-03,  ..., 9.1122e-04,\n",
       "          8.3126e-01, 6.7453e-02],\n",
       "         [1.2702e-01, 9.2604e-04, 8.6325e-03,  ..., 5.2788e-03,\n",
       "          6.2676e-01, 1.7081e-01],\n",
       "         ...,\n",
       "         [5.7951e-02, 1.8451e-04, 1.4192e-03,  ..., 2.9669e-03,\n",
       "          8.7912e-01, 4.9202e-02],\n",
       "         [1.2453e-01, 3.1800e-03, 7.5898e-03,  ..., 3.6005e-03,\n",
       "          6.1619e-01, 1.8918e-01],\n",
       "         [1.3307e-01, 1.9598e-03, 7.3549e-03,  ..., 3.3894e-03,\n",
       "          6.1665e-01, 1.7555e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3.0748e-02, 3.5477e-07, 8.4843e-05,  ..., 3.7481e-06,\n",
       "          9.6682e-01, 2.0405e-03],\n",
       "         [6.8901e-02, 2.1078e-05, 3.0160e-04,  ..., 4.9988e-04,\n",
       "          9.1219e-01, 7.5782e-03],\n",
       "         [9.9433e-02, 7.7722e-06, 2.1515e-03,  ..., 1.9678e-04,\n",
       "          8.7345e-01, 1.7185e-02],\n",
       "         ...,\n",
       "         [8.7828e-02, 1.2361e-05, 3.5630e-04,  ..., 1.3353e-03,\n",
       "          8.9356e-01, 1.0834e-02],\n",
       "         [4.9007e-02, 4.5044e-06, 4.3426e-04,  ..., 3.3731e-05,\n",
       "          9.4338e-01, 5.8470e-03],\n",
       "         [5.4941e-02, 3.3066e-06, 4.8205e-04,  ..., 5.0866e-05,\n",
       "          9.3229e-01, 9.9083e-03]],\n",
       "\n",
       "        [[2.0965e-02, 2.8212e-05, 5.9912e-04,  ..., 9.2821e-04,\n",
       "          1.5160e-01, 4.2453e-03],\n",
       "         [8.7337e-03, 1.3175e-06, 3.5860e-05,  ..., 3.4059e-04,\n",
       "          2.3044e-01, 1.0479e-03],\n",
       "         [3.8164e-02, 2.4054e-05, 1.0091e-03,  ..., 2.3017e-03,\n",
       "          3.1530e-01, 1.1526e-02],\n",
       "         ...,\n",
       "         [3.0845e-02, 2.4512e-05, 6.0621e-04,  ..., 5.0858e-03,\n",
       "          2.3414e-01, 5.9986e-03],\n",
       "         [5.6022e-02, 1.9221e-03, 4.3016e-03,  ..., 1.2763e-02,\n",
       "          2.1727e-01, 2.1088e-02],\n",
       "         [5.1396e-02, 1.5708e-04, 2.2593e-03,  ..., 3.4339e-03,\n",
       "          3.9055e-01, 1.6201e-02]],\n",
       "\n",
       "        [[5.1177e-02, 3.1880e-04, 1.9514e-03,  ..., 6.6268e-04,\n",
       "          6.7788e-01, 3.4501e-02],\n",
       "         [4.4674e-03, 1.5229e-04, 9.7047e-05,  ..., 2.3864e-04,\n",
       "          3.0969e-02, 2.0798e-03],\n",
       "         [7.8329e-02, 1.1210e-02, 2.5090e-02,  ..., 8.1026e-03,\n",
       "          3.9648e-01, 5.7364e-02],\n",
       "         ...,\n",
       "         [2.3221e-03, 5.7585e-05, 6.0563e-05,  ..., 9.0936e-04,\n",
       "          1.2383e-02, 7.3038e-04],\n",
       "         [7.2520e-02, 1.2036e-02, 1.0298e-02,  ..., 1.0684e-02,\n",
       "          2.7570e-01, 6.2241e-02],\n",
       "         [6.2298e-02, 1.3284e-03, 4.2407e-03,  ..., 3.3498e-03,\n",
       "          3.0764e-01, 4.2640e-02]]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6f6603b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 22, 22])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[-1][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c9af877f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([4.6547e-01, 1.6319e-01, 1.3226e-01, 1.1284e-01, 3.0710e-02, 2.3589e-02,\n",
       "        1.5187e-02, 1.4668e-02, 1.0825e-02, 7.8609e-03, 5.1292e-03, 5.1223e-03,\n",
       "        4.1093e-03, 2.5608e-03, 2.4061e-03, 1.7927e-03, 7.2891e-04, 6.6621e-04,\n",
       "        3.8680e-04, 2.5076e-04, 1.9151e-04, 5.2220e-05],\n",
       "       grad_fn=<SortBackward0>),\n",
       "indices=tensor([20,  8,  0, 21,  9,  2, 11, 19,  3,  5,  4, 10, 12, 14,  7,  1, 17, 18,\n",
       "        15, 13,  6, 16]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[-1][0][0][7].sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "bbc6fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_metrics = outputs.attentions[-1][0]\n",
    "att_sum = list(map(sum, att_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "16e02d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20,  4,  0,  7,  8, 21, 17,  9, 12,  2, 19,  5, 11,  6,  3, 18, 15, 14,\n",
       "        10,  1, 16, 13])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(att_sum).sort(descending=True).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bebdf407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([1.1546e+02, 1.5023e+01, 1.2315e+01, 9.2965e+00, 8.4022e+00, 6.5998e+00,\n",
       "        1.5970e+00, 1.0318e+00, 9.0482e-01, 8.5423e-01, 7.5215e-01, 6.3873e-01,\n",
       "        6.3835e-01, 6.2507e-01, 6.0779e-01, 4.9820e-01, 2.1790e-01, 2.1514e-01,\n",
       "        1.2704e-01, 8.1850e-02, 6.8447e-02, 4.1771e-02],\n",
       "       grad_fn=<SortBackward0>),\n",
       "indices=tensor([20,  4,  0,  7,  8, 21, 17,  9, 12,  2, 19,  5, 11,  6,  3, 18, 15, 14,\n",
       "        10,  1, 16, 13]))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(att_sum).sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5d3baeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1012) tensor(7038) tensor(18923) tensor(1010) tensor(1998)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('.', 'p o u n d s', 'a p p e t i t e', ',', 'a n d')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs[0][12], inputs[0][11], inputs[0][5], inputs[0][6], inputs[0][7])\n",
    "tokenizer.decode(1012), tokenizer.decode(7038), tokenizer.decode(18923), tokenizer.decode(1010), tokenizer.decode(1998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "50c008a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1012)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fd7adf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1012) tensor(12863) tensor(2008) tensor(2572) tensor(1045)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('.', '# # g i c', 't h a t', 'a m', 'i')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs[0][20], inputs[0][8], inputs[0][9], inputs[0][2], inputs[0][13])\n",
    "tokenizer.decode(1012), tokenizer.decode(12863), tokenizer.decode(2008), tokenizer.decode(2572), tokenizer.decode(1045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "46776543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_att_toks(input_text, num_words):\n",
    "    input_text = input_text.replace(\"'m\", \" am\").replace('.', ' ').replace(',', ' ')\n",
    "    print(input_text)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors='pt').to(training_config.device)\n",
    "    outputs = model(inputs)  # Run model\n",
    "    attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "    att_metrics = outputs.attentions[-1][0]\n",
    "    # print(f'att_metric: {len(att_metrics[-1])}')\n",
    "    att_sum = list(map(sum, att_metrics))\n",
    "    # print(f'att_sum: {len(att_sum[0])}')\n",
    "    sorted_att = sum(att_sum).sort(descending=True)\n",
    "    \n",
    "    cnt = 0 \n",
    "    tok_idx = []\n",
    "    for idx in range(len(inputs[0])):\n",
    "        if inputs[0][sorted_att.indices[idx]] == 101 or inputs[0][sorted_att.indices[idx]] == 102:\n",
    "            continue\n",
    "        tok_idx.append(sorted_att.indices[idx])\n",
    "        cnt += 1\n",
    "        if cnt == num_words:\n",
    "            break \n",
    "    \n",
    "    tok_list = [tokenizer.decode(inputs[0][int(tok)]) for tok in tok_idx]\n",
    "    return tok_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e12cd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These days I feel like I am too worthless and I want to die \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['w o r t h l e s s',\n",
       " 'w a n t',\n",
       " 't o',\n",
       " 'd i e',\n",
       " 't o o',\n",
       " 'i',\n",
       " 'a n d',\n",
       " 'a m',\n",
       " 'i',\n",
       " 'f e e l',\n",
       " 'i',\n",
       " 't h e s e',\n",
       " 'd a y s',\n",
       " 'l i k e']"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"These days,I feel like I'm too worthless and I want to die.\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt').to(training_config.device)\n",
    "get_att_toks(input_text, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf2e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
