{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c9dbf2",
   "metadata": {},
   "source": [
    "### 1. Environment Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e256a",
   "metadata": {},
   "source": [
    "#### 1.1 Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e218b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import pymysql\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "from attrdict import AttrDict\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertConfig, BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401885e",
   "metadata": {},
   "source": [
    "#### 1.2 Setting Default Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631d1c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cori/AuD/model1-2/src\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2275e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/cori/AuD/model1-2/data\"\n",
    "base_model_path = \"/home/cori/AuD/base-model\"\n",
    "save_model_path = \"/home/cori/AuD/model1-2/model\"\n",
    "config_path = \"/home/cori/AuD/model1-2/config\"\n",
    "log_path = \"/home/cori/AuD/model1-2/log\"\n",
    "config_file = \"bert-base.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f1b19",
   "metadata": {},
   "source": [
    "#### 1.3 Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5c443246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '우울',\n",
       " 1: '무기력',\n",
       " 2: '급격한 체중(식욕)변화',\n",
       " 3: '수면장애',\n",
       " 4: '정서불안',\n",
       " 5: '피로',\n",
       " 6: '과도한 죄책감 및 무가치함',\n",
       " 7: '인지기능저하',\n",
       " 8: '자살충동',\n",
       " 9: '일상'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = dict()\n",
    "\n",
    "label[0] = '우울'\n",
    "label[1] = '무기력'\n",
    "label[2] = '급격한 체중(식욕)변화'\n",
    "label[3] = '수면장애'\n",
    "label[4] = '정서불안'\n",
    "label[5] = '피로'\n",
    "label[6] = '과도한 죄책감 및 무가치함'\n",
    "label[7] = '인지기능저하'\n",
    "label[8] = '자살충동'\n",
    "label[9] = '일상'\n",
    "label"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb8b605d",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "dsm_data = pd.read_csv(os.path.join(data_path, 'dsm_data.csv'))\n",
    "dsm_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "895a8f6b",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# dsm_sample: label_10, dsm_sample2: label_9\n",
    "dsm_sample = pd.read_csv(os.path.join(data_path, 'dsm_sample2.csv'))\n",
    "dsm_sample.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71a0a79b",
   "metadata": {},
   "source": [
    "dsm_data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5ac7d45",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "dsm_data[dsm_data.label==8]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f252e26e",
   "metadata": {},
   "source": [
    "dsm_sample = dsm_data.copy()\n",
    "dsm = []\n",
    "\n",
    "dsm.extend(dsm_sample[dsm_sample.label==0].sample(40000).index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==1].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==2].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==3].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==4].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==5].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==6].sample(20000).index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==7].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==8].sample(20000).index.tolist())\n",
    "\n",
    "len(dsm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "322a9e15",
   "metadata": {},
   "source": [
    "dsm_sample = dsm_sample.loc[dsm]\n",
    "dsm_sample.to_csv(os.path.join(data_path, 'dsm_sample2.csv'), index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e25f123",
   "metadata": {},
   "source": [
    "X_train, X_test = train_test_split(dsm_sample, test_size=0.2, random_state=42, stratify=dsm_sample['label'])\n",
    "X_train, X_dev = train_test_split(X_train, test_size=0.2, random_state=42, stratify=X_train['label'])\n",
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "032bf234",
   "metadata": {},
   "source": [
    "X_train.groupby('label').count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e465582",
   "metadata": {},
   "source": [
    "X_train.to_csv(os.path.join(data_path, 'dsm_samp2_train.csv'), index=False)\n",
    "X_dev.to_csv(os.path.join(data_path, 'dsm_samp2_val.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(data_path, 'dsm_samp2_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671f6c4",
   "metadata": {},
   "source": [
    "#### 1.4 Load Pretrained model & tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bbf96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.join(data_path, 'dsm_samp_train.csv'))\n",
    "X_dev = pd.read_csv(os.path.join(data_path, 'dsm_samp_val.csv'))\n",
    "X_test = pd.read_csv(os.path.join(data_path, 'dsm_samp_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61d2504b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63580, 15895, 19869)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f93bf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 6, 7, 2, 0, 1, 3, 5, 4])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce43a043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우울\n",
      "무기력\n",
      "급격한 체중(식욕)변화\n",
      "수면장애\n",
      "정서불안\n",
      "피로\n",
      "과도한 죄책감 및 무가치함\n",
      "인지기능저하\n",
      "자살충동\n",
      "일상\n"
     ]
    }
   ],
   "source": [
    "for i, name in label.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cec384fe",
   "metadata": {},
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=10, output_hidden_states=True)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88a0b9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cori/AuD/base-model/bert-base'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(base_model_path, 'bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec85e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/cori/AuD/base-model/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/cori/AuD/base-model/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(base_model_path, 'bert-base'), model_max_length=128)\n",
    "config = BertConfig.from_pretrained(os.path.join(base_model_path, 'bert-base', 'bert_config.json'), num_labels=10)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(base_model_path, 'bert-base'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "562b48c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 768)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.attention_probs_dropout_prob, config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ee345",
   "metadata": {},
   "source": [
    "#### 1.5 setting training args & config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e440926",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, 'training_config.json')) as f:\n",
    "    training_config = AttrDict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "affe617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5401389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'default_path': '../', 'data_path': 'data', 'log_path': 'log', 'model_path': 'model', 'config_path': 'config', 'seed': 42, 'train_batch_size': 8, 'device': device(type='cuda'), 'eval_batch_size': 8, 'num_epochs': 500, 'gradient_accumulation_steps': 1, 'warmup_proportion': 0, 'adam_epsilon': 1e-08, 'learning_rate': 5e-05, 'do_lower_case': False, 'no_cuda': False, 'max_steps': -1, 'logging_steps': 100})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bdf7ea26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-05"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf4e57f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(training_config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c79e9",
   "metadata": {},
   "source": [
    "### 2. Define Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2e338dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.pad = 'max_length'\n",
    "training_config.num_epochs  = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd385338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = data_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.label)\n",
    "    \n",
    "    def reset_index(self):\n",
    "        self.data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # def clear_text(self)  => 전처리 코드를 여기에 넣을 경우 상당히 느려짐\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        return text, label\n",
    "        '''\n",
    "        self.reset_index()\n",
    "        text = self.data.text[idx]\n",
    "        label = self.data.label[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2c34513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertProcessor():\n",
    "    def __init__(self, config, training_config, tokenizer, truncation=True):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.max_len = config.max_position_embeddings\n",
    "        self.pad = training_config.pad\n",
    "        self.batch_size = training_config.train_batch_size\n",
    "        self.truncation = truncation\n",
    "    \n",
    "    def convert_data(self, data_file):\n",
    "        context2 = None    # single sentence classification\n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(data_file[idx][0], context2) for idx in range(len(data_file))],   # text, \n",
    "            max_length = self.max_len,\n",
    "            padding = self.pad,\n",
    "            truncation = self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        for i in range(len(data_file)):\n",
    "            inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "            try:\n",
    "                inputs['label'] = data_file[i][1] \n",
    "            except:\n",
    "                inputs['label'] = 0 \n",
    "            features.append(inputs)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "        return dataset\n",
    "    \n",
    "    def convert_sentence(self, sentence_list):   # 사용자 입력 문장 1개 -> 입력 형태 변환\n",
    "        pass\n",
    "    \n",
    "    def shuffle_data(self, dataset, data_type):\n",
    "        if data_type == 'train':\n",
    "            return RandomSampler(dataset)\n",
    "        elif data_type == 'eval' or data_type == 'test':\n",
    "            return SequentialSampler(dataset)\n",
    "        \n",
    "    def load_data(self, dataset, sampler):\n",
    "        return DataLoader(dataset, sampler=sampler, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdecbfd0",
   "metadata": {},
   "source": [
    "class ElectraRegressor(nn.Module):\n",
    "    '''\n",
    "    다중 분류 학습 시 선언하는 클래스 \n",
    "    '''\n",
    "    def __init__(self, electra, config):\n",
    "        # 부모 생성자 초기화, super().__init__(config) 시 오류 발생 \n",
    "        super(ElectraRegressor, self).__init__() \n",
    "        self.electra = electra\n",
    "        self.layer = nn.Linear(config.hidden_size, 128)\n",
    "        self.regressor = nn.Sequential(nn.Dropout(0.1), nn.Linear(128, 6))\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.electra(input_ids=input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids)\n",
    "        logits = outputs.last_hidden_state[:, 0, :]\n",
    "        output = self.layer(logits)\n",
    "        output = self.regressor(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89a0759c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'default_path': '../', 'data_path': 'data', 'log_path': 'log', 'model_path': 'model', 'config_path': 'config', 'seed': 42, 'train_batch_size': 8, 'device': device(type='cuda'), 'eval_batch_size': 8, 'num_epochs': 500, 'gradient_accumulation_steps': 1, 'warmup_proportion': 0, 'adam_epsilon': 1e-08, 'learning_rate': 5e-05, 'do_lower_case': False, 'no_cuda': False, 'max_steps': -1, 'logging_steps': 100, 'pad': 'max_length'})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config.num_epochs\n",
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2e2c3620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "796c4093",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.save_model_path = \"/home/cori/AuD/model1-2/model\"\n",
    "training_config.log_path = \"/home/cori/AuD/model1-2/log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a21c43d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cori/AuD/model1-2/model'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d8cb7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainer():\n",
    "    def __init__(self, config, training_config, model, train_dataloader, eval_dataloader, label, model_name):\n",
    "        self.config = config\n",
    "        self.training_config = training_config\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.eval_dataloader = eval_dataloader\n",
    "        self.label = label\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def set_seed(self):\n",
    "        random.seed(self.training_config.seed)\n",
    "        np.random.seed(self.training_config.seed)\n",
    "        torch.manual_seed(self.training_config.seed)\n",
    "        if not self.training_config.no_cuda and torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(self.training_config.seed)\n",
    "    \n",
    "    def train(self):\n",
    "        train_acc_list = []; eval_acc_list = [] \n",
    "        train_loss_list = []; eval_loss_list = []\n",
    "        # eval_acc_step = []; eval_loss_step = []\n",
    "        # train_acc_step = []; train_loss_step = []\n",
    "        nb_eval_steps = 0\n",
    "        best_loss = 9999; best_epoch = 0\n",
    "        t_total = len(self.train_dataloader) // self.training_config.gradient_accumulation_steps * self.training_config.num_epochs\n",
    "\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.training_config.learning_rate, eps=self.training_config.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(t_total * self.training_config.warmup_proportion), \\\n",
    "                                                    num_training_steps=t_total)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        for epoch in range(int(self.training_config.num_epochs)):\n",
    "            train_acc = 0.0; eval_acc = 0.0\n",
    "            train_loss = 0.0; eval_loss = 0.0 \n",
    "\n",
    "            for step, batch in enumerate(self.train_dataloader):\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.training_config.device) for t in batch)\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3]\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                # loss = outputs[0]\n",
    "                # y_pred = torch.max(outputs[1], 1)[1]\n",
    "                y_pred = outputs[1]\n",
    "                y_true = batch[3]\n",
    "                # y_true = torch.tensor([float(t) for t in y_true]).to(self.training_config.device)\n",
    "                loss = criterion(y_pred, y_true)\n",
    "                # print(outputs[0], outputs[1], batch[3])\n",
    "                loss.backward()\n",
    "                train_loss += loss.item()\n",
    "                train_acc += self.calc_accuracy(outputs[1], batch[3])\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                self.model.zero_grad()\n",
    "                '''\n",
    "                if step % training_config.logging_steps == 0:\n",
    "                    # print(f'step: {step}, {train_acc / (step + 1)}')\n",
    "                    # print(f'step: {step}, {train_loss / (step + 1)}')\n",
    "                    train_acc_step.append([step, train_acc / (step + 1)])\n",
    "                    train_loss_step.append([step, train_loss / (step + 1)])'''\n",
    "\n",
    "            train_acc = train_acc / (step + 1)\n",
    "            train_loss = train_loss / (step + 1)\n",
    "            print(f'epoch: {epoch}, train_loss: {train_loss}')\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_loss_list.append(train_loss)\n",
    "\n",
    "            for step2, batch2 in enumerate(self.eval_dataloader):\n",
    "                self.model.eval()\n",
    "                batch2 = tuple(t.to(self.training_config.device) for t in batch2)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    inputs = {\n",
    "                        \"input_ids\": batch2[0],\n",
    "                        \"attention_mask\": batch2[1],\n",
    "                        \"token_type_ids\": batch2[2],\n",
    "                        \"labels\": batch2[3]\n",
    "                    }\n",
    "                    outputs = self.model(**inputs)\n",
    "                    tmp_eval_loss, logits = outputs[:2]\n",
    "                    loss2 = criterion(logits, batch2[3])\n",
    "                    eval_loss += loss2.item()              \n",
    "                    # eval_loss += tmp_eval_loss.mean().item()\n",
    "                    eval_acc += self.calc_accuracy(outputs[1], batch2[3]) \n",
    "                    '''\n",
    "                    if step2 % training_config.logging_steps == 0:\n",
    "                        eval_acc_step.append([step2, eval_acc / (step + 1)])\n",
    "                        eval_loss_step.append([step2, eval_loss / (step + 1)])'''\n",
    "            '''            \n",
    "            try:\n",
    "                last_loss = eval_loss_list[-1]\n",
    "            except:\n",
    "                last_loss = 9999\n",
    "            '''\n",
    "            eval_loss = eval_loss / (step2 + 1)\n",
    "            eval_acc = eval_acc / (step2 + 1)\n",
    "            eval_acc_list.append(eval_acc)\n",
    "            eval_loss_list.append(eval_loss)\n",
    "            print(f'epoch: {epoch}, eval_loss: {eval_loss}')\n",
    "            \n",
    "            if eval_loss < best_loss:\n",
    "                best_loss = eval_loss\n",
    "                es = 0\n",
    "                print(f'save best loss state model & log(epoch {epoch + 1})')\n",
    "                self.save_model(os.path.join(self.training_config.save_model_path, label, model_name, f'bert_dsm_{epoch}.pt'))\n",
    "                best_epoch = epoch\n",
    "            else:\n",
    "                es += 1\n",
    "                print(\"Counter {} of 7\".format(es))\n",
    "\n",
    "            if es > 6:\n",
    "                print(\"Early stopping with best_loss: \", best_loss, \"and val_loss for this epoch: \", eval_loss, \"...\")\n",
    "                break\n",
    "                \n",
    "            '''\n",
    "            if eval_loss > last_loss:\n",
    "                trigger_times += 1\n",
    "                print('Trigger Times:', trigger_times)\n",
    "                self.save_model(os.path.join(self.training_config.default_path, self.training_config.model_path, f'bert_bws_{epoch}.pt'))\n",
    "                \n",
    "                if trigger_times > 4:\n",
    "                    print(\"Early stopping !\")\n",
    "                    self.save_model(os.path.join(self.training_config.default_path, self.training_config.model_path, f'bert_bws_best.pt'))\n",
    "                    break\n",
    "            else:\n",
    "                print('trigger times: 0')\n",
    "                trigger_times = 0'''\n",
    "            \n",
    "\n",
    "        self.save_log(train_acc_list, train_loss_list, eval_acc_list, eval_loss_list, epoch)\n",
    "        return train_acc_list, train_loss_list, eval_acc_list, eval_loss_list\n",
    "\n",
    "    def calc_accuracy(self, X,Y):\n",
    "        max_vals, max_indices = torch.max(X, 1)\n",
    "        train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "        return train_acc\n",
    "    \n",
    "    def compute_metrics(self, labels, preds):\n",
    "        assert len(preds) == len(labels)\n",
    "        acc = (labels == preds).mean()\n",
    "        return {\"acc\": acc}\n",
    "    \n",
    "    '''\n",
    "    def save_step_log(self, train_acc_step, train_loss_step, eval_acc_step, eval_loss_step, epoch):\n",
    "        with open(os.path.join(self.training_config.log_path, f'train_step_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_acc_step, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, f'train_step_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_loss_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, f'eval_step_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_acc_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, f'eval_step_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_loss_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "    '''\n",
    "    \n",
    "    def save_log(self, train_acc, train_loss, eval_acc, eval_loss, epoch):\n",
    "        with open(os.path.join(self.training_config.log_path, label, model_name, f'train_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_acc, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, label, model_name, f'train_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_loss, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, label, model_name, f'eval_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_acc, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.log_path, label, model_name, f'eval_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_loss, f, pickle.HIGHEST_PROTOCOL)  \n",
    "    \n",
    "    def save_model(self, model_name):\n",
    "        torch.save(self.model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fbc7d",
   "metadata": {},
   "source": [
    "### 3. Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ca8dfa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'label_10'\n",
    "model_name = 'bert-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7539a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 6, 7, 2, 0, 1, 3, 5, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a820e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = BertDataset(X_train)\n",
    "val_file = BertDataset(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bacfeb4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63580, 15895)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file), len(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "beaac774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.max_position_embeddings = 128\n",
    "config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f4417358",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_processor = BertProcessor(config, training_config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9d4276f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = bert_processor.convert_data(train_file)\n",
    "val_dataset = bert_processor.convert_data(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "986f2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = bert_processor.shuffle_data(train_dataset, 'train')\n",
    "val_sampler = bert_processor.shuffle_data(val_dataset, 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a1baa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = bert_processor.load_data(train_dataset, train_sampler)\n",
    "val_dataloader = bert_processor.load_data(val_dataset, val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bad48641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7948, 1987)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1b972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trainer = BertTrainer(config, training_config, model, train_dataloader, val_dataloader, label, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e9d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamdaco/anaconda3/envs/lamda_base/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.12397779855945944\n",
      "epoch: 0, eval_loss: 0.0788106242013499\n",
      "save best loss state model & log(epoch 1)\n",
      "epoch: 1, train_loss: 0.09275774860022078\n",
      "epoch: 1, eval_loss: 0.03403185696901672\n",
      "save best loss state model & log(epoch 2)\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss, eval_acc, eval_loss = bert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04497f7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = list(range(len(train_loss)))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "# plt.plot(list(range(len(train_loss))), train_loss, label='train_loss')\n",
    "plt.plot(list(range(len(train_loss))), train_loss, label='train_loss')\n",
    "plt.plot(list(range(len(train_loss))), eval_loss, label='val_loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32d280",
   "metadata": {},
   "source": [
    "### 3. Model Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "96dde817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '우울',\n",
       " 1: '무기력',\n",
       " 2: '급격한 체중(식욕)변화',\n",
       " 3: '수면장애',\n",
       " 4: '정서불안',\n",
       " 5: '피로',\n",
       " 6: '과도한 죄책감 및 무가치함',\n",
       " 7: '인지기능저하',\n",
       " 8: '자살충동',\n",
       " 9: '일상'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = dict()\n",
    "\n",
    "label[0] = '우울'\n",
    "label[1] = '무기력'\n",
    "label[2] = '급격한 체중(식욕)변화'\n",
    "label[3] = '수면장애'\n",
    "label[4] = '정서불안'\n",
    "label[5] = '피로'\n",
    "label[6] = '과도한 죄책감 및 무가치함'\n",
    "label[7] = '인지기능저하'\n",
    "label[8] = '자살충동'\n",
    "label[9] = '일상'\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c7803e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132946</td>\n",
       "      <td>Of course I do, but... That's what I've been t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_uzhrj</td>\n",
       "      <td>hurting yourself just leads to so many more pr...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_1f6rlk</td>\n",
       "      <td>as if it never mattered anyways i'll go to sle...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77173</td>\n",
       "      <td>You said you'd know the heat from one Kiki.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_1dzb0x</td>\n",
       "      <td>just because the \"cancer\" tells me i am worthl...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>t3_2s455q</td>\n",
       "      <td>if you view it as a - z, it can be very easy f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19865</th>\n",
       "      <td>43hkav</td>\n",
       "      <td>why the fuck should i be talking about suicide...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>t3_zhku3</td>\n",
       "      <td>it gave me terrible insomnias but it did work ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19867</th>\n",
       "      <td>2ffx1w</td>\n",
       "      <td>i will be very depressed for days or weeks at ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19868</th>\n",
       "      <td>44z67z</td>\n",
       "      <td>i am more busy daydreaming about suicide than ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19869 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text  label\n",
       "0         132946  Of course I do, but... That's what I've been t...      9\n",
       "1       t3_uzhrj  hurting yourself just leads to so many more pr...      8\n",
       "2      t3_1f6rlk  as if it never mattered anyways i'll go to sle...      3\n",
       "3          77173        You said you'd know the heat from one Kiki.      9\n",
       "4      t3_1dzb0x  just because the \"cancer\" tells me i am worthl...      6\n",
       "...          ...                                                ...    ...\n",
       "19864  t3_2s455q  if you view it as a - z, it can be very easy f...      1\n",
       "19865     43hkav  why the fuck should i be talking about suicide...      8\n",
       "19866   t3_zhku3  it gave me terrible insomnias but it did work ...      3\n",
       "19867     2ffx1w  i will be very depressed for days or weeks at ...      0\n",
       "19868     44z67z  i am more busy daydreaming about suicide than ...      8\n",
       "\n",
       "[19869 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(os.path.join(data_path, 'dsm_samp_test.csv'))\n",
    "X_test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d62aa080",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=9)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ce3c5973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/lamda_00/Depression_paper/model/bert-small were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/lamda_00/Depression_paper/model/bert-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(model_path, 'bert-small'), model_max_length=32)\n",
    "config = BertConfig.from_pretrained(os.path.join(model_path, 'bert-small', 'bert_config.json'), num_labels=10)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(model_path, 'bert-small'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7a16f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_position_embeddings = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b46c8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, 'training_config.json')) as f:\n",
    "    training_config = AttrDict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0086a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.pad = 'max_length'\n",
    "training_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "466405f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = data_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.label)\n",
    "    \n",
    "    def reset_index(self):\n",
    "        self.data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # def clear_text(self)  => 전처리 코드를 여기에 넣을 경우 상당히 느려짐\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        return text, label\n",
    "        '''\n",
    "        self.reset_index()\n",
    "        text = self.data.text[idx]\n",
    "        label = self.data.label[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f3451c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertProcessor():\n",
    "    def __init__(self, config, training_config, tokenizer, truncation=True):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.max_len = config.max_position_embeddings\n",
    "        self.pad = training_config.pad\n",
    "        self.batch_size = training_config.train_batch_size\n",
    "        self.truncation = truncation\n",
    "    \n",
    "    def convert_data(self, data_file):\n",
    "        context2 = None    # single sentence classification\n",
    "\n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(data_file[idx][0], context2) for idx in range(len(data_file))],   # text, \n",
    "            max_length = self.max_len,\n",
    "            padding = self.pad,\n",
    "            truncation = self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        for i in range(len(data_file)):\n",
    "            inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "            try:\n",
    "                inputs['label'] = data_file[i][1] \n",
    "            except:\n",
    "                inputs['label'] = 0 \n",
    "            features.append(inputs)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "        return dataset\n",
    "    \n",
    "    def convert_sentence(self, sent_list):   # 사용자 입력 문장 1개 -> 입력 형태 변환\n",
    "        context2 = None \n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(sent_list, context2)], max_length=self.max_len, padding=self.pad, truncation=self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        inputs = {k: batch_encoding[k][0] for k in batch_encoding}\n",
    "        inputs['label'] = 0 \n",
    "        features.append(inputs)\n",
    "\n",
    "        input_id = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        input_am = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        input_tts = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        input_lb = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "        dataset = TensorDataset(input_id, input_am, input_tts, input_lb)\n",
    "        return dataset\n",
    "    \n",
    "    def shuffle_data(self, dataset, data_type):\n",
    "        if data_type == 'train':\n",
    "            return RandomSampler(dataset)\n",
    "        elif data_type == 'eval' or data_type == 'test':\n",
    "            return SequentialSampler(dataset)\n",
    "        \n",
    "    def load_data(self, dataset, sampler):\n",
    "        return DataLoader(dataset, sampler=sampler, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "66386a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTester():\n",
    "    def __init__(self, training_config, model):\n",
    "        self.training_config = training_config\n",
    "        self.model = model\n",
    "\n",
    "    def get_label(self, test_dataloader, test_type):\n",
    "        '''\n",
    "        test_type: 0  -> Test dataset \n",
    "        test_type: 1  -> Test sentence\n",
    "        '''\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        for batch in test_dataloader:\n",
    "            self.model.eval()\n",
    "            batch = tuple(t.to(self.training_config.device) for t in batch)   # args.device: cuda \n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3]\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                test_loss, logits = outputs[:2] \n",
    "                pred = logits.detach().cpu().numpy()\n",
    "                if test_type == 0:\n",
    "                    preds.extend(np.argmax(pred, axis=1))\n",
    "                elif test_type == 1:\n",
    "                    preds.append(np.argmax(pred))  \n",
    "                            \n",
    "            label = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            labels.extend(label)\n",
    "  \n",
    "        return preds, labels \n",
    "    \n",
    "    def get_f1_score(self, test_dataloader):\n",
    "        y_pred, y_true = self.get_label(test_dataloader)\n",
    "        return round(f1_score(y_true, y_pred, average='micro'), 3) \n",
    "     \n",
    "    def get_cl_report(self, test_dataloader):\n",
    "        y_pred, y_true = self.get_label(test_dataloader)\n",
    "        cr = classification_report(y_true, y_pred).split('\\n')\n",
    "        clr_df = []\n",
    "\n",
    "        for idx, line in enumerate(cr):\n",
    "            clr_df.append([])\n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            word_list = line.strip().split(' ')\n",
    "\n",
    "            for word in word_list:\n",
    "                if word != '':\n",
    "                    clr_df[idx].append(word)\n",
    "\n",
    "        clr_df[-2][0] = ' '.join([clr_df[-2][0], clr_df[-2][1]])\n",
    "        clr_df[-3][0] = ' '.join([clr_df[-3][0], clr_df[-3][1]])\n",
    "        clr_df[-4].insert(1, ' ')\n",
    "        clr_df[-4].insert(2, ' ')\n",
    "        clr_df[0].insert(0, 'index')\n",
    "\n",
    "        clr_df[-2].pop(1)\n",
    "        clr_df[-3].pop(1)\n",
    "        clr_df.pop(1)\n",
    "        clr_df.pop(-1)\n",
    "        clr_df.pop(-4)\n",
    "        clr_df = pd.DataFrame(clr_df[1:], columns=clr_df[0])\n",
    "        clr_df.index = clr_df['index']\n",
    "\n",
    "        del clr_df['index']\n",
    "        return clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8dfbe5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processor = BertProcessor(config, training_config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eb41887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = BertDataset(X_test)\n",
    "test_dataset = test_processor.convert_data(test_file)\n",
    "test_sampler = test_processor.shuffle_data(test_dataset, 'test')\n",
    "test_dataloader = test_processor.load_data(test_dataset, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ad0437fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lamda_00/Depression_paper/model/'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2430407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = os.path.join(model_path, 'label_9', 'bert_medium', 'bert_class.pt')\n",
    "model_name = os.path.join(model_path, 'bert_dsm_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d97810a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_name))\n",
    "model.to(training_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b9cabbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tester = BertTester(training_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "97399182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Of course I do, but... That's what I've been thinking lately\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bddbae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'conv.pickle'), 'rb') as f:\n",
    "    conv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "51790cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>그러게, 그런데 나는 기분이 우울해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>번아웃이 온 거 같기도 해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text\n",
       "0          1        User                                     안녕\n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요\n",
       "2          3        User                               이름이 뭐야 ?\n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요\n",
       "4          5        User                                  아하 ㅎㅎ\n",
       "5          6     Chatbot                               좋은 아침이에요\n",
       "6          7        User                    그러게, 그런데 나는 기분이 우울해\n",
       "7          8     Chatbot                             무슨 일 있어요 ?\n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아\n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요\n",
       "10        11        User                         심리적으로도 지친 거 같아\n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?\n",
       "12        13        User                         번아웃이 온 거 같기도 해\n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요\n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지\n",
       "15        16     Chatbot                                  산책 좋죠\n",
       "16        17        User                               들어줘서 고마워\n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "30db8c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9317/3337350865.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv.text.loc[6] = '오늘 너무 우울하다'\n",
      "/tmp/ipykernel_9317/3337350865.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv.text.loc[12] = '일이 너무 많아서 잠도 너무 못 자 '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>오늘 너무 우울하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>일이 너무 많아서 잠도 너무 못 자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text\n",
       "0          1        User                                     안녕\n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요\n",
       "2          3        User                               이름이 뭐야 ?\n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요\n",
       "4          5        User                                  아하 ㅎㅎ\n",
       "5          6     Chatbot                               좋은 아침이에요\n",
       "6          7        User                             오늘 너무 우울하다\n",
       "7          8     Chatbot                             무슨 일 있어요 ?\n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아\n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요\n",
       "10        11        User                         심리적으로도 지친 거 같아\n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?\n",
       "12        13        User                   일이 너무 많아서 잠도 너무 못 자 \n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요\n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지\n",
       "15        16     Chatbot                                  산책 좋죠\n",
       "16        17        User                               들어줘서 고마워\n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.text.loc[6] = '오늘 너무 우울하다'\n",
    "conv.text.loc[12] = '일이 너무 많아서 잠도 너무 못 자 '\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "219ee4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated = [\"hey\", \"Hello, nice to meet you\", \"what is your name ?\", \"I am a psychological counseling chatbot\", \"Ah-huh\", \\\n",
    "              \"good morning\", \"I'm so depressed today\", \"What's wrong?\", \"I just feel so lethargic these days\", \\\n",
    "              \"When you're lethargic, you have to move your body\", \"I think he's psychologically exhausted\", \\\n",
    "              \"I think you're really tired Is your work very hard?\", \"I can't sleep because I have too much work to do\", \\\n",
    "              \"I think it's good to take a break for a while\", \"I should I'll go for a walk from time to time\", \\\n",
    "              \"Taking a walk is good\", \"Thanks for listening\", \"Yes! See you next time\"]\n",
    "\n",
    "len(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c5ba81a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "      <td>what is your name ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "      <td>Ah-huh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "      <td>good morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>오늘 너무 우울하다</td>\n",
       "      <td>I'm so depressed today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "      <td>What's wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "      <td>I just feel so lethargic these days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "      <td>When you're lethargic, you have to move your body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "      <td>I think he's psychologically exhausted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "      <td>I think you're really tired Is your work very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>일이 너무 많아서 잠도 너무 못 자</td>\n",
       "      <td>I can't sleep because I have too much work to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "      <td>I think it's good to take a break for a while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "      <td>I should I'll go for a walk from time to time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "      <td>Taking a walk is good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "      <td>Thanks for listening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "      <td>Yes! See you next time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text  \\\n",
       "0          1        User                                     안녕   \n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요   \n",
       "2          3        User                               이름이 뭐야 ?   \n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요   \n",
       "4          5        User                                  아하 ㅎㅎ   \n",
       "5          6     Chatbot                               좋은 아침이에요   \n",
       "6          7        User                             오늘 너무 우울하다   \n",
       "7          8     Chatbot                             무슨 일 있어요 ?   \n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아   \n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요   \n",
       "10        11        User                         심리적으로도 지친 거 같아   \n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?   \n",
       "12        13        User                   일이 너무 많아서 잠도 너무 못 자    \n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요   \n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지   \n",
       "15        16     Chatbot                                  산책 좋죠   \n",
       "16        17        User                               들어줘서 고마워   \n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요   \n",
       "\n",
       "                                           translated  \n",
       "0                                                 hey  \n",
       "1                             Hello, nice to meet you  \n",
       "2                                 what is your name ?  \n",
       "3             I am a psychological counseling chatbot  \n",
       "4                                              Ah-huh  \n",
       "5                                        good morning  \n",
       "6                              I'm so depressed today  \n",
       "7                                       What's wrong?  \n",
       "8                 I just feel so lethargic these days  \n",
       "9   When you're lethargic, you have to move your body  \n",
       "10             I think he's psychologically exhausted  \n",
       "11  I think you're really tired Is your work very ...  \n",
       "12   I can't sleep because I have too much work to do  \n",
       "13      I think it's good to take a break for a while  \n",
       "14      I should I'll go for a walk from time to time  \n",
       "15                              Taking a walk is good  \n",
       "16                               Thanks for listening  \n",
       "17                             Yes! See you next time  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['translated'] = translated\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "589b705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'conv_translated.pickle'), 'wb') as f:\n",
    "    pickle.dump(conv, f, pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3b06b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User</td>\n",
       "      <td>what is your name ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User</td>\n",
       "      <td>Ah-huh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                     text\n",
       "0     User                                      hey\n",
       "1  Chatbot                  Hello, nice to meet you\n",
       "2     User                      what is your name ?\n",
       "3  Chatbot  I am a psychological counseling chatbot\n",
       "4     User                                   Ah-huh"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['translated'] = translated\n",
    "conv = conv[['speaker_idx', 'translated']]\n",
    "conv.columns = ['speaker', 'text']\n",
    "conv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7797aa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'Hello, nice to meet you',\n",
       " 'what is your name ?',\n",
       " 'I am a psychological counseling chatbot',\n",
       " 'Ah-huh',\n",
       " 'good morning',\n",
       " \"I'm so depressed today\",\n",
       " \"What's wrong?\",\n",
       " 'I just feel so lethargic these days',\n",
       " \"When you're lethargic, you have to move your body\",\n",
       " \"I think he's psychologically exhausted\",\n",
       " \"I think you're really tired Is your work very hard?\",\n",
       " \"I can't sleep because I have too much work to do\",\n",
       " \"I think it's good to take a break for a while\",\n",
       " \"I should I'll go for a walk from time to time\",\n",
       " 'Taking a walk is good',\n",
       " 'Thanks for listening',\n",
       " 'Yes! See you next time']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_list = conv.text.values.tolist()\n",
    "conv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71939437",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_list = conv.text.values.tolist()\n",
    "\n",
    "conv_result = [] \n",
    "for text in conv_list: \n",
    "    conv_dataset = test_processor.convert_sentence(text)\n",
    "    conv_sampler = test_processor.shuffle_data(conv_dataset, 'test')\n",
    "    conv_dataloader = test_processor.load_data(conv_dataset, conv_sampler)\n",
    "    y_pred, y_true = bert_tester.get_label(conv_dataloader)\n",
    "    conv_result.append(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d10f41e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14854/1442458656.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv['predict'] = conv_result\n",
      "/tmp/ipykernel_14854/1442458656.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv['predict'] = conv.predict.apply(lambda x: label[x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User</td>\n",
       "      <td>hey</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User</td>\n",
       "      <td>what is your name ?</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User</td>\n",
       "      <td>Ah-huh</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>good morning</td>\n",
       "      <td>수면장애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>User</td>\n",
       "      <td>I'm so depressed today</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>What's wrong?</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>User</td>\n",
       "      <td>I just feel so lethargic these days</td>\n",
       "      <td>무기력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>When you're lethargic, you have to move your body</td>\n",
       "      <td>무기력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>User</td>\n",
       "      <td>I think he's psychologically exhausted</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I think you're really tired Is your work very ...</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>User</td>\n",
       "      <td>I can't sleep because I have too much work to do</td>\n",
       "      <td>수면장애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I think it's good to take a break for a while</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>User</td>\n",
       "      <td>I should I'll go for a walk from time to time</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Taking a walk is good</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>User</td>\n",
       "      <td>Thanks for listening</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Yes! See you next time</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                               text         predict\n",
       "0      User                                                hey              우울\n",
       "1   Chatbot                            Hello, nice to meet you              우울\n",
       "2      User                                what is your name ?              우울\n",
       "3   Chatbot            I am a psychological counseling chatbot  과도한 죄책감 및 무가치함\n",
       "4      User                                             Ah-huh              우울\n",
       "5   Chatbot                                       good morning            수면장애\n",
       "6      User                             I'm so depressed today              우울\n",
       "7   Chatbot                                      What's wrong?              우울\n",
       "8      User                I just feel so lethargic these days             무기력\n",
       "9   Chatbot  When you're lethargic, you have to move your body             무기력\n",
       "10     User             I think he's psychologically exhausted  과도한 죄책감 및 무가치함\n",
       "11  Chatbot  I think you're really tired Is your work very ...  과도한 죄책감 및 무가치함\n",
       "12     User   I can't sleep because I have too much work to do            수면장애\n",
       "13  Chatbot      I think it's good to take a break for a while              우울\n",
       "14     User      I should I'll go for a walk from time to time              우울\n",
       "15  Chatbot                              Taking a walk is good              우울\n",
       "16     User                               Thanks for listening              우울\n",
       "17  Chatbot                             Yes! See you next time              우울"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['predict'] = conv_result\n",
    "conv['predict'] = conv.predict.apply(lambda x: label[x])\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f7426eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sent = \"I can't sleep because I have too much work to do\" # X_test.text[0]\n",
    "test_data = test_processor.convert_sentence(test_sent)\n",
    "test_sampler = test_processor.shuffle_data(test_data, 'test')\n",
    "test_loader = test_processor.load_data(test_data, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dbb8068e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e266bb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1458</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  text\n",
       "label            \n",
       "0      4000  4000\n",
       "1       418   418\n",
       "2      1051  1051\n",
       "3      1458  1458\n",
       "4       143   143\n",
       "5       351   351\n",
       "6      2000  2000\n",
       "7       496   496\n",
       "8      2000  2000\n",
       "9      4000  4000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1acd9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = bert_tester.get_label(test_dataloader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d96195a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 3]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99c1ba61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 3]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67c3ee5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred, y_true \u001b[38;5;241m=\u001b[39m bert_tester\u001b[38;5;241m.\u001b[39mget_label(test_loader, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = bert_tester.get_label(test_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "076ea0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a1f4d80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 1]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "91b60322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 1]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a7db1779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3945</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1014</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>338</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3963</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3959</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>3930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2     3    4    5     6    7     8     9\n",
       "0  3945    0     3     7    3    0    19    2    15     6\n",
       "1     3  407     0     1    0    0     3    0     2     0\n",
       "2     1    1  1014     2    3    0     0    0     1     4\n",
       "3     2    0     1  1440    0    0     1    1     1     0\n",
       "4     0    0     0     2  141    0     0    0     0     0\n",
       "5     2    0     1     3    3  338     1    0     0     0\n",
       "6    13    0     3     5    0    0  3963    0    15     1\n",
       "7     1    0     0     3    0    1     0  485     0     0\n",
       "8    15    0     3     4    2    0     7    0  3959    10\n",
       "9    14    1    10    13    2    0     1    5    24  3930"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score , recall_score , confusion_matrix, f1_score, classification_report\n",
    "\n",
    "confusion_mt = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "confusion_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd513f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
