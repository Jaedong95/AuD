{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c9dbf2",
   "metadata": {},
   "source": [
    "### 1. Environment Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e256a",
   "metadata": {},
   "source": [
    "#### 1.1 Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e218b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import pymysql\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "from attrdict import AttrDict\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertConfig, BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401885e",
   "metadata": {},
   "source": [
    "#### 1.2 Setting Default Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2275e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/lamda_00/Depression_paper/data/\"\n",
    "model_path = \"/home/lamda_00/Depression_paper/model/\"\n",
    "ckpt_path = \"/home/lamda_00/Depression_paper/ckpt/\"\n",
    "config_path = \"/home/lamda_00/Depression_paper/config/\"\n",
    "log_path = \"/home/lamda_00/Depression_paper/log/\"\n",
    "config_file = \"bert-base.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f1b19",
   "metadata": {},
   "source": [
    "#### 1.3 Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c443246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '우울',\n",
       " 1: '무기력',\n",
       " 2: '급격한 체중(식욕)변화',\n",
       " 3: '수면장애',\n",
       " 4: '정서불안',\n",
       " 5: '피로',\n",
       " 6: '과도한 죄책감 및 무가치함',\n",
       " 7: '인지기능저하',\n",
       " 8: '자살충동',\n",
       " 9: '일상'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = dict()\n",
    "\n",
    "label[0] = '우울'\n",
    "label[1] = '무기력'\n",
    "label[2] = '급격한 체중(식욕)변화'\n",
    "label[3] = '수면장애'\n",
    "label[4] = '정서불안'\n",
    "label[5] = '피로'\n",
    "label[6] = '과도한 죄책감 및 무가치함'\n",
    "label[7] = '인지기능저하'\n",
    "label[8] = '자살충동'\n",
    "label[9] = '일상'\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c21818",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9317/2633627116.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dsm_data = pd.read_csv(os.path.join(data_path, 'dsm_data.csv'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>al526</td>\n",
       "      <td>so, am i depressed? i'm honestly unsure myself...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as8qg</td>\n",
       "      <td>i originally put it in askreddit, but realized...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as8qg</td>\n",
       "      <td>how did you do it? am i even depressed at all?...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ay63c</td>\n",
       "      <td>have been depressed for approximately 20 years...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aycre</td>\n",
       "      <td>i don't know if i'm depressed or if i'm being ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300070</th>\n",
       "      <td>126547</td>\n",
       "      <td>It is said that the incidence of respiratory d...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300071</th>\n",
       "      <td>126547</td>\n",
       "      <td>It was a little uncomfortable at first, but no...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300072</th>\n",
       "      <td>126547</td>\n",
       "      <td>I think I'll wear a mask for the rest of my li...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300073</th>\n",
       "      <td>126547</td>\n",
       "      <td>I think I should accept it as a habit now.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300074</th>\n",
       "      <td>126547</td>\n",
       "      <td>Will the time really come when COVID-19 ends?</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300075 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  label\n",
       "0        al526  so, am i depressed? i'm honestly unsure myself...      0\n",
       "1        as8qg  i originally put it in askreddit, but realized...      0\n",
       "2        as8qg  how did you do it? am i even depressed at all?...      0\n",
       "3        ay63c  have been depressed for approximately 20 years...      0\n",
       "4        aycre  i don't know if i'm depressed or if i'm being ...      0\n",
       "...        ...                                                ...    ...\n",
       "300070  126547  It is said that the incidence of respiratory d...      9\n",
       "300071  126547  It was a little uncomfortable at first, but no...      9\n",
       "300072  126547  I think I'll wear a mask for the rest of my li...      9\n",
       "300073  126547         I think I should accept it as a habit now.      9\n",
       "300074  126547      Will the time really come when COVID-19 ends?      9\n",
       "\n",
       "[300075 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_data = pd.read_csv(os.path.join(data_path, 'dsm_data.csv'))\n",
    "dsm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67766284",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lamda_00/Depression_paper/data/dsm_sample2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# dsm_sample: label_10, dsm_sample2: label_9\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dsm_sample \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdsm_sample2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m dsm_sample\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/pandas/io/common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    856\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lamda_00/Depression_paper/data/dsm_sample2.csv'"
     ]
    }
   ],
   "source": [
    "# dsm_sample: label_10, dsm_sample2: label_9\n",
    "dsm_sample = pd.read_csv(os.path.join(data_path, 'dsm_sample2.csv'))\n",
    "dsm_sample.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c7809673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87891</td>\n",
       "      <td>87891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2078</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5129</td>\n",
       "      <td>5129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7228</td>\n",
       "      <td>7228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1741</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41758</td>\n",
       "      <td>41758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2452</td>\n",
       "      <td>2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52860</td>\n",
       "      <td>52860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98222</td>\n",
       "      <td>98222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   text\n",
       "label              \n",
       "0      87891  87891\n",
       "1       2078   2078\n",
       "2       5129   5129\n",
       "3       7228   7228\n",
       "4        716    716\n",
       "5       1741   1741\n",
       "6      41758  41758\n",
       "7       2452   2452\n",
       "8      52860  52860\n",
       "9      98222  98222"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_data.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "655e58a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150201</th>\n",
       "      <td>amruc</td>\n",
       "      <td>besides, i worked myself out of the suicidal p...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150202</th>\n",
       "      <td>aud8r</td>\n",
       "      <td>i hate that on my \"good\" days i actually becom...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150203</th>\n",
       "      <td>b72of</td>\n",
       "      <td>therapy, medication, self-medication, suicidal...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150205</th>\n",
       "      <td>bak16</td>\n",
       "      <td>the depressed mode sometimes becomes panicky-d...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150206</th>\n",
       "      <td>bivnx</td>\n",
       "      <td>i have also been struggling with some suicidal...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206146</th>\n",
       "      <td>54jkqa</td>\n",
       "      <td>i don't want to say i want to die, because i d...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206147</th>\n",
       "      <td>t3_28v4mc</td>\n",
       "      <td>i don't really want to die, but sometimes i th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206148</th>\n",
       "      <td>t3_4op4fb</td>\n",
       "      <td>i don't really want to die, there are times wh...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206149</th>\n",
       "      <td>t3_50ycys</td>\n",
       "      <td>i too just want to die or just disappear</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206152</th>\n",
       "      <td>32kgfi</td>\n",
       "      <td>i don't even want to die, i only want to vanis...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52860 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  label\n",
       "150201      amruc  besides, i worked myself out of the suicidal p...      8\n",
       "150202      aud8r  i hate that on my \"good\" days i actually becom...      8\n",
       "150203      b72of  therapy, medication, self-medication, suicidal...      8\n",
       "150205      bak16  the depressed mode sometimes becomes panicky-d...      8\n",
       "150206      bivnx  i have also been struggling with some suicidal...      8\n",
       "...           ...                                                ...    ...\n",
       "206146     54jkqa  i don't want to say i want to die, because i d...      8\n",
       "206147  t3_28v4mc  i don't really want to die, but sometimes i th...      8\n",
       "206148  t3_4op4fb  i don't really want to die, there are times wh...      8\n",
       "206149  t3_50ycys           i too just want to die or just disappear      8\n",
       "206152     32kgfi  i don't even want to die, i only want to vanis...      8\n",
       "\n",
       "[52860 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_data[dsm_data.label==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3b85f7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99344"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_sample = dsm_data.copy()\n",
    "dsm = []\n",
    "\n",
    "dsm.extend(dsm_sample[dsm_sample.label==0].sample(40000).index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==1].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==2].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==3].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==4].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==5].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==6].sample(20000).index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==7].index.tolist())\n",
    "dsm.extend(dsm_sample[dsm_sample.label==8].sample(20000).index.tolist())\n",
    "\n",
    "len(dsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "586e5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_sample = dsm_sample.loc[dsm]\n",
    "dsm_sample.to_csv(os.path.join(data_path, 'dsm_sample2.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3623261b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63580, 15895, 19869)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(dsm_sample, test_size=0.2, random_state=42, stratify=dsm_sample['label'])\n",
    "X_train, X_dev = train_test_split(X_train, test_size=0.2, random_state=42, stratify=X_train['label'])\n",
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "295e98a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25600</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330</td>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3282</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4626</td>\n",
       "      <td>4626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>458</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1114</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12800</td>\n",
       "      <td>12800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1570</td>\n",
       "      <td>1570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12800</td>\n",
       "      <td>12800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   text\n",
       "label              \n",
       "0      25600  25600\n",
       "1       1330   1330\n",
       "2       3282   3282\n",
       "3       4626   4626\n",
       "4        458    458\n",
       "5       1114   1114\n",
       "6      12800  12800\n",
       "7       1570   1570\n",
       "8      12800  12800"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d7a0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(os.path.join(data_path, 'dsm_samp2_train.csv'), index=False)\n",
    "X_dev.to_csv(os.path.join(data_path, 'dsm_samp2_val.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(data_path, 'dsm_samp2_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671f6c4",
   "metadata": {},
   "source": [
    "#### 1.4 Load Pretrained model & tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0bbf96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(os.path.join(data_path, 'dsm_samp_train.csv'))\n",
    "X_dev = pd.read_csv(os.path.join(data_path, 'dsm_samp_val.csv'))\n",
    "X_test = pd.read_csv(os.path.join(data_path, 'dsm_samp_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "61d2504b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63580, 15895, 19869)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5f93bf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 0, 9, 3, 1, 2, 4, 5, 7])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ce43a043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우울\n",
      "무기력\n",
      "급격한 체중(식욕)변화\n",
      "수면장애\n",
      "정서불안\n",
      "피로\n",
      "과도한 죄책감 및 무가치함\n",
      "인지기능저하\n",
      "자살충동\n",
      "일상\n"
     ]
    }
   ],
   "source": [
    "for i, name in label.items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cec384fe",
   "metadata": {},
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=10, output_hidden_states=True)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88a0b9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lamda_00/Depression_paper/model/'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ec85e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/lamda_00/Depression_paper/model/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/lamda_00/Depression_paper/model/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(model_path, 'bert-base'), model_max_length=32)\n",
    "config = BertConfig.from_pretrained(os.path.join(model_path, 'bert-base', 'bert_config.json'), num_labels=10)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(model_path, 'bert-base'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "562b48c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 768)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.attention_probs_dropout_prob, config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ee345",
   "metadata": {},
   "source": [
    "#### 1.5 setting training args & config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9e440926",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, 'training_config.json')) as f:\n",
    "    training_config = AttrDict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "affe617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5401389c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'default_path': '../', 'data_path': 'data', 'log_path': 'log', 'model_path': 'model', 'config_path': 'config', 'seed': 42, 'train_batch_size': 32, 'device': device(type='cuda'), 'eval_batch_size': 32, 'num_epochs': 500, 'gradient_accumulation_steps': 1, 'max_grad_norm': 1.0, 'adam_epsilon': 1e-08, 'warmup_proportion': 0, 'learning_rate': 5e-05, 'do_lower_case': False, 'no_cuda': False, 'max_steps': -1, 'logging_steps': 100})"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bdf7ea26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-05"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cf4e57f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(training_config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c79e9",
   "metadata": {},
   "source": [
    "### 2. Define Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2e338dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.pad = 'max_length'\n",
    "training_config.num_epochs  = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dd385338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = data_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.label)\n",
    "    \n",
    "    def reset_index(self):\n",
    "        self.data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # def clear_text(self)  => 전처리 코드를 여기에 넣을 경우 상당히 느려짐\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        return text, label\n",
    "        '''\n",
    "        self.reset_index()\n",
    "        text = self.data.text[idx]\n",
    "        label = self.data.label[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e2c34513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertProcessor():\n",
    "    def __init__(self, config, training_config, tokenizer, truncation=True):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.max_len = config.max_position_embeddings\n",
    "        self.pad = training_config.pad\n",
    "        self.batch_size = training_config.train_batch_size\n",
    "        self.truncation = truncation\n",
    "    \n",
    "    def convert_data(self, data_file):\n",
    "        context2 = None    # single sentence classification\n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(data_file[idx][0], context2) for idx in range(len(data_file))],   # text, \n",
    "            max_length = self.max_len,\n",
    "            padding = self.pad,\n",
    "            truncation = self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        for i in range(len(data_file)):\n",
    "            inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "            try:\n",
    "                inputs['label'] = data_file[i][1] \n",
    "            except:\n",
    "                inputs['label'] = 0 \n",
    "            features.append(inputs)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "        return dataset\n",
    "    \n",
    "    def convert_sentence(self, sentence_list):   # 사용자 입력 문장 1개 -> 입력 형태 변환\n",
    "        pass\n",
    "    \n",
    "    def shuffle_data(self, dataset, data_type):\n",
    "        if data_type == 'train':\n",
    "            return RandomSampler(dataset)\n",
    "        elif data_type == 'eval' or data_type == 'test':\n",
    "            return SequentialSampler(dataset)\n",
    "        \n",
    "    def load_data(self, dataset, sampler):\n",
    "        return DataLoader(dataset, sampler=sampler, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdecbfd0",
   "metadata": {},
   "source": [
    "class ElectraRegressor(nn.Module):\n",
    "    '''\n",
    "    다중 분류 학습 시 선언하는 클래스 \n",
    "    '''\n",
    "    def __init__(self, electra, config):\n",
    "        # 부모 생성자 초기화, super().__init__(config) 시 오류 발생 \n",
    "        super(ElectraRegressor, self).__init__() \n",
    "        self.electra = electra\n",
    "        self.layer = nn.Linear(config.hidden_size, 128)\n",
    "        self.regressor = nn.Sequential(nn.Dropout(0.1), nn.Linear(128, 6))\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.electra(input_ids=input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids)\n",
    "        logits = outputs.last_hidden_state[:, 0, :]\n",
    "        output = self.layer(logits)\n",
    "        output = self.regressor(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "89a0759c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'default_path': '../', 'data_path': 'data', 'log_path': 'log', 'model_path': 'model', 'config_path': 'config', 'seed': 42, 'train_batch_size': 32, 'device': device(type='cuda'), 'eval_batch_size': 32, 'num_epochs': 500, 'gradient_accumulation_steps': 1, 'max_grad_norm': 1.0, 'adam_epsilon': 1e-08, 'warmup_proportion': 0, 'learning_rate': 5e-05, 'do_lower_case': False, 'no_cuda': False, 'max_steps': -1, 'logging_steps': 100, 'pad': 'max_length'})"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_config.num_epochs\n",
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2e2c3620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d8cb7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainer():\n",
    "    def __init__(self, config, training_config, model, train_dataloader, eval_dataloader):\n",
    "        self.config = config\n",
    "        self.training_config = training_config\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.eval_dataloader = eval_dataloader\n",
    "        \n",
    "    def set_seed(self):\n",
    "        random.seed(self.training_config.seed)\n",
    "        np.random.seed(self.training_config.seed)\n",
    "        torch.manual_seed(self.training_config.seed)\n",
    "        if not self.training_config.no_cuda and torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(self.training_config.seed)\n",
    "    \n",
    "    def train(self):\n",
    "        train_acc_list = []; eval_acc_list = [] \n",
    "        train_loss_list = []; eval_loss_list = []\n",
    "        # eval_acc_step = []; eval_loss_step = []\n",
    "        # train_acc_step = []; train_loss_step = []\n",
    "        nb_eval_steps = 0\n",
    "        best_loss = 9999; best_epoch = 0\n",
    "        t_total = len(self.train_dataloader) // self.training_config.gradient_accumulation_steps * self.training_config.num_epochs\n",
    "\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.training_config.learning_rate, eps=self.training_config.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(t_total * self.training_config.warmup_proportion), \\\n",
    "                                                    num_training_steps=t_total)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        for epoch in range(int(self.training_config.num_epochs)):\n",
    "            train_acc = 0.0; eval_acc = 0.0\n",
    "            train_loss = 0.0; eval_loss = 0.0 \n",
    "\n",
    "            for step, batch in enumerate(self.train_dataloader):\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.training_config.device) for t in batch)\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3]\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                # loss = outputs[0]\n",
    "                # y_pred = torch.max(outputs[1], 1)[1]\n",
    "                y_pred = outputs[1]\n",
    "                y_true = batch[3]\n",
    "                # y_true = torch.tensor([float(t) for t in y_true]).to(self.training_config.device)\n",
    "                loss = criterion(y_pred, y_true)\n",
    "                # print(outputs[0], outputs[1], batch[3])\n",
    "                loss.backward()\n",
    "                train_loss += loss.item()\n",
    "                train_acc += self.calc_accuracy(outputs[1], batch[3])\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                self.model.zero_grad()\n",
    "                '''\n",
    "                if step % training_config.logging_steps == 0:\n",
    "                    # print(f'step: {step}, {train_acc / (step + 1)}')\n",
    "                    # print(f'step: {step}, {train_loss / (step + 1)}')\n",
    "                    train_acc_step.append([step, train_acc / (step + 1)])\n",
    "                    train_loss_step.append([step, train_loss / (step + 1)])'''\n",
    "\n",
    "            train_acc = train_acc / (step + 1)\n",
    "            print(f'epoch: {epoch}, train_loss: {train_loss}')\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_loss_list.append(train_loss)\n",
    "\n",
    "            for step2, batch2 in enumerate(self.eval_dataloader):\n",
    "                self.model.eval()\n",
    "                batch2 = tuple(t.to(self.training_config.device) for t in batch2)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    inputs = {\n",
    "                        \"input_ids\": batch2[0],\n",
    "                        \"attention_mask\": batch2[1],\n",
    "                        \"token_type_ids\": batch2[2],\n",
    "                        \"labels\": batch2[3]\n",
    "                    }\n",
    "                    outputs = self.model(**inputs)\n",
    "                    tmp_eval_loss, logits = outputs[:2]\n",
    "                    loss2 = criterion(logits, batch2[3])\n",
    "                    eval_loss += loss2.item()              \n",
    "                    # eval_loss += tmp_eval_loss.mean().item()\n",
    "                    eval_acc += self.calc_accuracy(outputs[1], batch2[3]) \n",
    "                    '''\n",
    "                    if step2 % training_config.logging_steps == 0:\n",
    "                        eval_acc_step.append([step2, eval_acc / (step + 1)])\n",
    "                        eval_loss_step.append([step2, eval_loss / (step + 1)])'''\n",
    "            '''            \n",
    "            try:\n",
    "                last_loss = eval_loss_list[-1]\n",
    "            except:\n",
    "                last_loss = 9999\n",
    "            '''\n",
    "            eval_loss = eval_loss / (step2 + 1)\n",
    "            eval_acc = eval_acc / (step2 + 1)\n",
    "            eval_acc_list.append(eval_acc)\n",
    "            eval_loss_list.append(eval_loss)\n",
    "            print(f'epoch: {epoch}, eval_loss: {eval_loss}')\n",
    "            \n",
    "            if eval_loss < best_loss:\n",
    "                best_loss = eval_loss\n",
    "                es = 0\n",
    "                print(f'save best loss state model & log(epoch {epoch + 1})')\n",
    "                self.save_model(os.path.join(self.training_config.default_path, self.training_config.model_path, f'bert_dsm_{epoch}.pt'))\n",
    "                best_epoch = epoch\n",
    "            else:\n",
    "                es += 1\n",
    "                print(\"Counter {} of 7\".format(es))\n",
    "\n",
    "            if es > 6:\n",
    "                print(\"Early stopping with best_loss: \", best_loss, \"and val_loss for this epoch: \", eval_loss, \"...\")\n",
    "                break\n",
    "                \n",
    "            '''\n",
    "            if eval_loss > last_loss:\n",
    "                trigger_times += 1\n",
    "                print('Trigger Times:', trigger_times)\n",
    "                self.save_model(os.path.join(self.training_config.default_path, self.training_config.model_path, f'bert_bws_{epoch}.pt'))\n",
    "                \n",
    "                if trigger_times > 4:\n",
    "                    print(\"Early stopping !\")\n",
    "                    self.save_model(os.path.join(self.training_config.default_path, self.training_config.model_path, f'bert_bws_best.pt'))\n",
    "                    break\n",
    "            else:\n",
    "                print('trigger times: 0')\n",
    "                trigger_times = 0'''\n",
    "            \n",
    "\n",
    "        self.save_log(train_acc_list, train_loss_list, eval_acc_list, eval_loss_list, epoch)\n",
    "        return train_acc_list, train_loss_list, eval_acc_list, eval_loss_list\n",
    "\n",
    "    def calc_accuracy(self, X,Y):\n",
    "        max_vals, max_indices = torch.max(X, 1)\n",
    "        train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "        return train_acc\n",
    "    \n",
    "    def compute_metrics(self, labels, preds):\n",
    "        assert len(preds) == len(labels)\n",
    "        acc = (labels == preds).mean()\n",
    "        return {\"acc\": acc}\n",
    "    \n",
    "    def save_step_log(self, train_acc_step, train_loss_step, eval_acc_step, eval_loss_step, epoch):\n",
    "        with open(os.path.join(self.training_config.default_path, self.training_config.log_path, f'train_step_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_acc_step, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        with open(os.path.join(self.training_config.default_path, self.training_config.log_path, f'train_step_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_loss_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.default_path, self.training_config.log_path, f'eval_step_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_acc_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.default_path, self.training_config.log_path, f'eval_step_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_loss_step, f, pickle.HIGHEST_PROTOCOL)  \n",
    "            \n",
    "    def save_log(self, train_acc, train_loss, eval_acc, eval_loss, epoch):\n",
    "        with open(os.path.join(self.training_config.default_path, self.training_config.log_path, f'train_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_acc, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        with open(os.path.join(self.training_config.default_path, self.training_config.log_path, f'train_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(train_loss, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.default_path, self.training_config.log_path, f'eval_{epoch}_acc.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_acc, f, pickle.HIGHEST_PROTOCOL)  \n",
    "        \n",
    "        with open(os.path.join(self.training_config.default_path, self.training_config.log_path, f'eval_{epoch}_loss.pickle'), 'wb') as f:\n",
    "            pickle.dump(eval_loss, f, pickle.HIGHEST_PROTOCOL)  \n",
    "    \n",
    "    def save_model(self, model_name):\n",
    "        torch.save(self.model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fbc7d",
   "metadata": {},
   "source": [
    "### 3. Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7539a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 0, 9, 3, 1, 2, 4, 5, 7])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a820e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = BertDataset(X_train)\n",
    "val_file = BertDataset(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bacfeb4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63580, 15895)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file), len(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "beaac774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.max_position_embeddings = 32\n",
    "config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f4417358",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_processor = BertProcessor(config, training_config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9d4276f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = bert_processor.convert_data(train_file)\n",
    "val_dataset = bert_processor.convert_data(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "986f2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = bert_processor.shuffle_data(train_dataset, 'train')\n",
    "val_sampler = bert_processor.shuffle_data(val_dataset, 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4a1baa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = bert_processor.load_data(train_dataset, train_sampler)\n",
    "val_dataloader = bert_processor.load_data(val_dataset, val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bad48641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1987, 497)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a1b972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trainer = BertTrainer(config, training_config, model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5b6e9d5f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 248.3740598752629\n",
      "epoch: 0, eval_loss: 0.05096935437206587\n",
      "save best loss state model & log(epoch 1)\n",
      "epoch: 1, train_loss: 106.87129963678308\n",
      "epoch: 1, eval_loss: 0.0514270755217806\n",
      "Counter 1 of 7\n",
      "epoch: 2, train_loss: 76.87130812357645\n",
      "epoch: 2, eval_loss: 0.05343853877491919\n",
      "Counter 2 of 7\n",
      "epoch: 3, train_loss: 67.3428502138413\n",
      "epoch: 3, eval_loss: 0.04819384058011027\n",
      "save best loss state model & log(epoch 4)\n",
      "epoch: 4, train_loss: 52.54140174033819\n",
      "epoch: 4, eval_loss: 0.04979538091467047\n",
      "Counter 1 of 7\n",
      "epoch: 5, train_loss: 44.59284018780454\n",
      "epoch: 5, eval_loss: 0.05232976792287456\n",
      "Counter 2 of 7\n",
      "epoch: 6, train_loss: 41.28900588596298\n",
      "epoch: 6, eval_loss: 0.057177754054623664\n",
      "Counter 3 of 7\n",
      "epoch: 7, train_loss: 33.45048954570666\n",
      "epoch: 7, eval_loss: 0.060633899366506046\n",
      "Counter 4 of 7\n",
      "epoch: 8, train_loss: 37.39650171723042\n",
      "epoch: 8, eval_loss: 0.12861444413337775\n",
      "Counter 5 of 7\n",
      "epoch: 9, train_loss: 32.43412399854424\n",
      "epoch: 9, eval_loss: 0.0603993325078168\n",
      "Counter 6 of 7\n",
      "epoch: 10, train_loss: 27.999628019875672\n",
      "epoch: 10, eval_loss: 0.07304142474170383\n",
      "Counter 7 of 7\n",
      "Early stopping with best_loss:  0.04819384058011027 and val_loss for this epoch:  0.07304142474170383 ...\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss, eval_acc, eval_loss = bert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "04497f7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = list(range(len(train_loss)))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "# plt.plot(list(range(len(train_loss))), train_loss, label='train_loss')\n",
    "plt.plot(list(range(len(train_loss))), train_loss, label='train_loss')\n",
    "plt.plot(list(range(len(train_loss))), eval_loss, label='val_loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32d280",
   "metadata": {},
   "source": [
    "### 3. Model Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "96dde817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '우울',\n",
       " 1: '무기력',\n",
       " 2: '급격한 체중(식욕)변화',\n",
       " 3: '수면장애',\n",
       " 4: '정서불안',\n",
       " 5: '피로',\n",
       " 6: '과도한 죄책감 및 무가치함',\n",
       " 7: '인지기능저하',\n",
       " 8: '자살충동',\n",
       " 9: '일상'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = dict()\n",
    "\n",
    "label[0] = '우울'\n",
    "label[1] = '무기력'\n",
    "label[2] = '급격한 체중(식욕)변화'\n",
    "label[3] = '수면장애'\n",
    "label[4] = '정서불안'\n",
    "label[5] = '피로'\n",
    "label[6] = '과도한 죄책감 및 무가치함'\n",
    "label[7] = '인지기능저하'\n",
    "label[8] = '자살충동'\n",
    "label[9] = '일상'\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c7803e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132946</td>\n",
       "      <td>Of course I do, but... That's what I've been t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_uzhrj</td>\n",
       "      <td>hurting yourself just leads to so many more pr...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_1f6rlk</td>\n",
       "      <td>as if it never mattered anyways i'll go to sle...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77173</td>\n",
       "      <td>You said you'd know the heat from one Kiki.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_1dzb0x</td>\n",
       "      <td>just because the \"cancer\" tells me i am worthl...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>t3_2s455q</td>\n",
       "      <td>if you view it as a - z, it can be very easy f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19865</th>\n",
       "      <td>43hkav</td>\n",
       "      <td>why the fuck should i be talking about suicide...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>t3_zhku3</td>\n",
       "      <td>it gave me terrible insomnias but it did work ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19867</th>\n",
       "      <td>2ffx1w</td>\n",
       "      <td>i will be very depressed for days or weeks at ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19868</th>\n",
       "      <td>44z67z</td>\n",
       "      <td>i am more busy daydreaming about suicide than ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19869 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                               text  label\n",
       "0         132946  Of course I do, but... That's what I've been t...      9\n",
       "1       t3_uzhrj  hurting yourself just leads to so many more pr...      8\n",
       "2      t3_1f6rlk  as if it never mattered anyways i'll go to sle...      3\n",
       "3          77173        You said you'd know the heat from one Kiki.      9\n",
       "4      t3_1dzb0x  just because the \"cancer\" tells me i am worthl...      6\n",
       "...          ...                                                ...    ...\n",
       "19864  t3_2s455q  if you view it as a - z, it can be very easy f...      1\n",
       "19865     43hkav  why the fuck should i be talking about suicide...      8\n",
       "19866   t3_zhku3  it gave me terrible insomnias but it did work ...      3\n",
       "19867     2ffx1w  i will be very depressed for days or weeks at ...      0\n",
       "19868     44z67z  i am more busy daydreaming about suicide than ...      8\n",
       "\n",
       "[19869 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(os.path.join(data_path, 'dsm_samp_test.csv'))\n",
    "X_test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d62aa080",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=9)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ce3c5973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/lamda_00/Depression_paper/model/bert-small were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/lamda_00/Depression_paper/model/bert-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(model_path, 'bert-small'), model_max_length=32)\n",
    "config = BertConfig.from_pretrained(os.path.join(model_path, 'bert-small', 'bert_config.json'), num_labels=10)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(model_path, 'bert-small'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7a16f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_position_embeddings = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b46c8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, 'training_config.json')) as f:\n",
    "    training_config = AttrDict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0086a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.pad = 'max_length'\n",
    "training_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "466405f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = data_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.label)\n",
    "    \n",
    "    def reset_index(self):\n",
    "        self.data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # def clear_text(self)  => 전처리 코드를 여기에 넣을 경우 상당히 느려짐\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        return text, label\n",
    "        '''\n",
    "        self.reset_index()\n",
    "        text = self.data.text[idx]\n",
    "        label = self.data.label[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f3451c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertProcessor():\n",
    "    def __init__(self, config, training_config, tokenizer, truncation=True):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.max_len = config.max_position_embeddings\n",
    "        self.pad = training_config.pad\n",
    "        self.batch_size = training_config.train_batch_size\n",
    "        self.truncation = truncation\n",
    "    \n",
    "    def convert_data(self, data_file):\n",
    "        context2 = None    # single sentence classification\n",
    "\n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(data_file[idx][0], context2) for idx in range(len(data_file))],   # text, \n",
    "            max_length = self.max_len,\n",
    "            padding = self.pad,\n",
    "            truncation = self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        for i in range(len(data_file)):\n",
    "            inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "            try:\n",
    "                inputs['label'] = data_file[i][1] \n",
    "            except:\n",
    "                inputs['label'] = 0 \n",
    "            features.append(inputs)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "        return dataset\n",
    "    \n",
    "    def convert_sentence(self, sent_list):   # 사용자 입력 문장 1개 -> 입력 형태 변환\n",
    "        context2 = None \n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(sent_list, context2)], max_length=self.max_len, padding=self.pad, truncation=self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        inputs = {k: batch_encoding[k][0] for k in batch_encoding}\n",
    "        inputs['label'] = 0 \n",
    "        features.append(inputs)\n",
    "\n",
    "        input_id = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        input_am = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        input_tts = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        input_lb = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "        dataset = TensorDataset(input_id, input_am, input_tts, input_lb)\n",
    "        return dataset\n",
    "    \n",
    "    def shuffle_data(self, dataset, data_type):\n",
    "        if data_type == 'train':\n",
    "            return RandomSampler(dataset)\n",
    "        elif data_type == 'eval' or data_type == 'test':\n",
    "            return SequentialSampler(dataset)\n",
    "        \n",
    "    def load_data(self, dataset, sampler):\n",
    "        return DataLoader(dataset, sampler=sampler, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "66386a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTester():\n",
    "    def __init__(self, training_config, model):\n",
    "        self.training_config = training_config\n",
    "        self.model = model\n",
    "\n",
    "    def get_label(self, test_dataloader, test_type):\n",
    "        '''\n",
    "        test_type: 0  -> Test dataset \n",
    "        test_type: 1  -> Test sentence\n",
    "        '''\n",
    "        preds = []\n",
    "        labels = []\n",
    "\n",
    "        for batch in test_dataloader:\n",
    "            self.model.eval()\n",
    "            batch = tuple(t.to(self.training_config.device) for t in batch)   # args.device: cuda \n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3]\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                test_loss, logits = outputs[:2] \n",
    "                pred = logits.detach().cpu().numpy()\n",
    "                if test_type == 0:\n",
    "                    preds.extend(np.argmax(pred, axis=1))\n",
    "                elif test_type == 1:\n",
    "                    preds.append(np.argmax(pred))  \n",
    "                            \n",
    "            label = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            labels.extend(label)\n",
    "  \n",
    "        return preds, labels \n",
    "    \n",
    "    def get_f1_score(self, test_dataloader):\n",
    "        y_pred, y_true = self.get_label(test_dataloader)\n",
    "        return round(f1_score(y_true, y_pred, average='micro'), 3) \n",
    "     \n",
    "    def get_cl_report(self, test_dataloader):\n",
    "        y_pred, y_true = self.get_label(test_dataloader)\n",
    "        cr = classification_report(y_true, y_pred).split('\\n')\n",
    "        clr_df = []\n",
    "\n",
    "        for idx, line in enumerate(cr):\n",
    "            clr_df.append([])\n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            word_list = line.strip().split(' ')\n",
    "\n",
    "            for word in word_list:\n",
    "                if word != '':\n",
    "                    clr_df[idx].append(word)\n",
    "\n",
    "        clr_df[-2][0] = ' '.join([clr_df[-2][0], clr_df[-2][1]])\n",
    "        clr_df[-3][0] = ' '.join([clr_df[-3][0], clr_df[-3][1]])\n",
    "        clr_df[-4].insert(1, ' ')\n",
    "        clr_df[-4].insert(2, ' ')\n",
    "        clr_df[0].insert(0, 'index')\n",
    "\n",
    "        clr_df[-2].pop(1)\n",
    "        clr_df[-3].pop(1)\n",
    "        clr_df.pop(1)\n",
    "        clr_df.pop(-1)\n",
    "        clr_df.pop(-4)\n",
    "        clr_df = pd.DataFrame(clr_df[1:], columns=clr_df[0])\n",
    "        clr_df.index = clr_df['index']\n",
    "\n",
    "        del clr_df['index']\n",
    "        return clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8dfbe5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processor = BertProcessor(config, training_config, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eb41887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = BertDataset(X_test)\n",
    "test_dataset = test_processor.convert_data(test_file)\n",
    "test_sampler = test_processor.shuffle_data(test_dataset, 'test')\n",
    "test_dataloader = test_processor.load_data(test_dataset, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ad0437fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lamda_00/Depression_paper/model/'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2430407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = os.path.join(model_path, 'label_9', 'bert_medium', 'bert_class.pt')\n",
    "model_name = os.path.join(model_path, 'bert_dsm_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d97810a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_name))\n",
    "model.to(training_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b9cabbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tester = BertTester(training_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "97399182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Of course I do, but... That's what I've been thinking lately\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bddbae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'conv.pickle'), 'rb') as f:\n",
    "    conv = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "51790cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>그러게, 그런데 나는 기분이 우울해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>번아웃이 온 거 같기도 해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text\n",
       "0          1        User                                     안녕\n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요\n",
       "2          3        User                               이름이 뭐야 ?\n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요\n",
       "4          5        User                                  아하 ㅎㅎ\n",
       "5          6     Chatbot                               좋은 아침이에요\n",
       "6          7        User                    그러게, 그런데 나는 기분이 우울해\n",
       "7          8     Chatbot                             무슨 일 있어요 ?\n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아\n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요\n",
       "10        11        User                         심리적으로도 지친 거 같아\n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?\n",
       "12        13        User                         번아웃이 온 거 같기도 해\n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요\n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지\n",
       "15        16     Chatbot                                  산책 좋죠\n",
       "16        17        User                               들어줘서 고마워\n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "30db8c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9317/3337350865.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv.text.loc[6] = '오늘 너무 우울하다'\n",
      "/tmp/ipykernel_9317/3337350865.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv.text.loc[12] = '일이 너무 많아서 잠도 너무 못 자 '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>오늘 너무 우울하다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>일이 너무 많아서 잠도 너무 못 자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text\n",
       "0          1        User                                     안녕\n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요\n",
       "2          3        User                               이름이 뭐야 ?\n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요\n",
       "4          5        User                                  아하 ㅎㅎ\n",
       "5          6     Chatbot                               좋은 아침이에요\n",
       "6          7        User                             오늘 너무 우울하다\n",
       "7          8     Chatbot                             무슨 일 있어요 ?\n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아\n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요\n",
       "10        11        User                         심리적으로도 지친 거 같아\n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?\n",
       "12        13        User                   일이 너무 많아서 잠도 너무 못 자 \n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요\n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지\n",
       "15        16     Chatbot                                  산책 좋죠\n",
       "16        17        User                               들어줘서 고마워\n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.text.loc[6] = '오늘 너무 우울하다'\n",
    "conv.text.loc[12] = '일이 너무 많아서 잠도 너무 못 자 '\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "219ee4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated = [\"hey\", \"Hello, nice to meet you\", \"what is your name ?\", \"I am a psychological counseling chatbot\", \"Ah-huh\", \\\n",
    "              \"good morning\", \"I'm so depressed today\", \"What's wrong?\", \"I just feel so lethargic these days\", \\\n",
    "              \"When you're lethargic, you have to move your body\", \"I think he's psychologically exhausted\", \\\n",
    "              \"I think you're really tired Is your work very hard?\", \"I can't sleep because I have too much work to do\", \\\n",
    "              \"I think it's good to take a break for a while\", \"I should I'll go for a walk from time to time\", \\\n",
    "              \"Taking a walk is good\", \"Thanks for listening\", \"Yes! See you next time\"]\n",
    "\n",
    "len(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c5ba81a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn_cnt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>안녕</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>안녕하세요 ~ 반가워요</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>User</td>\n",
       "      <td>이름이 뭐야 ?</td>\n",
       "      <td>what is your name ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>저는 심리상담 챗봇, ~ 에요</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>User</td>\n",
       "      <td>아하 ㅎㅎ</td>\n",
       "      <td>Ah-huh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>좋은 아침이에요</td>\n",
       "      <td>good morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>User</td>\n",
       "      <td>오늘 너무 우울하다</td>\n",
       "      <td>I'm so depressed today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무슨 일 있어요 ?</td>\n",
       "      <td>What's wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>User</td>\n",
       "      <td>그냥 요즘 너무 무기력한거 같아</td>\n",
       "      <td>I just feel so lethargic these days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>무기력할 때는 몸을 움직여야 해요</td>\n",
       "      <td>When you're lethargic, you have to move your body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>User</td>\n",
       "      <td>심리적으로도 지친 거 같아</td>\n",
       "      <td>I think he's psychologically exhausted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?</td>\n",
       "      <td>I think you're really tired Is your work very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>User</td>\n",
       "      <td>일이 너무 많아서 잠도 너무 못 자</td>\n",
       "      <td>I can't sleep because I have too much work to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요</td>\n",
       "      <td>I think it's good to take a break for a while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>User</td>\n",
       "      <td>그래야겠어, 종종 산책하러 다녀야지</td>\n",
       "      <td>I should I'll go for a walk from time to time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>산책 좋죠</td>\n",
       "      <td>Taking a walk is good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>들어줘서 고마워</td>\n",
       "      <td>Thanks for listening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chatbot</td>\n",
       "      <td>네 ! 다음에 또 봐요</td>\n",
       "      <td>Yes! See you next time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    turn_cnt speaker_idx                                   text  \\\n",
       "0          1        User                                     안녕   \n",
       "1          2     Chatbot                           안녕하세요 ~ 반가워요   \n",
       "2          3        User                               이름이 뭐야 ?   \n",
       "3          4     Chatbot                       저는 심리상담 챗봇, ~ 에요   \n",
       "4          5        User                                  아하 ㅎㅎ   \n",
       "5          6     Chatbot                               좋은 아침이에요   \n",
       "6          7        User                             오늘 너무 우울하다   \n",
       "7          8     Chatbot                             무슨 일 있어요 ?   \n",
       "8          9        User                      그냥 요즘 너무 무기력한거 같아   \n",
       "9         10     Chatbot                     무기력할 때는 몸을 움직여야 해요   \n",
       "10        11        User                         심리적으로도 지친 거 같아   \n",
       "11        12     Chatbot        많이 지치신게 느껴지는거 같아요. 일이 많이 힘든가요 ?   \n",
       "12        13        User                   일이 너무 많아서 잠도 너무 못 자    \n",
       "13        14     Chatbot  그럴때는 잠시 마음의 여유를 가지고 쉬었다 가는 것도 좋은거 같아요   \n",
       "14        15        User                    그래야겠어, 종종 산책하러 다녀야지   \n",
       "15        16     Chatbot                                  산책 좋죠   \n",
       "16        17        User                               들어줘서 고마워   \n",
       "17        18     Chatbot                           네 ! 다음에 또 봐요   \n",
       "\n",
       "                                           translated  \n",
       "0                                                 hey  \n",
       "1                             Hello, nice to meet you  \n",
       "2                                 what is your name ?  \n",
       "3             I am a psychological counseling chatbot  \n",
       "4                                              Ah-huh  \n",
       "5                                        good morning  \n",
       "6                              I'm so depressed today  \n",
       "7                                       What's wrong?  \n",
       "8                 I just feel so lethargic these days  \n",
       "9   When you're lethargic, you have to move your body  \n",
       "10             I think he's psychologically exhausted  \n",
       "11  I think you're really tired Is your work very ...  \n",
       "12   I can't sleep because I have too much work to do  \n",
       "13      I think it's good to take a break for a while  \n",
       "14      I should I'll go for a walk from time to time  \n",
       "15                              Taking a walk is good  \n",
       "16                               Thanks for listening  \n",
       "17                             Yes! See you next time  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['translated'] = translated\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "589b705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'conv_translated.pickle'), 'wb') as f:\n",
    "    pickle.dump(conv, f, pickle.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3b06b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User</td>\n",
       "      <td>what is your name ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User</td>\n",
       "      <td>Ah-huh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                     text\n",
       "0     User                                      hey\n",
       "1  Chatbot                  Hello, nice to meet you\n",
       "2     User                      what is your name ?\n",
       "3  Chatbot  I am a psychological counseling chatbot\n",
       "4     User                                   Ah-huh"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['translated'] = translated\n",
    "conv = conv[['speaker_idx', 'translated']]\n",
    "conv.columns = ['speaker', 'text']\n",
    "conv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7797aa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'Hello, nice to meet you',\n",
       " 'what is your name ?',\n",
       " 'I am a psychological counseling chatbot',\n",
       " 'Ah-huh',\n",
       " 'good morning',\n",
       " \"I'm so depressed today\",\n",
       " \"What's wrong?\",\n",
       " 'I just feel so lethargic these days',\n",
       " \"When you're lethargic, you have to move your body\",\n",
       " \"I think he's psychologically exhausted\",\n",
       " \"I think you're really tired Is your work very hard?\",\n",
       " \"I can't sleep because I have too much work to do\",\n",
       " \"I think it's good to take a break for a while\",\n",
       " \"I should I'll go for a walk from time to time\",\n",
       " 'Taking a walk is good',\n",
       " 'Thanks for listening',\n",
       " 'Yes! See you next time']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_list = conv.text.values.tolist()\n",
    "conv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71939437",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_list = conv.text.values.tolist()\n",
    "\n",
    "conv_result = [] \n",
    "for text in conv_list: \n",
    "    conv_dataset = test_processor.convert_sentence(text)\n",
    "    conv_sampler = test_processor.shuffle_data(conv_dataset, 'test')\n",
    "    conv_dataloader = test_processor.load_data(conv_dataset, conv_sampler)\n",
    "    y_pred, y_true = bert_tester.get_label(conv_dataloader)\n",
    "    conv_result.append(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d10f41e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14854/1442458656.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv['predict'] = conv_result\n",
      "/tmp/ipykernel_14854/1442458656.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conv['predict'] = conv.predict.apply(lambda x: label[x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User</td>\n",
       "      <td>hey</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Hello, nice to meet you</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User</td>\n",
       "      <td>what is your name ?</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User</td>\n",
       "      <td>Ah-huh</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>good morning</td>\n",
       "      <td>수면장애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>User</td>\n",
       "      <td>I'm so depressed today</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>What's wrong?</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>User</td>\n",
       "      <td>I just feel so lethargic these days</td>\n",
       "      <td>무기력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>When you're lethargic, you have to move your body</td>\n",
       "      <td>무기력</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>User</td>\n",
       "      <td>I think he's psychologically exhausted</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I think you're really tired Is your work very ...</td>\n",
       "      <td>과도한 죄책감 및 무가치함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>User</td>\n",
       "      <td>I can't sleep because I have too much work to do</td>\n",
       "      <td>수면장애</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>I think it's good to take a break for a while</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>User</td>\n",
       "      <td>I should I'll go for a walk from time to time</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Taking a walk is good</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>User</td>\n",
       "      <td>Thanks for listening</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chatbot</td>\n",
       "      <td>Yes! See you next time</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                               text         predict\n",
       "0      User                                                hey              우울\n",
       "1   Chatbot                            Hello, nice to meet you              우울\n",
       "2      User                                what is your name ?              우울\n",
       "3   Chatbot            I am a psychological counseling chatbot  과도한 죄책감 및 무가치함\n",
       "4      User                                             Ah-huh              우울\n",
       "5   Chatbot                                       good morning            수면장애\n",
       "6      User                             I'm so depressed today              우울\n",
       "7   Chatbot                                      What's wrong?              우울\n",
       "8      User                I just feel so lethargic these days             무기력\n",
       "9   Chatbot  When you're lethargic, you have to move your body             무기력\n",
       "10     User             I think he's psychologically exhausted  과도한 죄책감 및 무가치함\n",
       "11  Chatbot  I think you're really tired Is your work very ...  과도한 죄책감 및 무가치함\n",
       "12     User   I can't sleep because I have too much work to do            수면장애\n",
       "13  Chatbot      I think it's good to take a break for a while              우울\n",
       "14     User      I should I'll go for a walk from time to time              우울\n",
       "15  Chatbot                              Taking a walk is good              우울\n",
       "16     User                               Thanks for listening              우울\n",
       "17  Chatbot                             Yes! See you next time              우울"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv['predict'] = conv_result\n",
    "conv['predict'] = conv.predict.apply(lambda x: label[x])\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f7426eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sent = \"I can't sleep because I have too much work to do\" # X_test.text[0]\n",
    "test_data = test_processor.convert_sentence(test_sent)\n",
    "test_sampler = test_processor.shuffle_data(test_data, 'test')\n",
    "test_loader = test_processor.load_data(test_data, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dbb8068e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e266bb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051</td>\n",
       "      <td>1051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1458</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>351</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  text\n",
       "label            \n",
       "0      4000  4000\n",
       "1       418   418\n",
       "2      1051  1051\n",
       "3      1458  1458\n",
       "4       143   143\n",
       "5       351   351\n",
       "6      2000  2000\n",
       "7       496   496\n",
       "8      2000  2000\n",
       "9      4000  4000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1acd9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = bert_tester.get_label(test_dataloader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d96195a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 3]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99c1ba61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 3]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "67c3ee5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred, y_true \u001b[38;5;241m=\u001b[39m bert_tester\u001b[38;5;241m.\u001b[39mget_label(test_loader, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred, y_true = bert_tester.get_label(test_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "076ea0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a1f4d80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 1]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "91b60322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 1]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a7db1779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3945</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1014</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>338</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3963</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3959</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>3930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2     3    4    5     6    7     8     9\n",
       "0  3945    0     3     7    3    0    19    2    15     6\n",
       "1     3  407     0     1    0    0     3    0     2     0\n",
       "2     1    1  1014     2    3    0     0    0     1     4\n",
       "3     2    0     1  1440    0    0     1    1     1     0\n",
       "4     0    0     0     2  141    0     0    0     0     0\n",
       "5     2    0     1     3    3  338     1    0     0     0\n",
       "6    13    0     3     5    0    0  3963    0    15     1\n",
       "7     1    0     0     3    0    1     0  485     0     0\n",
       "8    15    0     3     4    2    0     7    0  3959    10\n",
       "9    14    1    10    13    2    0     1    5    24  3930"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score , recall_score , confusion_matrix, f1_score, classification_report\n",
    "\n",
    "confusion_mt = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "confusion_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd513f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
