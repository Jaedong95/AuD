{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b497e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "from transformers import BertForSequenceClassification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536f3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path = os.getcwd()\n",
    "data_path = os.path.join(default_path, '../data')\n",
    "base_model = os.path.join(default_path, '../base-model')\n",
    "config_path = os.path.join(default_path, '../config')\n",
    "config_file = \"bert-base.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "242e14ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50gph3</td>\n",
       "      <td>every little insult even if it's online just h...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_wfhxs</td>\n",
       "      <td>do you know why you're feeling depressed, or i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58580</td>\n",
       "      <td>So I'm just gonna live in the countryside</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  label\n",
       "0    50gph3  every little insult even if it's online just h...      8\n",
       "1  t3_wfhxs  do you know why you're feeling depressed, or i...      0\n",
       "2     58580          So I'm just gonna live in the countryside      9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_samp = pd.read_csv(os.path.join(data_path, 'dsm_samp_test.csv'))\n",
    "dsm_samp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da6c626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at F:\\AuD\\base-model\\bert-base were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(base_model, 'bert-base'), model_max_length=32)\n",
    "config = BertConfig.from_pretrained(os.path.join(base_model, 'bert-base', 'bert_config.json'), output_hidden_states=True)\n",
    "model = BertModel.from_pretrained(os.path.join(base_model, 'bert-base'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18d94ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-9ec594b5589e>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(encoded['input_ids'])\n",
      "<ipython-input-6-9ec594b5589e>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attn_mask = torch.tensor(encoded['attention_mask'])\n",
      "<ipython-input-6-9ec594b5589e>:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_type_ids = torch.tensor(encoded['token_type_ids'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "dsm_emb = []\n",
    "\n",
    "for idx in range(len(dsm_samp)):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text=dsm_samp.text[idx],  # the sentence to be encoded\n",
    "        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "        max_length = 32,  # maximum length of a sentence\n",
    "        pad_to_max_length=True,  # Add [PAD]s\n",
    "        return_attention_mask = True,  # Generate the attention mask\n",
    "        return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    "    )\n",
    "    if idx % 1000 == 0:\n",
    "        print(idx)\n",
    "    # print(encoded)\n",
    "    input_ids = torch.tensor(encoded['input_ids'])\n",
    "    attn_mask = torch.tensor(encoded['attention_mask'])\n",
    "    token_type_ids = torch.tensor(encoded['token_type_ids'])\n",
    "    outputs = model(input_ids, attn_mask, token_type_ids)\n",
    "    hidden_states = outputs[2]\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "    dsm_emb.append(list(sentence_embedding.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276218d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsm_X = pd.DataFrame(dsm_emb, columns=range(len(dsm_emb[0])))\n",
    "dsm_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_y = dsm_samp.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffa0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "dsm_X = pca.fit_transform(dsm_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm_X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6626a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"bright\", 9)\n",
    "sns.scatterplot(x=dsm_X[:,0], y=dsm_X[:,1], hue=dsm_y, legend='full', palette=palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "dsm_X = pca.fit_transform(dsm_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd105a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2).fit_transform(dsm_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b9c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"bright\", 9)\n",
    "sns.scatterplot(x=X_embedded[:,0], y=X_embedded[:,1], hue=dsm_y, legend='full', palette=palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94022871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
