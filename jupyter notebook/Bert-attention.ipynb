{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f7b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import argparse\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertForSequenceClassification\n",
    "from attrdict import AttrDict\n",
    "from transformers import BertConfig, BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced57464",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path = os.getcwd()\n",
    "data_path = os.path.join(default_path, '../data')\n",
    "base_model = os.path.join(default_path, '../base-model')\n",
    "model_path = os.path.join(default_path, '../models')\n",
    "config_path = os.path.join(default_path, '../config')\n",
    "log_path = os.path.join(default_path, '../log')\n",
    "config_file = \"bert-base.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36337517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50gph3</td>\n",
       "      <td>every little insult even if it's online just h...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_wfhxs</td>\n",
       "      <td>do you know why you're feeling depressed, or i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58580</td>\n",
       "      <td>So I'm just gonna live in the countryside</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  label\n",
       "0    50gph3  every little insult even if it's online just h...      8\n",
       "1  t3_wfhxs  do you know why you're feeling depressed, or i...      0\n",
       "2     58580          So I'm just gonna live in the countryside      9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_samp = pd.read_csv(os.path.join(data_path, 'dsm_samp_test.csv'))\n",
    "dsm_samp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851d15f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at F:\\AuD\\base-model\\bert-mini were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at F:\\AuD\\base-model\\bert-mini and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(os.path.join(base_model, 'bert-mini'), model_max_length=128)\n",
    "config = BertConfig.from_pretrained(os.path.join(base_model, 'bert-mini', 'bert_config.json'),\\\n",
    "                                    num_labels=10,\\\n",
    "                                    output_hidden_states=True,\\\n",
    "                                    output_attentions=True)\n",
    "model = BertForSequenceClassification.from_pretrained(os.path.join(base_model, 'bert-mini'), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd14247",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, 'training_config.json')) as f:\n",
    "    training_config = AttrDict(json.load(f))\n",
    "\n",
    "training_config.pad = 'max_length'\n",
    "training_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77edf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.max_position_embeddings = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c180a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = os.path.join(model_path, 'DSM-5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87904be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 256, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 256)\n",
       "      (token_type_embeddings): Embedding(2, 256)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_name, map_location=torch.device('cpu')))\n",
    "model.to(training_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983a32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"I am so depressed today\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt').to(training_config.device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3be97acd",
   "metadata": {},
   "source": [
    "encoded = tokenizer.encode_plus(\n",
    "    text=dsm_samp.text[idx],  # the sentence to be encoded\n",
    "    add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "    max_length = 64,  # maximum length of a sentence\n",
    "    pad_to_max_length=True,  # Add [PAD]s\n",
    "    return_attention_mask = True,  # Generate the attention mask\n",
    "    return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a7d5c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  1045,  2572,  2061, 14777,  2651,   102]]), 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad3e33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92918453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 9.0596, -0.5454, -0.8855, -1.9694, -2.4331, -2.7073, -2.1461, -1.6226,\n",
       "         -2.0392, -0.5773]], grad_fn=<AddmmBackward0>), hidden_states=(tensor([[[ 0.3584, -0.5670,  1.5455,  ..., -0.0145,  0.0475,  0.7534],\n",
       "         [ 1.0136, -0.4370,  0.4381,  ..., -0.8308, -1.4829,  0.4043],\n",
       "         [ 1.8820,  0.9794,  0.1584,  ...,  0.3295, -1.5544,  0.7176],\n",
       "         ...,\n",
       "         [-0.1143, -0.7724, -1.0670,  ...,  2.0412, -0.8892,  1.0714],\n",
       "         [ 3.1112, -0.9919, -1.0718,  ..., -0.1175, -0.4586,  1.0868],\n",
       "         [-0.5815, -0.7431,  0.7391,  ..., -0.9457, -0.1700,  0.6018]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.7993, -0.8706,  0.7480,  ..., -0.0308, -0.3917,  1.3282],\n",
       "         [ 1.4623, -0.0041, -0.3623,  ..., -0.2483, -0.7309,  1.7501],\n",
       "         [ 0.9837,  0.0609, -0.0236,  ...,  1.0084, -1.6034,  1.8914],\n",
       "         ...,\n",
       "         [-0.3389, -0.4222, -0.7288,  ...,  2.4275, -1.2857,  2.2013],\n",
       "         [ 2.1268, -1.1720, -0.1829,  ...,  1.0100, -0.9156,  1.7390],\n",
       "         [ 0.4997, -0.7220,  0.3931,  ..., -0.3643, -0.4274,  1.0463]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 1.7107, -0.7500,  0.6371,  ...,  0.2378, -0.3680,  1.4095],\n",
       "         [ 2.2029, -0.3685,  0.1992,  ...,  0.4166, -0.3203,  1.1808],\n",
       "         [ 1.8978, -0.3260,  0.1615,  ...,  0.9229, -1.0142,  1.3608],\n",
       "         ...,\n",
       "         [ 0.6663, -0.5329, -0.0214,  ...,  1.6156, -0.8635,  1.4353],\n",
       "         [ 2.4990, -0.9197,  0.1081,  ...,  0.8443, -0.9355,  1.4447],\n",
       "         [ 1.3544, -0.7865,  0.4262,  ...,  0.0255, -0.1478,  1.3206]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1185, -0.9689,  0.7959,  ...,  1.2039, -1.1432,  0.8447],\n",
       "         [-0.0273, -0.7060,  0.6048,  ...,  1.1437, -1.4811,  0.8772],\n",
       "         [ 0.0381, -0.6280,  0.6289,  ...,  1.4278, -1.6064,  0.8424],\n",
       "         ...,\n",
       "         [-0.1327, -0.8369,  0.5473,  ...,  1.4719, -1.3912,  0.7387],\n",
       "         [ 0.2823, -0.9709,  0.5262,  ...,  1.1659, -1.4773,  0.8630],\n",
       "         [ 0.1047, -0.7419,  0.4409,  ...,  0.8955, -0.7689,  0.8141]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0675, -0.7802,  0.5396,  ...,  1.0596, -0.8252,  0.1387],\n",
       "         [ 0.0902, -0.6830,  0.5493,  ...,  1.0839, -0.8660,  0.1662],\n",
       "         [ 0.0992, -0.6967,  0.5424,  ...,  1.0981, -0.8613,  0.1406],\n",
       "         ...,\n",
       "         [ 0.0382, -0.7356,  0.5134,  ...,  1.0842, -0.8548,  0.1259],\n",
       "         [ 0.1066, -0.7355,  0.5438,  ...,  1.0586, -0.8587,  0.1380],\n",
       "         [ 0.0869, -0.7700,  0.5100,  ...,  1.0525, -0.7831,  0.1407]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)), attentions=(tensor([[[[2.3700e-01, 1.8312e-02, 1.9430e-01, 3.7809e-02, 2.6377e-01,\n",
       "           1.1033e-01, 1.3848e-01],\n",
       "          [3.7655e-02, 3.0173e-01, 2.6134e-01, 3.3127e-02, 1.3521e-01,\n",
       "           1.9518e-01, 3.5752e-02],\n",
       "          [6.8226e-02, 7.8500e-02, 6.7089e-01, 1.0101e-02, 2.7703e-02,\n",
       "           1.0974e-01, 3.4839e-02],\n",
       "          [4.2277e-02, 7.5930e-02, 1.9824e-01, 1.8847e-01, 4.8176e-02,\n",
       "           3.7635e-01, 7.0560e-02],\n",
       "          [3.0319e-01, 2.5710e-02, 1.1546e-01, 3.8158e-02, 2.4288e-01,\n",
       "           1.2809e-01, 1.4650e-01],\n",
       "          [5.6365e-03, 4.4063e-02, 1.6693e-01, 6.2473e-03, 8.6672e-03,\n",
       "           7.6553e-01, 2.9223e-03],\n",
       "          [1.5141e-02, 4.7855e-04, 8.9248e-01, 5.2812e-03, 1.2247e-02,\n",
       "           6.3557e-02, 1.0811e-02]],\n",
       "\n",
       "         [[4.2401e-01, 1.5064e-02, 4.7929e-03, 3.2947e-03, 4.7361e-03,\n",
       "           1.9682e-02, 5.2842e-01],\n",
       "          [4.6466e-04, 3.5965e-05, 9.9682e-01, 2.6002e-03, 5.8281e-05,\n",
       "           3.7685e-06, 1.7851e-05],\n",
       "          [5.2337e-04, 1.3708e-01, 2.5018e-02, 8.0837e-01, 2.8911e-02,\n",
       "           6.8299e-05, 3.0892e-05],\n",
       "          [3.2534e-03, 1.9056e-03, 1.8395e-01, 6.9812e-02, 7.3586e-01,\n",
       "           4.3674e-03, 8.5753e-04],\n",
       "          [2.3355e-03, 6.5471e-05, 1.0882e-03, 3.3653e-01, 5.0215e-01,\n",
       "           1.5286e-01, 4.9783e-03],\n",
       "          [4.4838e-02, 5.4314e-03, 2.5775e-03, 7.2617e-03, 4.0538e-02,\n",
       "           2.0458e-01, 6.9478e-01],\n",
       "          [2.2634e-02, 4.9162e-02, 3.2027e-01, 2.1916e-02, 2.9263e-02,\n",
       "           4.3859e-01, 1.1817e-01]],\n",
       "\n",
       "         [[8.6648e-02, 2.5917e-02, 4.9693e-01, 5.6788e-02, 1.5090e-01,\n",
       "           1.0724e-01, 7.5581e-02],\n",
       "          [2.8860e-02, 1.1533e-02, 2.8805e-01, 9.2760e-02, 4.6663e-01,\n",
       "           7.6895e-02, 3.5269e-02],\n",
       "          [3.6198e-02, 3.9557e-02, 2.8502e-01, 1.6738e-01, 3.0049e-01,\n",
       "           1.2438e-01, 4.6975e-02],\n",
       "          [5.7911e-02, 2.6669e-02, 3.8848e-01, 3.7807e-02, 3.1256e-01,\n",
       "           6.0865e-02, 1.1572e-01],\n",
       "          [1.0555e-01, 1.2746e-01, 3.1369e-01, 1.6361e-01, 1.3816e-02,\n",
       "           2.1434e-01, 6.1524e-02],\n",
       "          [8.2168e-02, 7.5310e-02, 3.6503e-01, 1.0845e-01, 2.5062e-01,\n",
       "           5.5764e-02, 6.2658e-02],\n",
       "          [2.3010e-02, 1.3844e-02, 4.0630e-01, 1.2144e-01, 3.5973e-01,\n",
       "           4.3816e-02, 3.1858e-02]],\n",
       "\n",
       "         [[1.8529e-03, 1.5740e-03, 2.8981e-03, 2.5499e-04, 9.7961e-01,\n",
       "           1.2780e-03, 1.2529e-02],\n",
       "          [3.0503e-04, 1.1742e-03, 4.0597e-01, 8.5722e-04, 5.8874e-01,\n",
       "           2.6202e-03, 3.3373e-04],\n",
       "          [1.3483e-04, 4.8721e-03, 1.1018e-02, 1.0124e-03, 9.7819e-01,\n",
       "           4.0718e-03, 6.9960e-04],\n",
       "          [3.3685e-04, 2.5463e-03, 2.5437e-02, 7.5363e-05, 9.7004e-01,\n",
       "           5.5659e-04, 1.0121e-03],\n",
       "          [1.8773e-04, 6.2539e-04, 3.7683e-03, 4.6308e-04, 9.9433e-01,\n",
       "           2.8194e-04, 3.4042e-04],\n",
       "          [2.0872e-03, 2.9932e-03, 1.3762e-02, 1.8246e-03, 9.6356e-01,\n",
       "           1.1666e-02, 4.1069e-03],\n",
       "          [8.5768e-04, 1.7044e-03, 1.9799e-02, 1.1544e-03, 9.6734e-01,\n",
       "           7.2358e-03, 1.9077e-03]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[4.7173e-01, 2.3237e-02, 1.9551e-01, 2.7919e-02, 9.3938e-02,\n",
       "           2.1686e-02, 1.6598e-01],\n",
       "          [3.3054e-03, 1.1834e-04, 1.4034e-01, 8.4491e-01, 1.1317e-02,\n",
       "           9.3821e-06, 2.2730e-06],\n",
       "          [8.2114e-04, 8.3074e-06, 4.0427e-03, 3.7748e-01, 6.1762e-01,\n",
       "           3.0157e-05, 2.6381e-07],\n",
       "          [3.9671e-05, 2.9462e-08, 1.7615e-04, 2.1431e-02, 9.7835e-01,\n",
       "           4.4899e-06, 1.3898e-09],\n",
       "          [2.9739e-02, 3.5791e-08, 4.3297e-06, 4.0273e-06, 9.6914e-01,\n",
       "           9.7156e-04, 1.3627e-04],\n",
       "          [4.3253e-01, 1.1899e-04, 1.8972e-03, 3.0567e-04, 2.2053e-01,\n",
       "           1.3157e-02, 3.3146e-01],\n",
       "          [5.2804e-01, 1.8636e-02, 8.6939e-02, 4.5205e-03, 8.1289e-04,\n",
       "           6.8759e-02, 2.9230e-01]],\n",
       "\n",
       "         [[2.1090e-02, 3.4145e-03, 3.6065e-02, 5.3401e-02, 8.4673e-01,\n",
       "           2.0703e-02, 1.8597e-02],\n",
       "          [3.7033e-02, 9.3285e-02, 1.9939e-01, 5.3360e-02, 4.5853e-01,\n",
       "           8.8650e-02, 6.9748e-02],\n",
       "          [3.0477e-03, 1.1301e-03, 8.2290e-01, 3.9476e-03, 1.4041e-01,\n",
       "           1.9556e-02, 8.9990e-03],\n",
       "          [1.6934e-02, 3.8966e-03, 6.7673e-02, 3.2548e-01, 4.5311e-01,\n",
       "           6.0531e-02, 7.2375e-02],\n",
       "          [8.5298e-03, 5.2689e-04, 2.9037e-02, 1.3272e-02, 9.0200e-01,\n",
       "           1.0844e-02, 3.5786e-02],\n",
       "          [1.2714e-02, 2.3594e-03, 1.7248e-01, 4.8142e-02, 4.1346e-01,\n",
       "           3.2314e-01, 2.7697e-02],\n",
       "          [1.6147e-02, 3.6609e-03, 1.1501e-01, 6.1265e-02, 7.6159e-01,\n",
       "           2.8962e-02, 1.3357e-02]],\n",
       "\n",
       "         [[1.6713e-02, 8.8419e-04, 1.0202e-02, 1.3596e-02, 9.4617e-01,\n",
       "           1.0449e-02, 1.9861e-03],\n",
       "          [4.4474e-01, 1.3076e-02, 7.8931e-02, 6.1900e-02, 3.7807e-01,\n",
       "           5.9600e-03, 1.7322e-02],\n",
       "          [3.2391e-01, 1.0142e-01, 9.4220e-02, 1.9391e-01, 2.5173e-01,\n",
       "           1.2394e-02, 2.2423e-02],\n",
       "          [1.6933e-01, 1.7850e-02, 1.3715e-01, 5.7852e-02, 6.1081e-01,\n",
       "           2.1741e-03, 4.8370e-03],\n",
       "          [2.3895e-02, 2.2487e-03, 1.7140e-02, 4.3561e-02, 9.0717e-01,\n",
       "           4.2169e-03, 1.7644e-03],\n",
       "          [7.9048e-02, 3.1403e-03, 2.8510e-02, 3.0221e-02, 8.3045e-01,\n",
       "           1.3846e-02, 1.4786e-02],\n",
       "          [2.4439e-01, 3.1047e-03, 1.0293e-02, 2.3394e-02, 6.1634e-01,\n",
       "           7.1368e-02, 3.1108e-02]],\n",
       "\n",
       "         [[7.0951e-01, 2.6932e-02, 9.4406e-02, 3.3303e-02, 7.2168e-02,\n",
       "           9.6292e-03, 5.4054e-02],\n",
       "          [9.1453e-01, 1.9722e-04, 7.7953e-03, 3.4545e-03, 4.3274e-02,\n",
       "           1.0816e-03, 2.9670e-02],\n",
       "          [8.9505e-01, 2.5268e-04, 1.0122e-02, 3.4466e-03, 7.4405e-02,\n",
       "           1.0616e-03, 1.5667e-02],\n",
       "          [8.2775e-01, 2.7057e-03, 7.4601e-02, 3.5543e-03, 6.8390e-02,\n",
       "           2.3520e-03, 2.0644e-02],\n",
       "          [9.7216e-01, 1.0519e-03, 7.7471e-03, 2.1187e-03, 7.2494e-03,\n",
       "           2.8830e-04, 9.3836e-03],\n",
       "          [7.4836e-01, 3.7135e-03, 9.7818e-02, 1.1868e-02, 1.0454e-01,\n",
       "           2.7908e-03, 3.0916e-02],\n",
       "          [5.4554e-01, 1.0739e-02, 1.4738e-01, 3.1040e-02, 1.9288e-01,\n",
       "           1.3892e-02, 5.8529e-02]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.5708e-01, 3.4605e-02, 1.4127e-01, 3.0115e-01, 2.0518e-01,\n",
       "           2.0847e-02, 3.9871e-02],\n",
       "          [2.5606e-01, 2.8706e-01, 1.9283e-01, 1.1226e-01, 2.5183e-02,\n",
       "           2.1999e-02, 1.0460e-01],\n",
       "          [1.1497e-01, 4.4163e-01, 1.7903e-01, 1.8623e-01, 1.6801e-02,\n",
       "           1.2111e-02, 4.9217e-02],\n",
       "          [9.4033e-02, 4.0977e-01, 2.6837e-01, 1.3382e-01, 1.6810e-02,\n",
       "           8.3634e-03, 6.8831e-02],\n",
       "          [3.7188e-01, 1.4321e-01, 1.5046e-01, 1.4421e-01, 7.3370e-02,\n",
       "           1.3385e-02, 1.0349e-01],\n",
       "          [6.5362e-01, 4.7582e-02, 3.1665e-02, 2.8441e-02, 6.1786e-02,\n",
       "           4.4101e-02, 1.3281e-01],\n",
       "          [7.3183e-01, 2.7213e-02, 2.8170e-02, 7.5807e-02, 5.0936e-02,\n",
       "           1.6444e-02, 6.9598e-02]],\n",
       "\n",
       "         [[9.0233e-02, 5.3689e-04, 1.3026e-02, 2.2382e-02, 8.4215e-01,\n",
       "           1.0018e-03, 3.0673e-02],\n",
       "          [5.0810e-02, 6.3495e-04, 1.5401e-02, 9.7286e-03, 8.9512e-01,\n",
       "           1.0034e-03, 2.7298e-02],\n",
       "          [7.1581e-02, 1.3715e-03, 2.6244e-02, 1.4645e-02, 8.2694e-01,\n",
       "           1.8770e-03, 5.7345e-02],\n",
       "          [1.3376e-01, 1.4993e-03, 2.6878e-02, 1.3528e-02, 7.3976e-01,\n",
       "           1.6362e-03, 8.2934e-02],\n",
       "          [1.8262e-01, 2.1064e-03, 3.2120e-02, 2.1832e-02, 6.5705e-01,\n",
       "           2.0206e-03, 1.0225e-01],\n",
       "          [7.2016e-02, 4.3273e-04, 1.5187e-02, 9.2589e-03, 8.6310e-01,\n",
       "           6.9700e-04, 3.9305e-02],\n",
       "          [1.6347e-01, 2.3667e-04, 7.5597e-03, 1.2009e-02, 7.8660e-01,\n",
       "           5.8048e-04, 2.9547e-02]],\n",
       "\n",
       "         [[2.4319e-01, 1.9188e-02, 5.8171e-02, 1.2637e-01, 4.6176e-01,\n",
       "           4.8502e-02, 4.2817e-02],\n",
       "          [1.5617e-01, 8.8032e-02, 2.3902e-01, 3.5937e-01, 1.4334e-01,\n",
       "           5.0446e-03, 9.0284e-03],\n",
       "          [1.9821e-01, 3.9347e-02, 1.2236e-01, 2.9982e-01, 3.3051e-01,\n",
       "           3.4546e-03, 6.2968e-03],\n",
       "          [3.7633e-01, 1.8183e-02, 7.4892e-02, 1.5606e-01, 3.6538e-01,\n",
       "           1.9989e-03, 7.1655e-03],\n",
       "          [5.0804e-01, 2.2476e-02, 3.5169e-02, 6.2288e-02, 3.1665e-01,\n",
       "           1.3273e-02, 4.2107e-02],\n",
       "          [1.8861e-01, 1.2827e-01, 1.1384e-01, 2.2769e-01, 2.5166e-01,\n",
       "           5.2650e-02, 3.7293e-02],\n",
       "          [3.2631e-01, 1.4688e-02, 6.8978e-02, 1.4205e-01, 3.3979e-01,\n",
       "           1.8621e-02, 8.9566e-02]],\n",
       "\n",
       "         [[1.3306e-02, 5.6506e-04, 1.3112e-03, 6.4588e-03, 9.7635e-01,\n",
       "           4.7458e-04, 1.5314e-03],\n",
       "          [1.5814e-03, 1.4744e-05, 8.8986e-05, 7.7109e-04, 9.9746e-01,\n",
       "           1.6055e-05, 6.3160e-05],\n",
       "          [2.0966e-03, 3.2548e-05, 1.4036e-04, 1.0507e-03, 9.9651e-01,\n",
       "           3.2119e-05, 1.3290e-04],\n",
       "          [8.4519e-03, 9.0541e-05, 2.8896e-04, 1.5466e-03, 9.8914e-01,\n",
       "           5.3398e-05, 4.2454e-04],\n",
       "          [2.0290e-02, 4.8408e-04, 9.2596e-04, 4.6404e-03, 9.7175e-01,\n",
       "           1.9984e-04, 1.7081e-03],\n",
       "          [2.6819e-03, 3.1334e-05, 1.4052e-04, 9.9182e-04, 9.9598e-01,\n",
       "           2.1901e-05, 1.5758e-04],\n",
       "          [1.2289e-02, 1.0424e-04, 4.8995e-04, 2.7631e-03, 9.8339e-01,\n",
       "           1.0910e-04, 8.4975e-04]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[0.1173, 0.0451, 0.0841, 0.0784, 0.1292, 0.0754, 0.4705],\n",
       "          [0.0791, 0.0389, 0.0519, 0.0610, 0.0959, 0.0663, 0.6068],\n",
       "          [0.0862, 0.0375, 0.0584, 0.0652, 0.1024, 0.0662, 0.5842],\n",
       "          [0.0942, 0.0395, 0.0627, 0.0753, 0.1168, 0.0733, 0.5381],\n",
       "          [0.1030, 0.0406, 0.0628, 0.0742, 0.1175, 0.0744, 0.5274],\n",
       "          [0.0790, 0.0364, 0.0593, 0.0660, 0.1088, 0.0760, 0.5743],\n",
       "          [0.1116, 0.0753, 0.1094, 0.0953, 0.1468, 0.1031, 0.3585]],\n",
       "\n",
       "         [[0.1637, 0.1049, 0.1804, 0.1774, 0.1790, 0.0292, 0.1653],\n",
       "          [0.1365, 0.0950, 0.1679, 0.1865, 0.1581, 0.0265, 0.2295],\n",
       "          [0.1386, 0.0976, 0.1629, 0.1874, 0.1600, 0.0252, 0.2283],\n",
       "          [0.1465, 0.0937, 0.1688, 0.1907, 0.1545, 0.0240, 0.2217],\n",
       "          [0.1432, 0.0973, 0.1549, 0.1765, 0.1567, 0.0307, 0.2408],\n",
       "          [0.1260, 0.0926, 0.1757, 0.1944, 0.1532, 0.0320, 0.2261],\n",
       "          [0.1308, 0.1295, 0.2042, 0.2050, 0.1920, 0.0294, 0.1091]],\n",
       "\n",
       "         [[0.1746, 0.0899, 0.0876, 0.1535, 0.1599, 0.0557, 0.2788],\n",
       "          [0.1558, 0.0787, 0.0746, 0.1143, 0.1127, 0.0634, 0.4005],\n",
       "          [0.1521, 0.0870, 0.0833, 0.1270, 0.1230, 0.0694, 0.3580],\n",
       "          [0.1523, 0.0917, 0.0814, 0.1266, 0.1243, 0.0688, 0.3550],\n",
       "          [0.1578, 0.0953, 0.0856, 0.1259, 0.1229, 0.0665, 0.3461],\n",
       "          [0.1689, 0.0755, 0.0681, 0.1019, 0.1121, 0.0608, 0.4127],\n",
       "          [0.1699, 0.1089, 0.0965, 0.1672, 0.1922, 0.0575, 0.2078]],\n",
       "\n",
       "         [[0.1990, 0.0403, 0.0806, 0.1105, 0.3290, 0.0365, 0.2041],\n",
       "          [0.2004, 0.0376, 0.0743, 0.0991, 0.2644, 0.0355, 0.2886],\n",
       "          [0.2027, 0.0397, 0.0789, 0.1033, 0.2842, 0.0378, 0.2534],\n",
       "          [0.2069, 0.0381, 0.0771, 0.0998, 0.2828, 0.0353, 0.2600],\n",
       "          [0.1980, 0.0416, 0.0835, 0.1069, 0.2774, 0.0370, 0.2557],\n",
       "          [0.1901, 0.0386, 0.0833, 0.1081, 0.2767, 0.0365, 0.2666],\n",
       "          [0.1715, 0.0435, 0.0835, 0.1114, 0.3692, 0.0406, 0.1803]]]],\n",
       "       grad_fn=<SoftmaxBackward0>)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b16cda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([1, 4, 7, 7]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.attentions), outputs.attentions[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20dc229f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 7, 256)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.hidden_states), len(outputs.hidden_states[0]), len(outputs.hidden_states[0][0]), len(outputs.hidden_states[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81e11ff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 4, 7, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs.attentions), len(outputs.attentions[-1]), len(outputs.attentions[-1][0]), len(outputs.attentions[-1][0][0]), len(outputs.attentions[-1][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8832579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 7, 7])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(outputs.attentions[-1], dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f0963c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'hidden_states', 'attentions'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49e46cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1116, 0.0753, 0.1094, 0.0953, 0.1468, 0.1031, 0.3585],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor(1.0000, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[-1][0][0][6], sum(outputs.attentions[-1][0][0][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2e34083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1173, 0.0451, 0.0841, 0.0784, 0.1292, 0.0754, 0.4705],\n",
       "         [0.0791, 0.0389, 0.0519, 0.0610, 0.0959, 0.0663, 0.6068],\n",
       "         [0.0862, 0.0375, 0.0584, 0.0652, 0.1024, 0.0662, 0.5842],\n",
       "         [0.0942, 0.0395, 0.0627, 0.0753, 0.1168, 0.0733, 0.5381],\n",
       "         [0.1030, 0.0406, 0.0628, 0.0742, 0.1175, 0.0744, 0.5274],\n",
       "         [0.0790, 0.0364, 0.0593, 0.0660, 0.1088, 0.0760, 0.5743],\n",
       "         [0.1116, 0.0753, 0.1094, 0.0953, 0.1468, 0.1031, 0.3585]],\n",
       "\n",
       "        [[0.1637, 0.1049, 0.1804, 0.1774, 0.1790, 0.0292, 0.1653],\n",
       "         [0.1365, 0.0950, 0.1679, 0.1865, 0.1581, 0.0265, 0.2295],\n",
       "         [0.1386, 0.0976, 0.1629, 0.1874, 0.1600, 0.0252, 0.2283],\n",
       "         [0.1465, 0.0937, 0.1688, 0.1907, 0.1545, 0.0240, 0.2217],\n",
       "         [0.1432, 0.0973, 0.1549, 0.1765, 0.1567, 0.0307, 0.2408],\n",
       "         [0.1260, 0.0926, 0.1757, 0.1944, 0.1532, 0.0320, 0.2261],\n",
       "         [0.1308, 0.1295, 0.2042, 0.2050, 0.1920, 0.0294, 0.1091]],\n",
       "\n",
       "        [[0.1746, 0.0899, 0.0876, 0.1535, 0.1599, 0.0557, 0.2788],\n",
       "         [0.1558, 0.0787, 0.0746, 0.1143, 0.1127, 0.0634, 0.4005],\n",
       "         [0.1521, 0.0870, 0.0833, 0.1270, 0.1230, 0.0694, 0.3580],\n",
       "         [0.1523, 0.0917, 0.0814, 0.1266, 0.1243, 0.0688, 0.3550],\n",
       "         [0.1578, 0.0953, 0.0856, 0.1259, 0.1229, 0.0665, 0.3461],\n",
       "         [0.1689, 0.0755, 0.0681, 0.1019, 0.1121, 0.0608, 0.4127],\n",
       "         [0.1699, 0.1089, 0.0965, 0.1672, 0.1922, 0.0575, 0.2078]],\n",
       "\n",
       "        [[0.1990, 0.0403, 0.0806, 0.1105, 0.3290, 0.0365, 0.2041],\n",
       "         [0.2004, 0.0376, 0.0743, 0.0991, 0.2644, 0.0355, 0.2886],\n",
       "         [0.2027, 0.0397, 0.0789, 0.1033, 0.2842, 0.0378, 0.2534],\n",
       "         [0.2069, 0.0381, 0.0771, 0.0998, 0.2828, 0.0353, 0.2600],\n",
       "         [0.1980, 0.0416, 0.0835, 0.1069, 0.2774, 0.0370, 0.2557],\n",
       "         [0.1901, 0.0386, 0.0833, 0.1081, 0.2767, 0.0365, 0.2666],\n",
       "         [0.1715, 0.0435, 0.0835, 0.1114, 0.3692, 0.0406, 0.1803]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f6603b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 7]), torch.Size([7, 7]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[-1][0].size(), outputs.attentions[-1][0][0].size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9af877f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([0.3585, 0.1468, 0.1116, 0.1094, 0.1031, 0.0953, 0.0753],\n",
       "       grad_fn=<SortBackward0>),\n",
       "indices=tensor([6, 4, 0, 2, 5, 3, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.attentions[-1][0][0][6].sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbc6fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_metrics = outputs.attentions[-1][0]\n",
    "att_sum = list(map(sum, att_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16e02d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 4, 0, 3, 2, 1, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(att_sum).sort(descending=True).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bebdf407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([9.1481, 5.0017, 4.1557, 3.4887, 2.8418, 1.9306, 1.4333],\n",
       "       grad_fn=<SortBackward0>),\n",
       "indices=tensor([6, 4, 0, 3, 2, 1, 5]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(att_sum).sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d3baeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2061) tensor(1045) tensor(2572)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('s o', 'i', 'a m', ',', 'a n d')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs[0][3], inputs[0][1], inputs[0][2])\n",
    "tokenizer.decode(2061), tokenizer.decode(1045), tokenizer.decode(2572), tokenizer.decode(1010), tokenizer.decode(1998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46776543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_att_toks(input_text, num_words):\n",
    "    input_text = input_text.replace(\"'m\", \" am\").replace('.', ' ').replace(',', ' ')\n",
    "    print(input_text)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors='pt').to(training_config.device)\n",
    "    outputs = model(inputs)  # Run model\n",
    "    attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "    att_metrics = outputs.attentions[-1][0]\n",
    "    # print(f'att_metric: {len(att_metrics[-1])}')\n",
    "    att_sum = list(map(sum, att_metrics))\n",
    "    # print(f'att_sum: {len(att_sum[0])}')\n",
    "    sorted_att = sum(att_sum).sort(descending=True)\n",
    "    \n",
    "    cnt = 0 \n",
    "    tok_idx = []\n",
    "    for idx in range(len(inputs[0])):\n",
    "        if inputs[0][sorted_att.indices[idx]] == 101 or inputs[0][sorted_att.indices[idx]] == 102:\n",
    "            continue\n",
    "        tok_idx.append(sorted_att.indices[idx])\n",
    "        cnt += 1\n",
    "        if cnt == num_words:\n",
    "            break \n",
    "    \n",
    "    tok_list = [tokenizer.decode(inputs[0][int(tok)]) for tok in tok_idx]\n",
    "    return tok_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e12cd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anyway  thanks for listening\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t h a n k s', 'a n y w a y', 'l i s t e n i n g', 'f o r']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Anyway, thanks for listening\"\n",
    "# inputs = tokenizer.encode(input_text, return_tensors='pt').to(training_config.device)\n",
    "get_att_toks(input_text, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73bf2e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker text\n",
       "0    user  hey"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'hey'\n",
    "conv = pd.DataFrame([text], columns=['text'])\n",
    "conv['speaker'] = 'user'\n",
    "conv = conv[['speaker', 'text']]\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbdbd827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user</td>\n",
       "      <td>hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>hello, nice to meet you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user</td>\n",
       "      <td>who are you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>I am a psychological counseling chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user</td>\n",
       "      <td>ah-huh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>how are you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user</td>\n",
       "      <td>I am very depressed today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>what is the matter ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user</td>\n",
       "      <td>I do not know why but just depressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>when you are depressed, you have to move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>user</td>\n",
       "      <td>also I lost 30 pounds and I feel lethargic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>that sounds too bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user</td>\n",
       "      <td>Anyway, thanks for listening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>yes, see you next time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speaker                                        text\n",
       "0      user                                         hey\n",
       "1   chatbot                     hello, nice to meet you\n",
       "2      user                               who are you ?\n",
       "3   chatbot     I am a psychological counseling chatbot\n",
       "4      user                                      ah-huh\n",
       "5   chatbot                               how are you ?\n",
       "6      user                   I am very depressed today\n",
       "7   chatbot                        what is the matter ?\n",
       "8      user        I do not know why but just depressed\n",
       "9   chatbot    when you are depressed, you have to move\n",
       "10     user  also I lost 30 pounds and I feel lethargic\n",
       "11  chatbot                         that sounds too bad\n",
       "12     user                Anyway, thanks for listening\n",
       "13  chatbot                      yes, see you next time"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.loc[1] = ['chatbot', 'hello, nice to meet you']\n",
    "conv.loc[2] = ['user', 'who are you ?']\n",
    "conv.loc[3] = ['chatbot', 'I am a psychological counseling chatbot']\n",
    "conv.loc[4] = ['user', 'ah-huh']\n",
    "conv.loc[5] = ['chatbot', 'how are you ?']\n",
    "conv.loc[6] = ['user', 'I am very depressed today']\n",
    "conv.loc[7] = ['chatbot', 'what is the matter ?'] \n",
    "conv.loc[8] = ['user', 'I do not know why but just depressed']\n",
    "conv.loc[9] = ['chatbot', 'when you are depressed, you have to move']\n",
    "conv.loc[10] = ['user', 'also I lost 30 pounds and I feel lethargic']\n",
    "conv.loc[11] = ['chatbot', 'that sounds too bad']\n",
    "conv.loc[12] = ['user', 'Anyway, thanks for listening']\n",
    "conv.loc[13] = ['chatbot', 'yes, see you next time']\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b4f7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = [idx for idx in range(len(conv)) if idx % 2 == 0]\n",
    "user_conv = conv.loc[user_idx]\n",
    "user_conv.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65259505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "who are you ?\n",
      "ah-huh\n",
      "I am very depressed today\n",
      "I do not know why but just depressed\n",
      "also I lost 30 pounds and I feel lethargic\n",
      "Anyway  thanks for listening\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['h e y'],\n",
       " ['?', 'y o u', 'w h o'],\n",
       " ['h u h', '-', 'a h'],\n",
       " ['d e p r e s s e d', 'a m', 'v e r y'],\n",
       " ['d e p r e s s e d', 'b u t', 'w h y'],\n",
       " ['# # h a r', 'p o u n d s', '3 0'],\n",
       " ['t h a n k s', 'a n y w a y', 'l i s t e n i n g']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_list = []\n",
    "for idx in range(len(user_conv)):\n",
    "    tok_list.append(get_att_toks(user_conv.text[idx], 3))\n",
    "\n",
    "tok_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79209506",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_conv['tokens'] = tok_list\n",
    "user_conv.tokens = user_conv.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbe08fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user</td>\n",
       "      <td>hey</td>\n",
       "      <td>h e y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user</td>\n",
       "      <td>who are you ?</td>\n",
       "      <td>?, y o u, w h o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user</td>\n",
       "      <td>ah-huh</td>\n",
       "      <td>h u h, -, a h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user</td>\n",
       "      <td>I am very depressed today</td>\n",
       "      <td>d e p r e s s e d, a m, v e r y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user</td>\n",
       "      <td>I do not know why but just depressed</td>\n",
       "      <td>d e p r e s s e d, b u t, w h y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user</td>\n",
       "      <td>also I lost 30 pounds and I feel lethargic</td>\n",
       "      <td># # h a r, p o u n d s, 3 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user</td>\n",
       "      <td>Anyway, thanks for listening</td>\n",
       "      <td>t h a n k s, a n y w a y, l i s t e n i n g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker                                        text  \\\n",
       "0    user                                         hey   \n",
       "1    user                               who are you ?   \n",
       "2    user                                      ah-huh   \n",
       "3    user                   I am very depressed today   \n",
       "4    user        I do not know why but just depressed   \n",
       "5    user  also I lost 30 pounds and I feel lethargic   \n",
       "6    user                Anyway, thanks for listening   \n",
       "\n",
       "                                        tokens  \n",
       "0                                        h e y  \n",
       "1                              ?, y o u, w h o  \n",
       "2                                h u h, -, a h  \n",
       "3              d e p r e s s e d, a m, v e r y  \n",
       "4              d e p r e s s e d, b u t, w h y  \n",
       "5                  # # h a r, p o u n d s, 3 0  \n",
       "6  t h a n k s, a n y w a y, l i s t e n i n g  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_conv.tokens = user_conv.tokens.apply(lambda x: ', '.join(x))\n",
    "user_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2998cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
